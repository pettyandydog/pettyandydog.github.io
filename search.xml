<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[JVM加载机制]]></title>
      <url>%2F2017%2F03%2F06%2Fjvm_classLoad%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 类加载过程类加载是指类通过JVM加载到内存开始到从内存中卸载出去的过程，其生命周期包括七个阶段：加载（Loading），验证（Verification），准备（Preparation），解析（Resolution），初始化（Initialization），使用（Using），卸载（Unloading），其中验证，准备和解析统称为链接过程，如下图所示： 类加载器类加载器作用于类的加载过程，每一个加载器都拥有独立的类名称空间，而JVM中，有两种类型的类加载器，一种是由C++语言实现的启动类加载器（Bootstrap ClassLoader），另一种是由java语言实现的，独立于虚拟机外部，并且全部继承抽象类java.lang.ClassLoader的类加载器 双亲委派模型在大部分开发程序中，一般都会使用三种系统提供的类加载器 启动类加载器（Bootstrap ClassLoader）：由C++语言编写，负责加载核心java库（存储在/jre/lib） 扩展类加载器（Extension ClassLoader）:由sun.misc.Launcher$ExtClassLoader实现，负责加载java扩展库（存储在） 应用程序类加载器（Application ClassLoader）：由sun.misc.Launcher$AppClassLoader实现，负责加载应用程序的java库（存储在java.class.path或CLASSPATH下的类库） 除了以上三个由系统实现的类加载器，还可以自己实现自定义的类加载器，而这些类的关系如下图所示： 如上类加载器的层次关系图，展示类加载器与类加载器之间的层次关系，这被称为双亲委派模型，每一层上面相当于是自己的父类加载器，以组合的模式来复用父类加载器的功能双亲委派模型的工作过程是：当一个加载器收到加载请求时，他首先会该请求委派给父类加载器去完成，最终传递到顶层的启动类加载器加载，只有当父类加载器加载不了，才会让子加载器自己去尝试加载，这样的话，可以防止代码的重复，比如A类的加载器要加载System，B类加载器也要加载System，双亲委派机制可能在系统实现的三个类加载器就可以加载了。 参考https://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM垃圾收集]]></title>
      <url>%2F2017%2F02%2F14%2Fjvm_gc%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 JVM垃圾收集技术需要关注三个步骤：1.哪些对象需要被回收，2.什么时候进行回收，3.如何进行回收 哪些对象需要被回收引用计数算法引用技术算法大致的过程是给对象分配一个引用计数器，当该对象被引用时，引用计数器就加一，该引用失效时，计数器就减一，当计数器为零时，说明该对象没有任何引用，就判定该对象可以被回收，虽然它的实现简单即高效，不过现代主流的JVM收集器都没有使用该算法，它有一个致命的缺陷是无法解决对象之间相互循环引用的问题 可达性分析算法可达性分析算法大致的过程是通过一系列的成为GC Roots的对象作为起点，他会向下进行搜索，所走过的路径成为引用链，如果一个对象到GC Roots没有任何的引用链（指该对象在程序中没有任何关系了），则说明该对象是可以被回收的在java语言中，可以作为GC Roots的对象包括如下： 虚拟机栈中的栈帧内的本地变量表中引用的对象 方法区中类静态属性引用和常量引用的对象 本地方法栈中引用的对象 什么时候进行回收在现代的内存分配中，堆被分为年轻代（8：1比例分配的1个Eden区和2个Survivor（FromSurvivor 和 ToSurvivor））和老年代，那什么时候会对年轻代和老年代的对象进行回收呢？ 首先，创建一个对象，JVM会给该对象分配一个对象年龄计数器，该对象大部分情况下会被优先分配到年轻代中的Eden区中（对于大对象，直接分配到老年代中），当Eden区中没有被分配的空间时，这时候JVM会触发一次Minor GC（年轻代GC），该对象的年龄置为1，存活下来的对象会往ToSurvivor区中移动，FromSurvivor区中存活的对象也复制到ToSurvivor区中，这时，ToSurvivor区和FromSurvivor区身份调换，当该对象的年龄增加到一定程度（默认是15）时，该对象会被晋升到老年代中，当然如果FromSurvivor中的相同年龄段的对象超过了一般，则大于该年龄段的对象直接晋升到老年代，在老年代中如果最大可用的连续空间小于晋升到老年代的对象大小，会进行一次Full GC 如何进行回收垃圾收集算法标记-清除算法（Mark-Sweep）标记-清除算法的回收过程分为两个阶段：标记和清除，标记就是标记哪些对象可以被回收（上面已经介绍过了），清除就是回收哪些被标记的可回收对象，这两个阶段的效率都不是很高，而且会产生大量的空间碎片，过程如下图 复制算法（Copying）复制算法的回收过程是将内存分成两块等量大小的内存块，一块是存储对象数据，另一块是保留区域（不存储任何数据），当存储对象数据的内存块用完了，就将还存活的对象复制到保留区域，然后将已使用过的内存块清理掉，原来存储对象数据的内存块变成了保留区，原来的保留区变成了存储对象数据的内存块，复制过程只需要移动堆顶的指针可以，简单高效，而且没有内存碎片化的存在，但是却将原有的内存缩小了一般，这也适合现代新生代的回收机制，因为新生代大部分都是朝生夕死，当然他们的内存划分比例不需要到达1：1，典型的就是8：1的eden区和survivor区，具体过程如下图： 标记-整理算法标记-整理算法的回收过程分为标记和整理两个阶段，它是标记-清除算法的改进版本，标记和标记-清除算法一致，不同的是，他不是直接对可回收的对象进行清除，而是将存活下来的对象往一端移动，再清理掉存活边界外的内存，它解决了标记-清除算法的内存碎片化问题，但是效率不是很高，具体过程如下图： 分代收集算法分代收集算法是指按照对象的存活周期，在堆中分为新生代和老年代，根据不同年代的特点使用不同收集算法的组合，比如新生代的特点是朝生夕死，对象存活周期短，使用复制算法，只需要少量的存活对象的复制成本即可，而老年代存活周期长，使用标记-清除或者标记-整理算法，因为它们的内存不大，没有额外的空间进行担保，这样就会形成一个组合来进行垃圾收集 垃圾收集器JVM的发展中，发布了很多的收集器，从最开始的单线程版的收集器serial(针对新生代)/serial old（针对老年代）收集器（JDK1.3以前）到多线程的并行收集器parallel scavenge（针对新生代）/parallel old(针对老年代)收集器，一直到现在针对多核，多CPU的环境下，充分的利用其硬件资源和重视快速响应的CMS收集器（JDK1.5以后）和G1收集器（JDK1.7以后） CMS收集器cms（Concurrent Mark Sweep）收集器是一款针对于最短回收时间停顿的老年代收集器，从名称上就可以知道该收集是基于标记-清除算法，它是把最耗时间的标记（GC Root Tracing）和清除过程使用了并发机制，和用户线程共同运行，大大的减少了停顿时间，具体过程如下：该收集器可以分为五个步骤： 初始标记：标记GC Roots所能关联的对象 并发标记：根据第一步的对象并发的遍历其他的对象（GC Roots Tracing） 重新标记：由于第二步的运行时间较长，对象可能会产生变化，开启多个线程重新标记已标记的对象 并发清理：并发的从需要被收集的对象集合中清除这些对象 并发重置：重置CMS收集器的数据，为下一次收集做准备 上述的五大步骤就是CMS收集的过程，整的来说已经实现了并发收集，低停顿，响应快等优点，但是还有三个明显的缺点： 由于CMS收集器是并发收集，它会占用其他线程的CPU资源，导致吞吐量低，部分线程变慢 CMS收集器无法处理在重新标记这个时间段里的垃圾，因为在重新标记期间，程序会产生新的对象或者变动，这是CMS收集器会预先预留一部分内存来处理，所以在一定的比例下（默认老年代空间使用率到达68%），就会触发CMS收集 CMS收集器采用的是标记-清除算法，所以会产生大量的内存碎片 G1收集器G1收集器（Garbage-First）是一款服务器型的垃圾收集器，它是由一个个大小相等的Regoin（内存区域）组成，通过一系列的标记阶段之后，之后优先收集那些垃圾最多的区域，它也保存了以往的分代收集的概念，但是新生代和老年代不需要设定固定的大小来控制，这样在内存的使用上提供了很大的灵活性，传统的堆分区如下：上述的是传统的把堆分成年轻代（1个eden区和2个survivor区），老年代，和永久代，在G1收集器中也保持了分代的理念，如下图: 如上图所述，他是用一个个内存区域的概念来存储分代对象，和CMS收集器不同的是它是用标记-整体算法来进行收集过程，整体的解决了内存碎片的问题 参考http://zhaoyanblog.com/archives/397.htmlhttps://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM运行时数据区域]]></title>
      <url>%2F2017%2F02%2F10%2Fjvm_list_range%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Java虚拟机（英语：Java Virtual Machine，缩写为JVM），一种能够运行Java bytecode的虚拟机，以堆栈结构机器来进行实做。最早由太阳微系统所研发并实现第一个实现版本，是Java平台的一部分，能够运行以Java语言写作的软件程序(来自wiki) 运行时数据区域JVM运行时数据区域由java栈，PC寄存器，本地方法栈，堆和方法区等五大数据区域组成，其结构图如下： 线程私有java栈java栈是线程私有的，它的生命周期会随着线程的创建而开始，摧毁而结束，它描述着java执行方法的内存模型：每个线程在执行方法时，会创建一个栈帧，该栈帧存储着方法的所有信息（局部变量表，操作数栈，栈数据区和方法出口等信息），一个方法的调用就好像是JVM对栈帧进行进栈到出栈的过程，由于其生命周期和线程一样，所以不需要GC PC寄存器PC寄存器也是线程私有的，是一块很小的内存，它是存储JVM当前方法执行的指令地址，就像是执行字节码的指示器，控制着当前程序的执行方向，JVM执行方法时就需要获取该计数器的指令来进行下一步的操作 本地方法栈本地方法栈与java栈类似，不同的是java栈执行的是java方法服务（字节码），而本地方法栈执行的JVM自己定义的本地方法服务，也就native修饰的方法 线程共享堆堆是线程共享的，所以它的声明周期由虚拟机创建时开始，主要存放的是对象的实例和数组，是JVM内存分配最大的，由于其生命周期较长，所以被垃圾回收收集器管理，由于现代的垃圾收集器都采用分代收集算法，所以还能以8比1的比例细分成一个Eden区和两个Survivor区（FromSurvivor和ToSurvivor） 方法区方法区也是线程共享的，它用于存储类的信息，常量，静态变量等信息（类的元数据在JAVA1.8已经移动到一块本地内存空间，也就是元空间），还有运行时常量池是方法区很重要的部分，存放编译器编译期间各种class中的常量值和类的描述信息。 对象在内存区域是如何运行对象在内存中是如果创建我们在代码中直接用new来表示创建一个对象，而在虚拟机中，会碰到一个new指令，首先会检查指令的参数在常量池中是否有这个类的符号引用，再检查此类是否已经被加载，解析和初始化过了，如果没有就会执行相应的加载过程，然后就会在堆中为对象分配内存，分配内存有两种方式： 指针碰撞：如果GC使用的是复制算法，把堆内存一分为二，一边是已分配内存，一边是空闲内存，没有内存碎片，那么只需从中间开始，指针往空闲内存空间移动相应大小的距离即可 空闲列表：如果GC是没有使用标记-整体的算法，存在内存碎片，这时候会维护一种记录可用内存的表，再从表中寻找一块足够大小的内存空间分配给对象实例。 由于堆是线程共享的，在分配内存时存在着线程安全，比如T1线程准备在表中选取A内存分配，还没有开始分配，这时T2线程也准备在表中选取A内存分配，这就会造成冲突，解决线程安全问题有下面两个方案： CAS同步，在分配操作上使用CAS操作保证分配内存的原子性 每个线程在堆上预先分配自己的一小块内存（本地线程分配缓冲 TLAB），只需要在该内存用完了，再同步分配新的TLAB 对象在内存中的结构组成对象存储在内存中分为三个部分：对象头，实例数据，对齐填充 对象头对象头包括两个部分，第一部分是存储对象自身的运行时数据（哈希码，GC分代年龄，锁标志等），也叫Mark Word，第二部分是类型指针，也叫元数据指针，来确定该对象是哪个类的实例 实例数据实例数据存储的是该对象内部所定义的类型的字段信息，包括从父类继承下来的，还是在子类定义的 对齐填充这是一个占位符，JVM规定对象的大小为8字节的整数倍，如果不是就用对齐填充来补全 对象在内存中如何被访问在内存中访问对象有两种方式：句柄池和直接引用 句柄池句柄池访问是指在栈中的reference引用指向的是句柄池上的地址，再由句柄池指向相应的对象信息，句柄池的内容包括对象实例数据的指针和对象类型数据的指针，在java堆划分一小块内存来存储它，具体访问过程如下图： 直接引用直接引用访问是指栈中的reference引用直接指向堆中对象实例的地址，访问过程如下图：以上两种访问方式各有优劣，句柄池在对象实例频繁的更替时，不需要改动reference中的指针，只需改变句柄池的指针即可，但是直接引用的访问速度比句柄池更快，省去了句柄池的指针指向对象实例的消耗，总结出来就是，对象更替频繁的使用句柄池，对象访问频繁的使用直接引用 参考https://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis持久化策略]]></title>
      <url>%2F2017%2F01%2F17%2Fredis_data_persistence%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Redis提供了两种不同级别的持久化策略，RDB（redis database）持久化和AOF(append only file)持久化，它们应用在不同的场景中，各有千秋，以下是两种策略的实现方案 RDB（redis database）持久化RDB（redis database）持久化是将内存中的数据生成一个特定格式的二进制的rdb文件，保存在磁盘中，在redis服务进程开启时通过读取磁盘中的rdb文件，数据又会还原到内存中。rdb文件结构如下： 写入指令写入（1）SAVE：SAVE命令是在当前服务进程进行持久化操作，会阻塞其他的操作命令，直到RDB文件创建完毕（2）BGSAVE：BGSAVE命令是创建一个子服务进程来专门处理持久化操作，其它操作命令在父服务进程继续执行 间隔性写入在配置文件中设置写入触发条件,比如:SAVE 900 1,代表在900秒内对数据库进行一次修改，就触发写入程序。 载入在服务器启动时，会对当前的持久化策略进行一个判断，如果当前已经开启了AOF持久化功能，那就会优先载入AOF还原程序，否则才载入RDB文件，整个载入过程都是阻塞的，保持数据的一致性。 AOF(append only file)持久化AOF(append only file)持久化是基于redis服务器对键值对的操作命令生成的aof文件，保存在磁盘中,AOF文件的结构就是一串操作命令的文本文件 写入AOF持久化通过以下步骤来进行持久化操作： 1. 命令追加（append）在redis服务器中提供了一个sds（简单动态字符串）类型的缓冲区aof_buff,它用于记录redis的操作命令，也就是利用命令追加（append）模式将redis的操作命令一条一条的追加到该缓冲区的末尾 2. 写入AOF文件将存储到缓冲区aof_buff中的指令通过调用flushAppendOnlyFile函数写入AOF文件中，写入AOF文件有三个策略： ● always：每一次数据操作，就将aof_buff缓冲区中的所有数据同步写入到AOF文件中 ● everysec：启动一个线程，定时（每隔一秒）将aof_buff缓冲区中的所有数据同步写入AOF文件中 ● no：不要求同步的情况下（aof_buff存储满溢），将aof_buff缓冲区中的数据写入AOF文件中三个策略的安全性：always&gt;everysec&gt;no , 效率：no&gt;everysec&gt;always 载入AOF持久化的载入方式是创建一个伪客户端去读取AOF文件，再在伪客户端中执行读取AOF文件中的一条条指令，直到完毕，数据库就恢复了之前的状态 重写AOF文件就像是数据库操作的日志文件，记录了数据库各种操作的指令，但是会出现冗余的指令记录，长时间下去，会导致文件体积变得太大，比如，执行如下操作1234RPUSH msg &apos;a&apos;RPUSH msg &apos;b&apos;RPUSH msg &apos;c&apos;RPUSH msg &apos;d&apos; 如上所示，最后msg的结果是’a’,’b’,’c’,’d’，AOF文件就会有四条指令的记录，其实只要一条指令记录就可以了，这时，AOF持久化提供了一种重写的机制，它会创建一个子进程来处理，在子进程中创建一个新的AOF文件，针对上面情况，对一个对象的多次操作，它会用一条指令来表示，这样新的AOF文件就大大减少了存储体积，由于在子进程进行重写的时候，父进程还会处理操作指令，在重写期间执行的操作指令会被写到一个aof重写缓冲区中，所以不仅仅是aof缓冲区写入新的AOF文件中，aof重写缓冲区也会写进新的AOF文件中，这样和旧的AOF文件保存的数据库状态是一致的，最后替换旧的AOF文件 思考优劣比较RDB持久化的优点在于：（1）RDB文件是一个非常紧凑的二进制文件，所以在远程传输上有很大的优势，可用于灾备中心的存储文件（2）在载入数据库上，大数据量的情况下，RDB比AOF更加快速（3）在持久化上，RDB持久化方式会fork一个子进程来执行，这样会保证Redis最大的性能缺点如下：（1）Redis的数据存储是基于内存的，如果碰上意外（宕机或者电源中断），如果你是每个五分钟甚至更长进行一次持久化，那么将会损失这几分钟的数据（2）RDB是fork子进程来进行持久化的，所以当大数据集的时候，这会加大cpu的响应时间，影响Redis的处理速度AOF持久化的优点在于：（1）AOF使用的是fsync策略进行持久化，所以即使碰上意外，也只是损失1秒的数据（2）AOF文件是一个日志文件，由指令集组成，通俗易懂，使使用者更加的好维护缺点如下：（1）相对于RDB文件来说，AOF文件相对过大了 如何选择使用哪种持久化方式一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快， 除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug 参考http://www.redis.cn/topics/persistence.htmlhttps://read.douban.com/ebook/7519526/（数据库的设计与实现）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis基本数据类型及其实现]]></title>
      <url>%2F2016%2F12%2F28%2Fredis_datatype%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库(来自wiki)，它提供丰富的数据结构类型：字符串（Strings），列表（Lists），哈希（Hashed），集合（Sets），有序集合（Sorted sets）来满足数据存储的需求，下面分别对这五大数据类型及其实现进行详述 字符串（String）实现的数据结构1. REDIS_ENCODING_INT（long类型整数）场景：SET的value为整数指令：SET msg 123 2. REDIS_ENCODING_RAW（大于32字节的字符串）场景：SET的value为大于32字节的字符串指令：SET msg LongString...... 注意：SDS是redis内部构建基于字符串的数据结构（不是直接使用C字符串），它由free（未分配空间），len（字符串长度或已使用长度），buf（存储字符数组）三部分组成，降低操作字符串的复杂度，len属性解决了不需要遍历整个字符串才能获取，free属性降低了内存重新分配的次数 3. REDIS_ENCODING_EMBSTR（小于32字节的字符串）场景：SET的value为小于32字节的字符串指令：SET msg hello 注意：对于字符串存储，对于raw编码模式，需要调用两次连续分配内存函数构建RedisObject和SDS这两块内存，而embstr的编码只需要一次性的内存分配一块连续的内存空间即可， 列表（Lists）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩列表）场景：（1）列表保存的元素都少于64个字节 （2）列表保存的元素数量少于512个指令：RPUSH msg &#39;a&#39; &#39;b&#39; &#39;c&#39;注意：ZipList是redis基于小数值和短字符串而构建的数据结构，由zlbytes（压缩列表占用的字节数），zltail（压缩列表尾节点到起始地址的偏移量），zllen（节点数），entryx（压缩列表的各个节点），zlend（压缩列表的尾端标记值） 2. REDIS_ENCODING_LINKEDLIST（链表）场景：（1）列表保存的元素都大于64个字节 （2）列表保存的元素数量大于512个指令：RPUSH msg &#39;a&#39; &#39;b&#39; &#39;c&#39; ......注意：LinkedList是类似于java中的LinkedList，由一个双向链表构成，自带长度计数器和表头表尾指针，在对于增加删除时能高效的进行调整（前后指针重新指定） 哈希（Hashes）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩列表）场景：（1）哈希对象中的键值对的长度都小于64字节 （2）哈希对象中的键值对的数量小于512个指令：HSET msg name &quot;andy&quot;注意：利用压缩列表实现键值对，实现方法是：key在前，value在后，形成一个链 2. REDIS_ENCODING_HASHTABLE（哈希表）场景：（1）哈希对象中的键值对的长度都大于64字节 （2）哈希对象中的键值对的数量大于512个指令：HSET msg name &quot;andy&quot; age &quot;24&quot; ......注意：HashTable也叫字典表，是整个redis的核心，类似于java中的HashTable，但是在其特殊的应用场景下，做出了一些改进，比如渐进式的rehash等等 集合（Sets）实现的数据结构1. REDIS_ENCODING_INTSET（整数集合）场景：（1）集合中的元素为整数 （2）集合中的元素个数小于512个指令：SADD msg 1 2 3注意：IntSet是redis存储整数集合的数据结构，有encoding（编码，保存的位数类型），length（长度）和contents（整数数组）构成，可以灵活的根据整数的存储位数来选择相应的存储方式来节省内存 2. REDIS_ENCODING_HASHTABLE（哈希表）场景：（1）集合中的元素不为整数 （2）集合中的元素个数大于512个指令：SADD msg &quot;a&quot; &quot;b&quot; &quot;c&quot; 有序集合（Sorted Sets）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩表）场景：（1）有序集合中的元素小于128个 （2）有序集合中所有元素的集合都少于64个字节指令：ZADD a 8 b 5 2. REDIS_ENCODING_SKIPLIST（跳跃表）场景：（1）有序集合中的元素大于128个 （2）有序集合中所有元素的集合有多于64个字节指令：ZADD a 8 b 5 ......注意：跳跃表是一种有序的数据结构，它通过每个节点指向其它多个节点的指针，来到达最快的访问节点速度，由header（表头节点），tail（表尾节点），level（节点最大层数），length（节点数），简单的实现就是通过一个有序的链表，表示为第一层，再取其中头结点和尾节点，中间随机多个不重复节点组成新的链表，即为第二层，如下重复下去，直到到达随机（1-32层）的阈值，这样到达中间的节点的复杂度将会大大的降低。上图中是还使用了哈希来获取元素的分数值来进行排序。 参考http://www.redis.cn/topics/data-types.htmlhttps://read.douban.com/ebook/7519526/（数据库的设计与实现）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[源码解析String，StringBuffer，StringBuilder的区别]]></title>
      <url>%2F2016%2F11%2F18%2FString%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 String，StringBuffer，StringBuilder三者是处理字符串的常用类，String是在JDK1.0时就存在的字符串处理类，也是使用最广泛的，StringBuffer也是JDK1.0开始发布的线程安全的字符串处理类，他改变了原有String不可改变的字符串，增加了一个缓冲的概念，StringBuilder是JDK1.5提出的字符串处理类，他取消了StringBuffer原有的线程安全的特性，增加了字符串处理的效率。 其实要说哪种处理字符串是性能最好的，我觉得是哪种场景上的字符串处理性能是最好的，因为他们是各有千秋，下面是基于JDK1.8的源码解析这三种字符串处理方式的区别 String123public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char value[]; 由上可知，String实现了序列化和字符序列两个接口，这会带来两个特性，一个是可传输的特性，一个是字符处理的特性，再看String的核心属性value，value是存储字符串的载体，由于被final修饰了，所有该字符串载体一旦初始化了就是不可变的，正是String不可变这一特性，所以它在处理字符串的方式只能通过构造初始化的方式来实现 1.初始化一个空串123public String() &#123; this.value = "".value;&#125; 2.初始化一个字符串对象1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125; 3.初始化一个字符串123public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length);&#125; 4.初始化字节类型的字符串123public String(byte ascii[], int hibyte) &#123; this(ascii, hibyte, 0, ascii.length);&#125; 当然还可以初始化StringBuffer，StringBuilder来构建，String的构造方法很丰富，提供了很多类型且多样的数据源来支持，如果你想要构建一个不变的或者变化不多的字符串，String很适合你 StringBuffer123public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123; 在StringBuffer继承体系来看，StringBuffer拥有String应有的特性，而且还继承了AbstractStringBuilder这个抽象类，这个类定义了StringBuffer的存储载体(也是StringBuilder的存储载体)，现在通过一个append方法来看看StringBuffer处理字符串的方式 12345public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this;&#125; 由上可知，这是一个StringBuffer拼接字符串的方法，由synchronized来修饰，所以StringBuffer是线程安全的（其实StringBuffer几乎所有的方法都是由synchronized修饰），这里它是调用的父类的append方法 123456789public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;&#125; 这是父类AbstractStringBuilder的append方法，在方法内有是两个很重要方法，也就是缓冲区的实现 扩容方法：ensureCapacityInternal(int minimumCapacity) 赋值方法：str.getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) 我们先看看扩容方法1234private void ensureCapacityInternal(int minimumCapacity) &#123; if (minimumCapacity - value.length &gt; 0) expandCapacity(minimumCapacity);&#125; 这里会对所拼接的字符串做一个判断，也就是所拼接的字符串不能为空1234567891011void expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity);&#125; 以上代码可知，他会先对原有的字符数组的容量扩大两倍再加二，在和最小的容量(原有的容量+拼接字符串的容量)比较，没有最小容量大就取最小容量，这里也有一个以防内存溢出导致容量为负数的一个处理，最后核心的就是 Arrays.copyOf(value, newCapacity)，Arrays这是一个数组的工具类，copyOf方法是针对数组在原有的基础上改变其容量，这就是等于对原有的字符串数组进行了扩容，在回来看看将拼接的字符数组重新添加到新的字符数组的方法 123456789101112public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) &#123; if (srcBegin &lt; 0) &#123; throw new StringIndexOutOfBoundsException(srcBegin); &#125; if (srcEnd &gt; value.length) &#123; throw new StringIndexOutOfBoundsException(srcEnd); &#125; if (srcBegin &gt; srcEnd) &#123; throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); &#125; System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin);&#125; 该方法开始会对不符合条件进行异常处理，最后的调用System.arraycopy方法将拼接字符数组添加到新的字符数组，这就完成了一个字符串拼接的过程，也就是缓冲池的实现，在多线程的情况下保证安全的前提字符串大量的变动，使用StringBuffer是最好的 StringBuilder123public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence 其实从父类体系来看，StringBuilder和StringBuffer是一样的，那StringBuilder与StringBuffer有什么区别呢？让我们看看它的append的方法 1234public StringBuilder append(String str) &#123; super.append(str); return this;&#125; 这里你就会方法它也是调用父类的append方法，而他们的父类又是同一个，这里不同的就是StringBuilder的append方法没有用synchronized修饰，所以它是不安全的，当然也就意味着在单线程的情况下比StringBuffer的性能是要好的，其实对于StringBuffer和StringBuilder来讲，它们都是对于AbstractStringBuilder类的实现，或许会有其他细节处理的不同，大致来讲，他们的区别就是一个是线程安全的实现，一个是线程不安全的实现，只是要你自己去权衡线程安全与性能之间的抉择 总结StringBuilder或者StringBuffer并不一定比String的效率高，在各个场景中有不同的用法而已，对于StringBuilder和StringBuffer来讲，也不是施了什么魔法，只是实现了CopyOnWrite的思想，对字符串的操作的性能更高了，应对不同情况的选择而已]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解刨单例模式]]></title>
      <url>%2F2016%2F11%2F01%2Fsingleton%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 单例模式，也叫单子模式，是一种常用的软件设计模式。在应用这个模式时，单例对象的类必须保证只有一个实例存在。许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。这种方式简化了在复杂环境下的配置管理。——来自wikipedia 单例模式大致上分为两种模式，饿汉模式和懒汉模式，在开发环境中有很多的应用，比如Spring的bean工厂就应用了单例模式来对bean进行初始化，他对类的实例进行了统一的管理，每次返回该类的唯一实例，也优化了实例化类的资源利用。 饿汉模式123456789public class HungrySingleton &#123; private final static HungrySingleton INSTANCE = new HungrySingleton(); private HungrySingleton() &#123;&#125; public static HungrySingleton getInstance() &#123; return INSTANCE; &#125;&#125; 饿汉模式指在类的实例在全局定义，利用static和final修饰，保持类的唯一性，在类装载的时候就初始化了， 因为创建实例本身是线程安全的，所以饿汉模式也是线程安全的。 但是饿汉模式的应用场景是明确类本身实例的信息，因为这是在类装载前就实例化了，无法改变，但是如果想根据上下文或者所依赖参数的变化来动态的实例化类，饿汉模式就不匹配了，于是另一种懒汉模式就登场了。 懒汉模式懒汉模式指全局的实例在第一次调用的时候才加载 简单模式123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;// 线程1 instance = new LazySingleton();// 线程2 &#125; return instance; &#125;&#125; 这是一个很简单的懒汉模式，在单线程的环境下，通过第一次检查instance是否为空来获取唯一的实例，但是在多线程的环境下，由于instance = new LazySingleton()不是一个原子性的操作，会受到其他线程的干扰，如上所示： 如果线程1在if (instance == null) {挂起，线程2在instance = new Singleton()开始执行，instance指向了一个内存空间，但是还没有开始初始化对象( 指令重排序，下面会讲到 )，线程2挂起，线程1这个时候继续，这个时候判断instance不为null，返回的只是一个空内存块(没有实例化对象)，很容易造成NullPointException， 如果线程2在instance = new Singleton()挂起，线程1在if (instance == null) {开始执行，这个时候instance还没有指向内存，instance为null，也进来进行了创建实例的步骤，线程1和线程2创建了两个实例，违背了单例的思想 所以以上两种情况表明这种简单模式是线程不安全的 单重检验锁模式（single checked locking pattern）123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static synchronized LazySingleton getInstance() &#123; if (instance == null) &#123;// single check instance = new LazySingleton(); &#125; return instance; &#125;&#125; 以上的模式是在获取实例的方法getInstance()加上同步锁synchronized来修饰，以保证线程的安全性，但是虽然保证了线程安全，但是这种暴力的同步严重影响了程序执行的性能，在执行getInstance()方法时，频繁的线程的更换调度，对于性能是一个很大的开销。 如果instance已经实例化了，对于上述模式来讲，他还是要等待前面的线程获取完实例才能获取实例，这样实现很低效，其实同步只是针对实例化对象的过程，对于已经实例化对象的instance来说，只需要返回就可以了，不需要同步。 双重检验锁模式（double checked locking pattern）1234567891011121314151617public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;//single check 线程1 synchronized (LazySingleton.class) &#123; if (instance == null) &#123;//double check instance = new LazySingleton(); //线程2 &#125; &#125; &#125; return instance; &#125;&#125; 双重检验锁模式又对单重检验锁模式进行了优化，他用两次检查来判断instance是否被实例化，同步锁只是针对instance的实例化，对于instance已经实例化的情况下，直接返回instance，不进入同步锁的代码块，大大的提高了性能 但是，又重现了简单模式的第一种情况，如上代码所示，假设线程2在实例化对象只是在instance指向了内存空间，但是还没有实例化对象(指令重排序)，这个时候线程1的instance！=null，直接返回instance，造成NullPointException，现在问题来了，什么是指令重排序？ 一般的情况下，程序运行代码是顺序运行的，但是会存在一些指令的重排序问题，比如123int a=1；int b=1；int c=a+b; 以上代码使用指令来执行，分为以下5个步骤： 对a赋值1 对b赋值1 获取a的值 获取b的值 运算a+b的值存在c的内存中 上述的五个步骤有时并不是按照顺序进行的，有时你执行步骤1对a赋值1时，就会执行步骤3获取a的值，因为他们存在数据依赖，这就是发生了指令重排(具体了解，访问 http://tech.meituan.com/java-memory-reordering.html )，对于实例化对象来讲，具体的步骤如下： 分配内存 实例化对象 引用指向内存对象 正常的情况下只有实例化了对象才会引用指向内存对象，但是如果这时发生了指令重排序，执行顺序变成了1,3,2，在执行步骤3还没有执行步骤2就执行线程1了，这个时候就会造成异常错误，这个时候就会使用volatile关键字来避免指令重排序。 volatile式模式（double checked locking pattern with ）volatile的定义是：java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 正如上所说，java线程内存模型确保所有线程看到这个变量的值是一致的就是volatile的可见性，正是因为他的可见性，要求所有线程看见该变量要一致，所以代表着volatile的另一个特性:禁止指令重排序，其实，在JDK1.5之前volatile是不能保证能够禁止指令重排序的，在JDK1.5之后才能应用于双重检查模式。 1234567891011121314151617public class LazySingleton &#123; private volatile static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;//single check synchronized(LazySingleton.class)&#123; if (instance == null) &#123;//double check instance = new LazySingleton(); &#125; &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类模式(static nested class pattern)静态内部类模式也是一种懒汉模式，他利用内部类的特性(调用时才加载）来创建实例 123456789public class LazySingleton &#123; private static class SingletonClass &#123; private static final LazySingleton INSTANCE = new LazySingleton(); &#125; private LazySingleton ()&#123;&#125; public static final LazySingleton getInstance() &#123; return SingletonClass.INSTANCE; &#125; &#125; 这种模式也能保证线程的安全性，JVM在保持类的信息的一致性，加载类的时候是线程安全的，而且不需要同步来执行getInstance()方法。 参考https://zh.wikipedia.org/wiki/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8Fhttp://tech.meituan.com/java-memory-reordering.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[动态代理]]></title>
      <url>%2F2016%2F10%2F05%2Fproxy%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 代理模式 在代理模式中,角色分配如下： Subject(1-k) : 委托对象所实现的所有接口(i&gt;=1) RealSubject : 委托对象，也就是被代理的对象 ProxySubject : 代理对象 在JDK实现的代理模式是面向接口的，不管是委托类还是代理类都应该实现相同的接口，这样才会保持行为的一致性，因为对于Client来说，它只要输出它所想要的结果，不会管你是谁实现的，所以为了减轻委托对象的压力，就必须要克隆出其他跟自己一样的帮手来帮助自己，就好像火车票代售点一样，代理对象就由此而生了。 静态代理静态代理是指在JVM执行前就把你的代理类给定义好了，例子如下： Subject 123public interface Subject &#123; public void doSomething();&#125; RealSubject 1234567public class RealSubject implements Subject&#123; @Override public void doSomething() &#123; // TODO Auto-generated method stub System.out.println("i am just do something!!!!!"); &#125;&#125; ProxySubject 12345678910public class ProxySubject implements Subject&#123; Subject realSubject = null ; @Override public void doSomething() &#123; //类似于Spring的@Before do something realSubject = new RealSubject(); realSubject.doSomething(); //类似于Spring的@After do something &#125;&#125; 由上可知，其实调用代理类(ProxySubject)和调用委托类(RealSubject)是一样的效果，等于是代理类对委托类又重新封装了一层，但是为什么要这样做呢？ 如果每次Client调用委托类来完成业务操作，那么每次委托类就得创建对象来完成业务，如果是大业务场景，消耗的内存是巨大的，这个时候，如果是代理类来实现，可以在代理类内对委托类实现缓存操作，这样就会减少很大的内存消耗。 如果你想对原生的委托类进行扩展(比如Spring中的@After和@Before的思想），你可以对委托类进行修改，但是这会影响原有已经实现的程序逻辑，如果使用代理类，在不影响原生的委托类情况下再进行逻辑的扩展，使程序变得更加健壮。 由上可知，代理类的作用使原生的委托类更加的灵活被运用，能够应付不同的不同应用场景，但是，如果委托类的一些应用方法的删减，实现接口的减少，对于代理类来说也要进行很大的修改，这样的改动有时使代理模式变得更加的复杂，变得不是那么的灵活，如果有一种代理类能够需要调用的时候才加载，不管接口的变动，代理类都会自动的更新，无需改变，那么这就是动态代理。 动态代理动态代理是在静态代理的基础上对代理类进行了优化，利用java反射的原理来创建代理类，使代理类在JVM运行时创建。 如上图所示，这个代理类会根据现有的接口数或者实现的方法动态的去创建对象，对于业务频繁更替的场景下，不需要对代理类进行频繁的更改，更加的灵活，而在java中，对于动态代理的实现，有两种方法，一种是JDK形式的实现，一种是第三方包cglib的实现形式。 JDK动态代理在JDK实现中，主要是一个类，一个接口：动态代理类Proxy和调用处理器InvocationHandler 1.Proxy Proxy是动态创建代理类的类，它主要是利用接口的信息在类加载器中动态的生成代理类，而其中主要的生成代理类的方法就是newProxyInstance方法，实现如下： 123456789101112131415161718192021222324252627public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; // 检查调用处理器是否为空，为空抛异常 if (h == null) &#123; throw new NullPointerException(); &#125; // 获得与制定类装载器和一组接口相关的代理类类型对象 Class cl = getProxyClass(loader, interfaces); // 通过反射获取构造函数对象并生成代理类实例 try &#123; Constructor cons = cl.getConstructor(constructorParams); return (Object) cons.newInstance(new Object[] &#123; h &#125;); &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString()); &#125; catch (IllegalAccessException e) &#123; throw new InternalError(e.toString()); &#125; catch (InstantiationException e) &#123; throw new InternalError(e.toString()); &#125; catch (InvocationTargetException e) &#123; throw new InternalError(e.toString()); &#125; &#125; 由上就很容易发现，这是个简单的java反射创建对象，获取Class对象，再获取构造器，最后反射成对象，这是个静态方法，所以直接类本身就可以调用了。 Proxy还有很多的实现，比如利用一个HashMap来实现对代理类的缓存，key就是接口列表，value就是代理类的对象，还有关联调用处理器的方法等等。 2.InvocationHandler InvocationHandler是调用处理器，是负责方法调用时，利用java反射机制在JVM运行时调用该方法，其中主要的方法就是invoke方法，有三个参数proxy,method,args，这是需要自己去实现的，以下是invoke方法的实现 12345public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //方法反射 Object obj = method.invoke(proxyObj, args); return obj; &#125; 3.代码实现 MyInvocationHandler 1234567891011public class MyInvocationHandler implements InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; ////类似于Spring的@Before do something //方法反射 Object obj = method.invoke(proxyObj, args); //类似于Spring的@After do something return obj; &#125;&#125; JdkProxyFactory 1234567891011public class JdkProxyFactory &#123; private Object proxyObj = null;//代理类 // 创建代理 public Object createProxy(Object targetObject,InvocationHandler myInvocationHandler) &#123; if (null != targetObject) &#123; this.proxyObj = targetObject; &#125; return Proxy.newProxyInstance(this.proxyObj.getClass().getClassLoader(), this.proxyObj.getClass().getInterfaces(), myInvocationHandler); &#125;&#125; 以上就是一个简单的JDK实现的代理类，直接用以下的代码调用就可以了 123Subject proxySubject = (Subject)new JdkProxyFactory().createProxy(new RealSubject(),new MyInvocationHandler());proxySubject.doSomething(); 当我们调用doSomething方法时，你以为是调用RealSubject对象的doSomething方法，其实是调用代理类$ProxyN(生成代理类的名称，N从1开始)的doSomething方法，他会触发该方法的调用处理器invoke方法来调用doSomething方法。 cglib动态代理CGLib是面向类的，而cglib动态代理的实现也是一个类和一个接口：Enhancer和MethodInterceptor，和JDK的Proxy和InvocationHandler职能是一样的，一个是负责创建类，一个是负责调用方法的处理 1.Enhancer Enhancer可以说是CGLib的一个字节码增强器，它的作用通过委托类的子类来实现代理类的创建，创建过程如下： 通过委托类创建它的子类，在子类中的每个方法设置回调方法，然后获取它的Class对象 利用Class对象根据GeneratorStrategy.generate方法生成代理类的字节码 通过反编译生成代理类的Class对象 再通过反射机制创建代理类的对象 2.MethodInterceptor MethodInterceptor是一个方法拦截器，它的作用就是在代理类每执行一个方法时执行拦截方法并返回，其中最主要的方法intercept实现如下 123456public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //相当于调用了代理类本身的方法 Object result = proxy.invokeSuper(obj, args); return result; &#125; CGLib实现了Fastclass机制，对代理类的方法建立了索引，把方法存储在索引中，通过方法名和它的信息就可以获取该方法，不需要进行反射来进行方法的调用。 3.代码实现 MyMethodInterceptor 1234567891011public class MyMethodInterceptor implements MethodInterceptor &#123; public Object intercept(Object obj, Method method, Object[] arg, MethodProxy proxy) throws Throwable &#123; ////类似于Spring的@Before do something //方法反射 Object object = proxy.invokeSuper(obj, arg); //类似于Spring的@After do something return object; &#125;&#125; CglibProxyFactory 12345678910111213public class CglibProxyFactory &#123; private Object proxyObj = null;//代理类 // 创建代理 public Object createProxy(Object targetObject,MethodInterceptor MyMethodInterceptor) &#123; if (null != targetObject) &#123; this.proxyObj = targetObject; &#125; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.proxyObj.class); enhancer.setCallback(MyMethodInterceptor); return enhancer.create(); &#125;&#125; 这是一段Cglib代理类的实现，调用代码如下： 12Subject proxySubject = (Subject)new CglibProxyFactory().createProxy(new RealSubject(),new MethodInterceptor());proxySubject.doSomething(); 相比于JDK代理实现，Cglib的实现更快，它的不同之处在于 Cglib代理摒除了JDK代理利用反射来调用方法(反射的效率是很低的），利用索引来实现。 Cglib代理是面向extends的，意味着一些不能继承的类无法用Cglib来实现，而JDK代理是面向implements,这方面更规范。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neo4j的导入方案]]></title>
      <url>%2F2016%2F09%2F27%2Fneo4j-import%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 概述Neo4j是一种强大的，可扩展的和高性能的图形数据库，由边，属性和节点组成，是用来描述节点与节点之间的关系，由位于美国旧金山的Neo技术公司进行开发和维护，它属于NoSql的范围内，在一些社交的项目中处理人与人或物之间的关系挥发这巨大的作用，以下列举它的一些特点 支持ACID事务 高可用性 可扩展到数十亿的节点和关系 高效且快速的遍历查询(图的遍历) 强大的结构化查询语言Cypher 导入方案如果你想选择Neo4j作为你的处理关系的数据库，首先处理的问题就是导入外部数据，将MySQL，Oracle或者PostgreSQL的关于用户的关系数据导入Neo4j中，这里有两种导入数据的方式： 1. LOAD CSVLOAD CSV是Cypher语言的指令，是将csv文件中的属性插入Neo4j中，首先先将原数据库的数据导出成csv文件，以电影信息为例，导出CSV文件如下： movies.csv：1234id,title,country,year1,Wall Street,USA,19872,The American President,USA,19953,The Shawshank Redemption,USA,1994 Neo4j提供了一个WEB端的客户端系统，利用可视化的方式展示节点与节点的关系，在上面可以利用Cypher语言对数据进行操作，代码如下：1234LOAD CSV WITH HEADERS FROM &quot;CSV地址&quot; AS csvLineMERGE (country:Country &#123; name: csvLine.country &#125;)CREATE (movie:Movie &#123; id: toInt(csvLine.id), title: csvLine.title, year:toInt(csvLine.year)&#125;)CREATE (movie)-[:MADE_IN]-&gt;(country) 上面的意思是创建country和movie节点，然后将country和movie建立MADE_IN的关系，这样就将csv的数据导入了Neo4j中了，LOAD CSV指令导入的形式只是相当于多个CRATE指令，通过繁杂的JAVA程序向硬盘写数据，所以只是适于小数据量的导入 注意：csv中属性的数据都是String类型的，Neo4j是由JAVA写的，每个属性是有类型的，所以内置了toInt这样的类型转换方法 2. neo4j-importneo4j内置了一个批量导入的脚本，存储在/BIN目录下的neo4j-import.bat,它直接在数据库存储文件目录中生成你所需创建节点和关系文件，所以它的限制也很多，第一点是导入前，还没有创建数据库，讲白了只能是第一次导入才有效，第二点是节点和关系要分开导入就是要额外进行导出存储关系的csv，第三点是如果不进行强制指定类型，每个节点(包括不同类型的节点)的id不能相同， movie.csv：1234id,title,year1,Wall Street,19872,The American President,19953,The Shawshank Redemption,1994 country.csv：1234id,name4,USA5,CHINA6,UK MADE_IN.csv：1234:START_ID,:END_ID1,42,53,6 （1）由于配置文件的默认读取的位置在import中，所以导出的csv格式的文件要存储在neo4j存储目录下的import目录（2）使用neo4j-import工具,在neo4j的bin目录下执行以下的指令1neo4j-import --into ../data/databases/graph.db --id-type string --nodes:movie ../import/movie.csv --nodes:country ../import/country.csv --relationships:MADE_IN ../import/MADE_IN.csv --multiline-fields=true --skip-bad-relationships=true --bad-tolerance=2000 这样就完成了neo4j的批量导入了，大约1000万的数据量，十几分钟就完成了 注意：在导入过程中有可能遇到如下错误（1）./data/databases/graph.db already contains a database错误，表示graph.db已经包含了一个数据库，需要将其删除才能导入（2）Duplicate input ids that would otherwise clash can be put into separate id space，表示有ID重复，按提示查询（3）panic called，so exiting表示出现特殊符号，可检查列中可含有特殊符号 –multiline-fields=true :多行导入–skip-bad-relationships=true：过滤错误的关系不导入，可以在log中查看–bad-tolerance=2000：错误的最大限制在2000个]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LRU(Least recently used-最久未使用算法)]]></title>
      <url>%2F2016%2F09%2F22%2FLeast_recently_used%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 现在的数据越来越多的被存储，对于数据库来讲，访问大数据量会变得越来越慢，于是为了提高访问的速度，将小范围区域的数据存储在一个高速缓冲存储器，以至于不会每次去读取磁盘，而是在内存中直接访问数据。内存存储的代价远远的大于磁盘存储的价值，所以缓存很小，并不能存储你所有的数据，所以你不得不保存你所认为重要的数据(使用次数较多的数据)，那就要淘汰最少使用的数据，如何从缓存中淘汰最少使用的数据，一个简单而且有效的算法，最近最少使用算法LRU. LRU原理最久未使用算法（LRU）：最久没有访问的内容作为替换对象 —– 来自wiki LRU翻译过来就是最久未使用，当缓存到达一定的阀值时，剔除掉最久未使用的数据，通俗来讲，比如一个缓存只能缓存10000条数据，10000条就是这个缓存的阀值，小于10000条时可以随意添加，一旦数据量到达了10000条时，这个时候就要删除最久未使用的数据了，以保持最大程度的使用缓存。 LRU实现LRU的实现最简单的就是单链表的实现，这里引用的就是JDK中的LinkedHashMap,它有两种形式，一个是最晚读的数据放在前面，最早读的数据放在后面，另一个就是FIFO，也就是先进先出。 晚读放前，早读放后 每次新的数据从头部开始插入，当链表缓存空间满了的时候，就从尾部对数据进行删除，如果有数据命中的话，就将该数据移动到头部。 而基于LinkedHashMap的实现有两种方法，一种就是继承LinkedHashMap的方式，叫做inheritance，一种直接使用LinkedHashMap,叫做delegation，这两种都可以实现LRU算法，而大部分功能LinkedHashMap已经实现了,但是淘汰的删除方法就需要重写了。12345678public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 这是LinkedHashMap的构造方法和删除元素的方法，默认情况下，LinkedHashMap是根据元素的添加顺序进行存储的,如果构造参数accessOrder为true的话，就会按照访问数据，最晚访问的放在最前，最早访问的放在最后。 inheritance12345678910111213public class LruInheritance&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int MAX_SIZE=100; public LruInheritance(int cacheSize) &#123; super((int) Math.ceil(cacheSize / 0.75)+1, 0.75f, true); MAX_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_SIZE; &#125;&#125; 在构造方法中，由于将负载因子设置为0.75，所以在原有容量要除以该负载因子，因为Map中的阀值是原有容量*负载因子，以此来判断是否超标。而原本LinkedHashMap删除的机制返回的都是false，所以要重写removeEldestEntry方法,如果超过当前容量就返回true，就会删除当前元素了。 delegation12345678910111213141516public class LruDelegation&lt;K, V&gt; &#123; private final int MAX_SIZE; LinkedHashMap&lt;K, V&gt; map; public LruDelegation(int cacheSize) &#123; MAX_CACHE_SIZE = cacheSize; int capacity = (int) Math.ceil(MAX_SIZE / 0.75) + 1; map = new LinkedHashMap(capacity, 0.75f, true) &#123; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_SIZE; &#125; &#125;; &#125;&#125; 在这个构造方法中，它内部就是用已经重写removeEldestEntry方法的LinkedHashMap实现的，他与inheritance不同的是，对LinkedHashMap不同使用，一个当爹使，一个当朋友使。 FIFO(先进先出)其实与第一种方式相比，对于LinkedHashMap来讲，就是accessOrder参数的变化，上面也提到，LinkedHashMap默认的是FIFO的，构造参数accessOrder默认是false的，所以与第一种相比，只要将accessOrder置为false，或者使用一个无参构造，就可以实现了。1234567final int MAX_SIZE= 100;LinkedHashMap&lt;Integer, String&gt; lru = new LinkedHashMap&lt;Integer, String&gt;() &#123; @Override protected boolean removeEldestEntry(Map.Entry&lt;Integer, String&gt; eldest) &#123; return size() &gt; MAX_SIZE; &#125;&#125;; 这种是基于单链表实现LRU缺点是：由于LinkedHashMap本身特性，所以是线程不安全的，而且命中率不高。优点是：实现起来简单，很多东西LinkedHashMap已经帮你实现了 其实多链表或者多队列的组合使用，效率和命中很更高，一个链表或队列专门用来维护命中概率（作为访问历史数据存储），另一个作为多次访问数据存储 ### 新的数据都会从历史数据的队列的头部插入,如果当前队列容量满了之后，就会从尾部淘汰，如果当前历史数据被访问多次，就会移动到正式的LRU数据队列中，然后按时间排序，当该队列满了之后，就会从尾部淘汰。多个链表或队列组合的LRU能够应该复杂的场景,能够应对不同情况，不同的淘汰机制,提高数据的命中率，同时响应的维护成本也响应的提高了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初识HTTP-1]]></title>
      <url>%2F2016%2F09%2F06%2Fmeet-http-1%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 定义HTTP译为超文本传输协议,是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）,也是基于超文本为载体在客户端和服务器端进行传输的协议。 超文本是基于超文本构建语言构建的文档，比如HTML(HyperText Markup Language 超文本标记语言)就是标准的构成超文本的语言,而传输（转移）是基于超文本的内容在客户端和服务器端进行通信。 如上图所示，这是一个简单的超文本传输的过程，]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java反射笔记(java reflection)]]></title>
      <url>%2F2016%2F09%2F04%2Fjava_reflection%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 java是一门静态语言，一般来讲，类的定义需要在JVM运行前完成，要通过JVM编译环节，才能运行在JVM上，而java反射机制使java的类定义能够在JVM运行时动态的加载，让在某些功能上更加灵活多用，根据不同的上下文来决定类的功能 Class在每一个类都有Class对象，在JVM编译的环节中，他会检查类的信息，这个时候就会获取该类的Class对象，它包含了该类的所有信息,获取Class对象有很多种方法。 获取Class对象1.利用类本身的情况下 1Class myClass = className.class; 2.利用类名的情况下 1Class myClass = Class.forName("className"); 注意：在使用类名获取Class对象时，参数名称必须是类的全称，包括包的名称，这样才能找得到 3.利用类对象的情况下 1Class myClass = new Object().getClass(); 当然，你拥有Class对象，等于你就知道该类的所有信息，包括变量，方法，修饰符，注解，甚至它的父类，实现的接口，所在包的信息，具体的方法可以参考相应的文档：http://docs.oracle.com/javase/6/docs/api/java/lang/Class.html Constructor在java中，创建实例对象是根据构造器来实现的，JVM编译环节通过Constructor来检查类中构造方法的信息，Constructor拥有构造方法所有的信息，如果我们获取了Constructor对象，也就可以反射出拥有该构造器的对象。 获取Constructor对象1.获取所有的Constructor对象 1Constructor[] constructors = myClass.getConstructors(); 2.获取指定的构造器 1Constructor constructor = myClass.getConstructor(String.class); getConstructor方法的参数是构造方法的参数的Class对象 实例化对象12Object obj = constructor.newInstance("参数值"); 相当于SimpleReflection simpleReflection = new SimpleReflection(“参数值”)，newInstance方法的参数是构造方法的参数的实例 Field在java的JVM编译环节中，通过Field来检查类变量的信息,它拥有类变量所有的信息。 获取Field对象公有(public)变量1.获取所有Field 1Field[] fields = myClass.getFields(); 2.获取指定的Field 1Field field = myClass.getField(); 私有(private)变量1.获取所有Field 1Field[] privateFields = myClass.getDeclaredFields(); 2.获取指定的Field 1Field privateField = myClass.getDeclaredField(); 获取变量属性1.获取变量名称 1String fieldName = field.getName(); 2.获取变量类型 1Class fieldType = field.getType(); set&amp;get变量公有(public)变量12Object value = field.get(new Object());field.set(new Object(), value); 私有(private)变量通常情况下，外部类是不能访问内部的私有变量的，因为在访问对象变量时，JVM会有一个反射访问检查(reflection access check),私有变量没有访问权限是不能访问的，在Field对象有一个setAccessible方法，true表示在外部对象的作用域里可以访问私有变量。 123privateField.setAccessible(true);Object value = privateField.get(new Object());privateField.set(new Object(), value); 非静态变量的Field.get()和Field.set()方法需要指定该变量所属的对象，因为每个对象里有很多相同变量，它们独自享有一块内存，如果不指定对象，就会有歧义，而对于静态变量，可以将参数设置为NULL，因为在类加载时，是先加载静态变量，后加载构造方法，所以静态变量和对象没有必要的关系。 Method在java的JVM编译环节中，通过Method来检查方法的信息,它拥有方法所有的信息。 获取Method对象公有(public)方法1.获取所有的方法1Method[] methods = myClass.getMethods(); 2.获取指定的方法1Method method = myClass.getMethod("methodName", new Class[]&#123; String.class&#125;); 私有(private)方法1.获取所有的方法1Method[] privateMethods = myClass.getDeclaredMethods(); 2.获取指定的方法1Method privateMethod = myClass.getDeclaredMethod("methodName", new Class[]&#123; String.class&#125;); 获取Method信息1.获取方法名1String methodName = method.getName(); 2.获取返回类型1Class methodType = method.getReturnType(); 3.获取参数类型1Class[] types = method.getExceptionTypes(); Method访问方法公有(public)方法1Object returnValue = method.invoke(new Object(), "方法参数列表"); 私有(private)方法原理和Field一样，在JVM反射访问检查时，通过setAccessible方法来设置私有方法的访问权限。12privateMethod.setAccessible(true);Object returnValue = privateMethod.invoke(new Object(), "方法参数列表"); 方法也有静态的，所以在invoke方法中如果是静态方法可以设置成NULL. Annotation注解在java 5才出现，它扩展了类，属性，方法，参数等，在JVM编译时，通过Annotation来检查注解的信息 类注解1.获取所有的注解1Annotation[] annotations = myClass.getAnnotations(); 2.获取指定的注解1Annotation annotation = myClass.getAnnotation(MyAnnotation.class); 方法注解1.获取所有的注解1Annotation[] annotations = method.getAnnotations(); 2.获取指定的注解1Annotation annotation = method.getAnnotation(MyAnnotation.class); 参数注解12345Annotation[][] parameterAnnotations = method.getParameterAnnotations();for(Annotation[] annotations : parameterAnnotations)&#123; for(Annotation annotation : annotations)&#123; &#125;&#125; 变量注解1.获取所有的注解1Annotation[] annotations = field.getAnnotations(); 2.获取指定的注解1Annotation annotation = field.getAnnotation(MyAnnotation.class); 访问注解信息1234if(annotation instanceof MyAnnotation)&#123; MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println("name: " + myAnnotation.name());//假设注解中有name属性，就可以这样访问了&#125; Array在java中，数组是一个很特殊的对象，它不继承于Object，它们没有Object的所有属性和方法，所以它不是有某个类实例化出来的，它是由JVM动态创建的，JVM有一个Array通过反射机制来处理数组 创建数组1String[] arrays = (int[]) Array.newInstance(String.class, 3); 相当于String[] arrays = new String(3),newInstance方法中的参数为数组的类型和大小 访问数组set(对数组赋值)12Array.set(arrays, 0, 'hello');Array.set(arrays, 1, 'world'); set方法参数为别为目标数组，数组下标，值。 get(获取数组值)1Array.get(arrays,0); get方法参数分别是目标数组，数组下标。 获取Class对象通过class属性1Class class = String[].class; 通过forName方法1Class intArray = Class.forName("[I"); “[“代表的是数组，”I”代表的是int类型(针对于基本类型)，这个是原生的数组创建，因为在JVM创建数组，类名就是”[I”。 而对于普通类型来讲，创建数组就需要明确类型：1Class intArray = Class.forName("[Ljava.lang.String;"); “[L”声明普通类型数组，”java.lang.String”表示类型(类型全称)，”;”表示结束 通过getClass方法1Class class = arrays.getClass(); 获取数组属性获取数组类型1Class type = class.getComponentType(); 参考http://ifeve.com/java-reflection/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap的死循环(HashMap infinite loop)]]></title>
      <url>%2F2016%2F08%2F28%2FHashMap_infinite_loop%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 HashMap是一个线程不安全的key-value的存储集合，也意味着它在多线程的环境中也存在很大的风险。 HashMap的存储结构： 通常来讲，HashMap是由一个数组和一个链表组成，在初始化的时候，HashMap会初始化一个数组table[],在不指定容量的情况下默认为16，负载系数为0.75，HashMap在put的时候会通过key的hash值来计算这个数组的下标，然后就把这个存储集合存储在该下标的数组中，在查找时的复杂度为O(1),然而在Hash算法中，很有可能存在不同的key算出相同的值，HashMap就会把相同的值用链表来表示，这个时候就要遍历链表了，查找复杂度为O(n) 正是由于链表的存在，在多线程的环境下，共享链表，这就会变得不安全了 什么时候链表会变得不安全呢？HashMap的容量是动态的，随着容量的增加而增量，在每次put的时候都会检查当前的容量是否满足，假设上述图片的容量为4，如果当前的容量大于4乘以0.75(负载因子)，就会创建一个4乘以2的容量的新数组，将老的数组Copy到新的数组，然后所有的值就会重新hash，也就是rehash 现在我们模拟两个线程下的rehash情况，我们有两个线程：Thread1，Thread2，我们先看看HashMap中的rehash方法transfer(). 123456789101112131415// tranfer()片段// 这是在resize()中调用的方法,resize()就是HashMap扩容的方法 for (int j = 0; j &lt; src.length; j++) &#123; Entry e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry next = e.next; //假设线程1停留在这里就挂起了,线程2登场 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125;&#125; 此时运行完Thread1： 此时Entry e是e1，Entry next = e.next中的next是next1,红色是还没有完成，指针指向步骤还没有开始。现在Thread2登场了，Thread2运行完结构如下： 发现与Thread1的情况刚好反过来了，此时Entry e是e2，Entry next = e.next中的next是next2，是的，Thread2已经完成了指针指向操作了 12345Entry next = e.next; int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next;//假设Thread2已经走了这里 这个时候Thread1要登场了，从Entry next = e.next;开始继续运行下去,此时在Thread2的影响下Thread1运行的结构已经变了 此时由于Thread2的影响，(key:2 ,value:b)已经指向了(key:1,value:a),而红线是Thread1接下来的操作,完成指针指向操作，当Thread1完成时结构如下 这个时候你就会发现圆圈内形成了一个闭环，infinite loop就形成了！！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[exports和module.exports的区别]]></title>
      <url>%2F2016%2F08%2F22%2Fexports_module.exports%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 首先得明确两个的含义 exports:首先对于本身来讲是一个变量（对象），它不是module的引用，它是{}的引用，它指向module.exports的{}模块 module.exports:首先，module是一个变量，指向一块内存，exports是module中的一个属性，存储在内存中，然后exports属性指向{}模块 内存示意图如下： 现在来看看它们在运用中的异同：12exports.bar=function()&#123;&#125;;module.exports.bar=function()&#123;&#125; 上面的两行代码，分别来暴露相同的模块，两个方式是等价的，因为他们改变的内存是暴露模块的{}，使暴露模块变成了 exports和module.exports的等价是由于他们在操作同一块内存，所以意义是一样的12exports=function()&#123;&#125;;module.exports=function()&#123;&#125; 现在我们把bar属性给去掉，这时候效果就完全不一样了 这时候exports和module.exports操作的就不是同一块内存了,exports指向了新的内存,实际上module.exports也指向了新的内存，但是nodejs中寻找的是module变量下的exports属性所指向的内存块,如果exports和module.exports操作的不是同一个内存块的话，exports就不起作用了，所以不管怎么样，使用module.exports是万无一失的。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker学习笔记]]></title>
      <url>%2F2016%2F07%2F07%2Fdocker%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 什么是dockerdocker是基于linux内核（涉及cgroup，namespace，以及 AUFS 类的 Union FS 等技术），由go语言开发的，实际上是linux的一个独立和被隔离的进程，也可以称之为容器，其中含义如上鲸鱼船的图标（docker的图标）一样形象，鲸鱼船就像是linux一样，船本身相当于内核，船上可以载重的空间相当于文件存储系统，而在船上的箱子就是docker，他只是运行在linux内核上，箱子内部的空间相当于小型的文件存储系统，自成一体，不会受到外部空间（宿主）的影响，可以随时搬到另一艘船(内核)进行运输 docker和传统虚拟机的区别docker属于一种轻量级的虚拟机，那它比传统的虚拟机相比有什么区别 由上图可知，传统的虚拟机运行了一个完整的Guest OS(操作系统)，通过虚拟技术运行在宿主上，而docker上没有运行一个完整的操作系统，它只是一个容器，由docker引擎运行在宿主上，本质上来讲传统的虚拟机是在宿主之上虚拟出一套硬件，独立运行，而docker是直接运行在宿主的内核上，共享硬件资源，所以它的优势很明显 资源利用上更高效(接近宿主) 运行速度高(不需要另外一个完整的操作系统) 可移植性高(共享内核，可以在其他的宿主上运行) 安装docker支持很多主流平台的安装，包括windows，mac，linux各大发行版，在官网上写的很详细，这里说安装的一些注意点 docker对于安装环境有两个很重要的要求 宿主是linux的64位系统 宿主的内核版本不能低于3.10 如果不是linux64位的系统，那只有更换成64位的，内核版本可以通过uname -rshell命令查看你系统的内核版本，如果内核版本过低，通过sudo apt-get install -y --install-recommends linux-generic-lts-xenialshell命令去升级内核，这样就可以开始docker的安装了 如果在使用脚本安装的时候出错，可能是由于国内的防火墙的原因，可以使用国内云服务提供的修改版本 阿里云版本：1curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - DaoCloud版本：1curl -sSL https://get.daocloud.io/docker | sh 如果你的系统内核缺少AUFS内核驱动（这是docker最佳实践的内核）的话，可执行以下指令安装1sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual 如果官网的GPG密钥地址无法识别，可以执行如下指定进行安装 12sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 如果你已经安装好了docker引擎，进行docker服务的启动，linux旧版本(CentOS 7之前，Ubuntu 12.04/14.04,Debian 7 Wheezy)的启动方式： 1sudo service docker start 如果是高版本(CentOS 7之后，Ubuntu 16.04,Debian 8 Jessie/Stretch)的启动方式：12sudo systemctl enable dockersudo systemctl start docker docker核心：镜像，容器，仓库开始docker的第一个例子hello world 1docker run hello-world 以上指令是运行一个名为‘hello-world’的镜像，分解成下面的操作 运行完成会生成一个容器，利用docker ps 指令就可以查询你所生成的容器 由上可知，运行hello-world镜像可以分解成两步： 从本地镜像库查找，如果匹配则运行 如果本地镜像库没有找到，则会从官方维护的镜像库开始查找进行，如果匹配则运行，不匹配则报错 上面无论是本地镜像库，还是官方镜像库都是存储镜像的仓库，其实对于镜像，容器和仓库这三者，如果基于JAVA这种面向对象的语言来理解，镜像相当于一个声明类，而容器相当于一个实例对象，仓库就是JDK,而docker引擎就是等于JVM，当然这不是很严谨，但是很形象 镜像镜像是docker一个很重要的组件，通过docker images指令来查看所有的镜像，如下图所示 由上可知，镜像由五个属性组成： REPOSITORY：镜像实体，一般来讲名为‘hello-world’此类镜像是有官方维护的，‘andy/hello-world’此类镜像是由用户维护的，andy是用户名 TAG：标签，对于软件而言，理解也可以成版本，laster表示是该镜像的最终版本 IMAGE ID：镜像的唯一标识 CREATED：指镜像的创建时间 VIRTUAL SIZE：虚拟大小，并不是实际的大小，跟docker的分层存储有关 利用docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt;命令来加载镜像，如果没有Docker Registry地址，则默认会加载官方的镜像，标签如果没有指定，则默认下载laster版本 也可以利用docker rmi &lt;IMAGE ID&gt;指令去删除指定的镜像，也可以使用docker rmi $(docker iamges -q)去删除所有的镜像 容器简单的说，容器是一组独立运行的应用，由docker引擎提供它的上下文，镜像提供内容，利用docker run 指令可以新建和运行容器，如下图所示 利用docker ps -a指令来查看你所有的容器，如下图所示 由上可知，容器由七项属性组成 CONTAINER ID：容器唯一标识 IMAGE：所依赖的镜像 COMMAND：运行容器的命令 CREATE：容器的创建时间 STATUS：容器的状态 PORTS：所暴露的端口 NAMES：容器名 利用docker stop &lt;container id&gt; 指令停止指定容器运行，也可以使用docker stop $(docker ps -a)停止所有的容器如果你想启动它，可以利用docker start &lt;container id&gt;命令，如果你还想重新启动，可以利用docker restart &lt;container id&gt;,如果你想删除一个容器,可以使用docker rm &lt;container id&gt;，这跟删除镜像有点相似，rm指令是删除容器的，rmi指令是删除镜像的 仓库仓库是存放镜像的地方，官方维护了一个类似于github的dockerhub公共仓库来存放镜像，它的设计思想跟github很像，在这里你可以托管你的镜像，你可以点击dockerhub注册一个dockerhub的账户，然后在终端利用docker login命令输入你的用户名，密码和邮箱进行登录，在本地用户目录就会生成一个.dockercfg文件来保存用户信息，可以利用docker search &lt;image&gt;命令查询你所要镜像的信息，如下图所示 由上可知，你所查询的该镜像在公共仓库的信息，以下五项组成 NAME：相关镜像的名称 DESCRIPTION：相关镜像的描述 STARS：喜欢程度，表示该镜像的受欢迎程度 OFFICIAL：是否是官方的镜像 AUTOMATED：是否是自动创建的镜像 然后使用docker pull &lt;image&gt;命令加载公共仓库的镜像到本地，当然如果想要将自己的镜像推送到公共仓库上只需要两步 将你自己的镜像打上标签：docker tag &lt;IMAGE ID&gt; &lt;USERNAME&gt;/&lt;IAMGE NAME&gt;:&lt;TAG&gt;. 推送到公共仓库：docker push &lt;USERNAME&gt;/&lt;REPOSITORY&gt;. 自定义镜像：dockerfile现实中，官方的镜像是根本不能满足我们的需求的，所以我们需要自己去自定义镜像，首先我们需要创建dockerfile文件 123mkdir myimagecd myimagetouch Dockerfile 现在可以开始来构建一条鲸鱼的镜像，首先用文本编辑器打开Dockerfile，编辑以下内容123FROM docker/whalesay:latestRUN apt-get -y update &amp;&amp; apt-get install -y fortunesCMD /usr/games/fortune -a | cowsay Dockerfile内容一条指令会加载一层镜像，以下会分成三步执行 加载鲸鱼的镜像 更新软件源，并下载安装fortunes应用 运行这个应用 现在在该目录下利用docker build -t docker-whale .指令就完成了自己的镜像构建了，这里要注意一点，在构建的时候，镜像名后会跟随一个.，这个往往会被忽略掉，这表示运行该镜像的上下文，不是Dockerfile文件的位置，Dockerfile里所运行的上下文都是基于这个定义的，你自己也可以定义你想要的上下文，比如使用/usr/local替换.最后使用docker run docker-whale指令运行该镜像，如下图所示： 这就是一个基于官网的例子的自定义镜像，自定义镜像让docker更加灵活，更加强大，让就像编程一样，拥有无限魔力 这里列举自定义镜像最佳实践和建议 Dockerfile的定义尽量是简短的，合理而又简短的配置，一站化停止和销毁 每个Dockerfile目录尽量只有Dockerfile文件，如果有其他文件，在构建的时候，可以新建一个.dockerignore的文件到该目录进行排除其他不必要的文件 尽量避免安装不必要的包，即使他是很有用的 多数情况下，一个容器只是运行一个进程，这样能够更容易扩展和重复使用(使用容器连接) 减少构建层数来减少构建的复杂度，使用‘\’和连接符‘&amp;&amp;’来进行一次性构建 这里再列举一些常用的Dockerfile指令 LABEL记录你的Dockerfile的信息 比如：LABEL version=”0.0.1-beta” RUN运行你的应用程序或者是指令 比如：RUN apt-get update &amp;&amp; apt-get install -y curl注意：如果以上命令分成两层写，会导致获取缓存内以前的版本，导致安装无效 CMD运行该镜像包含的软件 比如：CMD [“sh”,”-s”“server tomcat start”] ENTRYPOINT运行你的应用程序和指令，或者是脚本 ENTRYPOINT [“server”]注意：如果指定了ENTRYPOINT，那么后面的CMD都变成了它的参数 EXPOSE指定该容器所监听连接的默认端口，如果docker run -p指定端口，则会覆盖该端口，比如EXPOSE 8080 ENV更新或添加你当前容器的环境变量 比如：ENV PATH /user/local/nginx/bin:$PATH ARG构建临时的环境变量，在容器运行时不会存储这些环境变量 比如：ARG NAME [=jack] COPY本地文件复制到容器 比如：COPY usr/local/ /usr/local/ ADD也有复制的功能，但在其上多了远程url下载，和自动解压包的功能 比如：ADD http://source.com/a.tar /usr/local (先下载url的资源，再解压到目标目录中)注意：推荐使用COPY，因为他的目标更明确，ADD相当于使用了多层的RUN，还不如使用RUN加连接符 VOLUME指定数据存储区，使容器和宿主进行映射存储 比如：VOLUME /data 然后使用docker run -dv mydata:/data 命令指定宿主的mydata作为容器中data目录的存储区 WORKDIR指定当前目录(目录必须存在，应使用绝对路径)，比如： WORKDIR /usr/local/ USER指定当前用户 比如：USER docker ONBUILD指定当前的镜像后面的指令不会马上构建，只有在别的镜像引用时才构建加载，适合一些基础的组件构建 总结：这是一篇docker的学习笔记，docker很强大，特别在云服务平台发挥很大的重要，现在在很多集群管理也使用docker来构建，学习docker也会有很大的提升。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[原子操作-CAS]]></title>
      <url>%2F2016%2F06%2F06%2Fcas%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 概念CAS(compare and swap)，比较和交换，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值—来自wikipedia 现代的大多数CPU都实现了CAS,它是一种无锁(lock-free),且非阻塞的一种算法，保持数据的一致性，原理并不难理解，下面是一段CAS的简单实现： 1234567891011121314public boolean cas(int old_v)&#123; for(;;)&#123; int new_v = old_v+1; int except_v = getMemoryValue(); if(expect_v == old_v)&#123; setMemoryValue(new_v); break; &#125;else&#123; old_v = except_v; &#125; &#125; return true;&#125; 其中getMemoryValue()方法指在内存中取出最新的值，setMemoryValue(new_v)方法指在讲新的值放入内存中，整个if-else就是CAS的操作（expect_v==old_v是compare，而setMemoryValue(new_v)是swap），假设有两个线程访问以上代码，用分段图表示如下： 以上图就是CAS的操作表现，由此可知，在CAS中，有三个核心的属性：old_i(旧值)，new_i(新值)，expect_i(期望值)，它每次通过旧值通过计算得到新值，然后利用旧值与期望值(从内存读取的最新的值)相比较，如果相同，就将新值写入内存中替换期望值，如果不相同，则表示操作失败，重新执行。 ABA问题CAS并不是一个完美的无锁算法，在以上的CAS操作中，getMemoryValue()方法只是在内存中取出最新的值，它不会在乎它的变化，如下图所示 如上图所示，如果线程2期间发生了两次变化，线程1是察觉不到的，经典的例子就是堆的pop和push，线程1入栈时，top的值是A，然后线程2进行了两次入堆，第二次入栈的值也是A，线程1对top进行compare，发现和旧值是一样的，就执行入堆操作，其实这时堆已经发生了改变当然如果想要解决这个问题，只有加上一个标志或者版本号来监视它的变化，这样由两个值来最为compare的根据，如还是堆的pop和push问题，只要加上一个操作标志，当每次对进行pop或者push就加1，那compare的时候再加上对原来的改变次数和现在的改变次数进行比较，这样就可以避免ABA问题了 应用乐观锁乐观锁是在最理想的情况下去执行，只有在发生冲突的时候再进行处理，其实这跟CAS的理念是很符合的，也可以这么讲，CAS也是一种乐观锁技术 JAVAjava中实现了大量的CAS操作，在JDK1.5发布的java.util.concurrent包就是建立在CAS之上的，相对比与synchronized这种锁机制且阻塞的算法，无锁且非阻塞的CAS无疑在性能上有质的提升，来看看java对CAS的实现，以AtomicInteger的增量方法为例(基于JDK1.8)123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 这里会调用sun.misc包下的Unsafe类，这是一个调用底层指令集的final类，下面看一下getAndAddInt方法12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 在这里你会看见compareAndSwapInt方法，这是一个native的方法，用来调用CPU的CAS指令实现无锁且非阻塞的增量操作，这在concurrent包下有很多这样的操作，JDK1.8的concurrentHashMap放弃了分段锁的概念，采用了CAS操作，这大大的增加了多线程下的性能 总结很多时候在线程安全和性能方面很难得到权衡，线程安全的两大特性：可见性和原子性，原子性往往就要加上锁去实现，现在用CAS去替代原子性，volatile保证可见性，大大增加了多线程在操作上的性能 参考https://zh.wikipedia.org/wiki/%E6%AF%94%E8%BE%83%E5%B9%B6%E4%BA%A4%E6%8D%A2http://zl198751.iteye.com/blog/1848575]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库索引]]></title>
      <url>%2F2016%2F05%2F12%2Fdatabase_index%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 索引概述 索引（英语：Index）：又稱引得，通檢，備檢，是一本书籍的重要组成部分，它把书中的重要名词列罗列出来，并给出它们相应的页码，方便读者快速查找该名 词的定义和含义—-来自维基百科。 数据库索引：是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据——来自维基百科。 索引很普遍，也很方便，他能使人能更好更快的找到自己想要的东西，在生活中也都能有很好的应用，比如一些书籍目录，指示牌，门牌号，而下面讲到的是在数据库中的应用。 数据库索引二叉树查找树要知道数据库索引之前，必须知道一种数据结构二叉查找树 二叉查找树是一种特殊的二叉树，必须要符合一定的结构规则： 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 如上图所示可知，我们这颗二叉查找树一共有7个节点，比如我们现在要搜索122这个节点，从根节点100开始遍历： 由于100&lt;122，所以我们需要查找根节点的右节点150 由于122&lt;150，所以我们现在需要查找它的左节点122 由于122==122，返回当前的节点(如果122节点绑定了当前数据库的信息，我们就可以通过索引来查找数据了) 二叉查找树是根据查找的层数来决定你的查找效率，当然最坏的查找效率也就O(n),但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(log n),如SBT,AVL树，红黑树等。 其实在这里你就能够想象到在数据库中使用索引的查找时的整个结构过程，以上我们会发现，二叉搜索树太依赖搜索的层数，数据太多也意味着层数也会增加，查询的效率也会相应的下降，面对百万级，甚至亿级的查询时，分分钟崩溃，而且你也会发现二叉搜索树应对的是单值查询（where p=2），在范围查询（where 1&lt;p&lt;3）中就捉襟见肘了（要遍历很多次），其实在单值查询中还有一种索引结构叫做哈希表 哈希表哈希表（Hash table，也叫散列表），是根据键（Key）而直接访问在内存存储位置的数据结构。 也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。 这个映射函数称做散列函数，存放记录的数组称做散列表。—-来自维基百科 其实在数据库中一些简单常见的连接操作叫做hash连接，这个数据结构也被数据库用来保存一些内部的东西（比如锁表或者缓冲池） 哈希表的定义： 关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。 关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。 由图可知，这个Hash table中有0-9十个哈希桶，我们想象成是一个数组（以0-9下标组成）,比如你所要查找的关键字通过哈希函数对10去模，保留整数有效位最后一位，用它利用比较函数（比如equals）来定位哈希桶的位置： 如果元素最后一位是 0，则进入哈希桶0， 如果元素最后一位是 1，则进入哈希桶1， 如果元素最后一位是 2，则进入哈希桶2 。依次类推 比方说你要找元素 78： 哈希表计算 78 的哈希码，等于 8。 查找哈希桶 8，找到的第一个元素是 78。 返回元素 78 查询仅耗费了 2 次运算（1次计算哈希值，另一次在哈希桶中查找元素）。 现在，比方说你要找元素 59： 哈希表计算 59 的哈希码，等于9。 查找哈希桶 9，第一个找到的元素是 99。因为 99 不等于 59， 那么 99 不是正确的元素。 用同样的逻辑，查找第二个元素(9)，第三个(79)，……，最后一个(29)。 元素不存在。 搜索耗费了 7 次运算其实由上可知，只要你的哈希函数与哈希桶定义的越好，查找的效率也就相应的越高。 B-Tree以上的关于查找的数据结构都不能满足现在日新月异的数据库了，在二叉树搜索树的基础上，又演变出一种新的数据结构B-Tree B树（英语：B-tree）是一种自平衡的树，能够保持数据有序。这种资料结构能够让查找数据，顺序访问，插入数据及删除的动作，都在对数时间内完成—-来自维基百科 一颗m阶的B-Tree规则如下： 树中每个结点至多有m个孩子； 除根结点和叶子结点外，其它每个结点至少有m/2个孩子； 若根结点不是叶子结点，则至少有2个孩子； 所有叶子结点(失败节点)都出现在同一层，叶子结点不包含任何关键字信息； 所有非终端结点中包含下列信息数据 ( n, A0 , K1 , A1 , K2 , A2 , … , Kn , An )，其中： Ki (i=1,…,n)为关键字，且Ki &lt; Ki+1 , Ai (i=0,…,n)为指向子树根结点的指针, n为关键字的个数 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 相对于二叉搜索树而言，B-Tree在每个节点中最少都得有两个孩子，优化了二叉搜索树过于依赖层数，使其更加灵活，然而相应的维护成本大大的增高。 如上图所示，比方说你要查找节点21,从根节点开始遍历： 在根节点中，由于节点21满足20&lt;21&lt;30,所以指针指向了P2 在P2中，节点21满足21&lt;22,但是指针没有指向任何地址，所以返回NULL 又比方说要查找节点88，从根节点开始遍历 在根节点中，由于节点88满足30&lt;80,所以指针指向P3 在P3中，节点88满足88&gt;62,所以指针指向P7 在P7中，节点88满足88==88，所以返回P7中的88节点 由于B-Tree的索引结构文件和表数据存储文件不是连在一起的，访问数据也有额外消耗了 由上你可以发现这种结构还是不能高效解决范围查询的场景，当出现范围查询（where 1&lt;p&lt;3）,B-Tree还是得一遍一遍的从根节点开始遍历，再一次一次进行磁盘IO（因为索引文件存储在磁盘上，而磁盘操作是物理操作，非常耗时的，所以磁盘IO是数据库查询的一个瓶颈，后面的B+Tree正好优化了这一点）。 B+Tree B+ 树是一种树数据结构，通常用于数据库和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反——来自维基百科 在一个B+树里结构： 只有最底层的节点（叶子节点）才保存信息（相关表的行位置） 其它节点只是在搜索中用来指引到正确节点的 所有的叶子节点都带有关键字直至底层节点 B+树是B树的进化体,他从磁盘IO上对原有的结构进行了优化,以至于减少对磁盘的IO（上面也提到，磁盘IO是物理操作，这对磁盘来说是很耗时间的），大大的增加了搜索的效率。 上面也提到，B树对于范围查询来讲是比较吃力的，不能高效的满足它的需求，因为范围查询（where 1&lt;p&lt;3）正常情况下在B树上要遍历两或者三遍（每次从根节点遍历），意味着要至少进行两三次的磁盘IO，这对于大数据量查询来讲是很吃力的。 B+树是怎么样进行减少磁盘IO的优化呢？我们先来看看一个范围查询在索引是怎么遍历的。 我们假设一个范围查询：where 10&lt;p&lt;50 在根节点中，满足5&lt;10&lt;58,所以指针指向P1节点 在P1节点中，满足5&lt;10&lt;30,所以指针指向P2节点 在P2底层节点中，每个节点都带有关键字，且每个节点之间相互链接，可以从一个节点遍历到另一个节点，且都是顺序的，所以，在大于或等于10的节点开始遍历，一直遍历到小于等于50为止 由上可知，在底层节点都是互相连接的，遍历中间的值就是查询的结果，而且B+树的表数据和索引文件是存储在一起的，所以遍历的就是表的行数据，这样只要一次IO就完成了。 参考http://coding-geek.com/how-databases-work/http://blog.csdn.net/v_july_v/article/details/6530142]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo搭建github博客]]></title>
      <url>%2F2016%2F05%2F11%2Fset_up_github_blog_with_hexo%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 安装环境 由于hexo是基于node.js的一个博客框架，所以在安装hexo之前，先安装node.js，点击node.js进入官网进行安装即可 当然还要安装基于github的deploy工具git，点击git，进入官网进行安装即可 以上安装完成时，在你的博客磁盘区域新建一个hexo文件夹，进入hexo文件夹，右键点击Git Bash Here，就会进入git的交互环境，安装hexo环境只需三个指令 123$ npm install hexo-cli -g$ hexo init$ hexo g 依次完成以上的指令，就完成了hexo的安装，现在我们启动服务，输入1$ hexo s 即可以启动hexo服务，根据提示在浏览器输入 http://localhost:4000/ 就可以查看你博客了 当然这里有一些常用命令做参考： hexo new “postName” # 新建文章 hexo new page “pageName” # 新建页面 hexo generate # 生成public目录 hexo server # 启动服务 hexo deploy # 部署到github hexo help # 查看帮助 hexo version # 查看Hexo的版本 选择主题在 http://localhost:4000/ 看到的是hexo默认的博客主题，如果你想要别的主题，点击 https://hexo.io/themes/ 就可以查看了hexo的主题大全。我使用的Random主题，他符合以下人群： 喜欢用大图做背景 不喜欢文章摘要 不喜欢在文章列表中翻页 如果你也喜欢Random主题，接下来简单的介绍它的安装，安装Random只需两个指令就可以完成，还是在/hexo目录下运行下面的指令1$ git clone https://github.com/stiekel/hexo-theme-random.git themes/random 这样主题就下载好了,现在打开 hexo/_config.yml (_config.yml文件有两个，一个在hexo的根目录下，一个在你的主题文件夹的根目录下)，找到theme属性，将主题设为random1theme: random 这里要注意一点，yaml配置文件的属性冒号之后要有一个空格，然后是值，否则将读取不到你的值然后再重启服务12$ hexo clean$ hexo s 这样就可以查看Random主题的效果了，当然了还有其他配置，比如配置他的tags，categories，about，还有你的社交网站的链接的配置，你可以访问的他的中文文档 http://hexo-theme-random.herokuapp.com/2016/05/23/Hexo-theme-Random-Chinese-User-Guide/ 这里面可以很全面的去配置random主题的博客。 github部署如果你想把你的本地的静态博客部署到线上，github是一个很好的选择，它是一个代码托管工具，由于还支持markdown这样的文本编辑格式，所以也可以算是博客的托管工具，我们可以把我们的博客托管到github上，就可以通过浏览器的url访问了。 如果你没有github的账号，你可以点击 https://github.com/ ，根据它的提示注册账号和配置shh，也可以网上搜索github如何使用，如果你有github账号,接下来就是创建博客的仓库。 创建仓库首先你先在github的repositores页面点击右上角的new按钮，来新建一个仓库，然后在Repository name一栏，写上yourname.github.io (yourname指你的用户名)，然后点击create repository按钮进行创建。 配置_config.yml在hexo根目录下的_config.yml找到 deploy: 处，设置你自己的发布信息1234567deploy: #类型为git type: git #填写你仓库的地址 repository: https://github.com/yourname/yourname.github.io.git #根据你自己的分支情况，如果没有其他分支，一般为主分支 branch: master 注意：在前面也提到，每个属性后面的值前面一定要有个空格，比如 type:(空格)git 发布现在就是将你本地的静态博客发布到github上12$ hexo clean$ hexo d -g 注意，如果你的hexo是5.0以上或者出现 error deployer not found 错误 ，那就必须先安装 hexo-deployer-git 1npm install hexo-deployer-git --save 命令 git d -g相当于git g再git d，命令完成之后只需输入你的用户名和密码完成验证即可，发布完成，打开浏览器，输入 http://yourname.github.io 就可以查看你的博客了。 域名管理当然如果你不喜欢github的子域名来访问你的博客，这个时候，你就得自己创建域名了 域名的供应商很多，不过国内外最有名的就是 godaddy 了，狗爹是目前号称最大的域名注册商，当然各种服务也是挺好的，当然还有中国的 万维网 ，不过还是推荐狗爹，这里域名注册我就不介绍了，你只需按照网站步骤就可以了 不过得注意狗爹上很多域名产品是有优惠的，你只需google或者百度godaddy优惠码就会有很多的，可以一一去试，还是能够省一点的，对于国内来讲，优惠码一定要看准是否支持支付宝支付，因为有些优惠码不支持支付宝，当然如果你有国外的信用卡或者银联就另当别论了。 CNAME想要你的域名访问你的github的仓库，就必须要创建CNAME文件,CNAME文件创建有两种方法： 第一种直接在你的仓库的根目录下直接创建CNAME文件，内容为你域名的名称，比如 1pettyandydog.com 第二种在 /hexo/source/ 目录下创建CNAME文件( 推荐 )，内容相同，然后再重新发布 DNS配置如果你已经注册号域名了，接下来就是dns配置了，dns配置有两种 第一种用是godaddy自己的dns解释器，打开godaddy的账户/产品，点击当前域名下的DNS管理按钮，配置如下 第二种使用DNSpod域名DNS代理,注册DNSpod，进入DNSpod管理，添加你自己的域名，一样按上图添加记录，然后将godaddy的nameservers界面增加两条记录 这样就大功告成，输入你的网站 ( 比如：http://pettyandydog.com ) 就可以访问你的博客了,有时候可能短时间访问不了，只需等上一段时间就可以了。]]></content>
    </entry>

    
  
  
</search>
