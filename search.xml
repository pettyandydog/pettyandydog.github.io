<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[深入了解HTTP协议]]></title>
      <url>%2F2017%2F08%2F28%2Fhttp%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言HTTP是超文本传输协议（HyperText Transfer Protocol）的缩写，是一种用于分布式、协作式和超媒体信息系统的应用层协议，也是万维网的数据通信的基础，设计最初的目的是为了统一发布和接收HTML页面的标准，由统一资源标识符（Uniform Resource Identifiers，URI）来标识 注意：统一资源标识符的英文缩写是uri，并不是统一资源定位符（uniform resource locator）url，从名称可见，uri是标识资源信息的，url是定位资源位置的，资源位置也是资源信息中的一种，所以url是uri的子集，比如http://pettyandydog.com 是一个url，也可以说是一个uri，但是http://andy:123@pettyandydog.com 就不是一个url，而是uri，因为包含了资源的认证信息 HTTP经历了多个版本的迭代，从最开始，也是最简单的，还没有版本的概念，后来统称为：HTTP/0.9版本，到后来形成可扩展的标准化协议，下面就是HTTP各个版本的变迁： HTTP/0.9HTTP/0.9版本很简单，一个请求由一个单行的指令组成，只接受GET一种请求方法，没有HTTP头和状态码，如果请求过程中出现了任何问题很难定位原因，很有局限性 HTTP/1.0为了解决HTTP/0.9版本的局限性，引入了HTTP头和状态码，并且根据不同的场景增加了其他的请求方法，能够传输更多的文档类型，大大的提升了灵活性 HTTP/1.1目前使用最广泛的HTTP版本，并且在HTTP/1.0版本的基础上做了很多的优化，比如持久化连接，单IP多域名（Host），以及增加Range和Content-Range头域和100(contiune)状态来节约带宽和完善缓存机制等等 HTTP/2.0HTTP/2.0兼容HTTP/1.1的基础上，采用了二进制的方式来优化传输的效率，连接方式上采用了多路复用，就是单个连接同时可以处理多个请求，他消除了一些相似请求的重复操作，虽然HTTP/2.0还没有被广泛的使用，但是前途一片光明 HTTP现在在浏览器请求http://pettyandydog.com 为例，先看一下客户端到服务端请求的方式 上述的网络通讯是基于利用TCP/IP协议族完成的，发送端的客户端在应用层发送了一个HTTP请求http://pettyandydog.com ，封装成一个请求报文，然后经过传输层，TCP协议把HTTP的报文进行分割，并在各个报文打上标记序号和端口号发送给网络层，在网络层的IP协议就负责将目的地的MAC地址转发给链路层，在目标地址的链路层接收到数据，再一层层解析，直到应用层， 这就是一个完整的HTTP请求的过程 HTTP报文HTTP的报文分为请求报文和响应报文，如上图所示就是请求报文和相应报文的结构，都是由报文首部+空行+报文主体（不一定存在）组成，而报文首部又由请求行，状态行和四种首部以及其它（HTTP的RFC规范未定义的首部，比如cookie）构成，接下分别介绍请求报文和响应报文的首部字段 请求报文在上述HTTP请求的过程中，客户端在应用层会对HTTP报文进行封装，而这封装的HTTP报文就是请求报文，接下来看下请求http://pettyandydog.com 的首部字段（来自chrome console ） Apccept：上图就是HTTP的请求首部字段，前三行以Apccept开头的表示客户端和服务端协商的内容规范， Accept表示客户端希望接收服务端的MIME格式的资源，比如text/html表示希望接收的是html类型，application/xml表示希望接收的是xml类型，Accept-Encoding表示希望接收的编码格式，在客户端和服务端通信过程中，会对文本内容进行编码来优化传输效率，也就是数据压缩，gzip和deflate就是常用的压缩算法，Accept-Language表示希望接收的语言，按先后顺序，中国当然是首选zh-CN，除了上图的三种Accept开头的首部，还有Accept-Charset表示字符编码等等 Cookie：指保存在客户端数据标识，当服务器接收请求之后，会在响应首部Set-Cookie设置cookie存储数据，并设置过期时间，域，路径来维护cookie的生命周期，之后发送的请求都会携带cookie首部到服务端，比如最常见的登录操作就会利用这个首部 Host：是HTTP/1.1新增的首部，它是解决一IP多域名的问题，由于在一台机器上可以装有多个虚拟机，所以会存在多个域名端口，而Host就是标识是哪个域名端口的请求 If-Modified-Since：表示是请求的资源在缓存中更改的时间，是用于缓存检验，他对应着响应首部Last-Modified（表示服务端资源最后更改的时间），当首次请求的响应首部中含有Last-Modified返回，当再次访问该资源，Last-Modified的时间会赋给If-Modified-Since首部传送给服务器进行校验，如果服务器资源修改时间与之相同表示资源未被修改，使用当前资源缓存，返回304状态码，如果服务器资源的时间在这之后，表示已经修改过了，重新获取资源，返回200状态码，其实If-Modified-Since和Last-Modified这种组合的缓存校验是一种弱校验，他们只是精确到秒级，如果多个请求在单秒内请求同一资源，一个请求对其资源进行了修改，另外一个请求获取的资源由于都是在秒内响应，所以比较时间会表示没有更改，直接获取之前资源副本，所以在很多高并发级别的场景下并不准确，这个时候就有另外一个组合请求首部If-None-Match和响应首部Etag，如果If-Modified-Since和If-None-Match同时出现在请求首部时，会优先使用If-None-Match，他是通过版本号来区分资源，比较两个资源的字节，全部相同才认为是一致的，相对于If-None-Match和Etag组合来说，这是属于一个弱比较算法，因为还有一个因素就是时间，如果该资源被修改成另一个资源，后来又修改回来，虽然内容是一致的，但是从时间上来说是不同的资源了，这类似原子操作CAS的ABA问题，所以有另外一个请求首部字段和Etag组合，就是If-Match,这个组合通常搭配请求首部Range（后面会讲到）用于范围请求资源 Proxy-Connection：该首部源于早期超文本传输协议版本实现中的错误。与标准的连接（Connection）字段的功能完全相同,主要是用于管理网络连接，在HTTP/1.0版本中，默认的连接是短连接（Connection：close），每一个HTTP请求时都会建立TCP连接-三次握手，到HTTP请求完成之后会关闭TCP连接-四次挥手，如果在一定时间内请求多次，这样频繁的连接关闭其实很耗时的，所以到HTTP/1.1版本出现了长连接（Connection：Keep-Alive），也是现在最常用的，他会让一个连接保持一段时间，这样可以重复的利用该连接，但是如果这段时间内没有连接也会占用资源，这样频繁的话会很浪费资源，且长连接只是解决了资源重复利用，对于HTTP的连接来说是顺序的，下一个请求必须要等待上一个执行完成，如果他们可以并行的话可以大大的提升请求的效率，这就是HTTP Pipeining但是大多数的浏览器并不支持HTTP Pipeining，所以在HTTP/2.0版本中，有一种更好的连接方式代替了HTTP Pipeining，那就是multiplexing-多路复用，单个进程就可以实现多个连接并行执行，在现在很多的 IO通信中都用这种模型 Upgrade-Insecure-Request：这是客户端向服务端发送一个信号，表示可以接受升级机制的资源，比如http过渡到https时可以访问该资源 User-Agent：标识客户端的身份，包含应用系统，软件开发商，以及版本号等等 除了上述用到的请求首部之外，还有比较常用的比如range首部，用于范围请求，通常会用于断点续传的下载功能，对于一些较大的文件的资源访问时，range会规范请求的字节范围，请求成功会响应206 Partial Content状态码表示处理了范围请求，如果请求首部没有声明Accept-Range或者值为none，表示不支持范围请求，返回200 ok状态吗，如果请求的字节大小大于资源的大小则会返回 416 Requested Range Not Satisfiable 无法满足范围请求，或者使用If-Range请求首部说明范围请求的条件 响应报文在发送HTTP请求给服务端，服务端会对HTTP请求进行处理并且返回处理结果给客户端，而这个处理结果会被封装成一个HTTP报文进行传输，这就是响应报文，下面是响应http://pettyandydog.com 请求的首部字段 Access-Control-Allow-Origin：这个是针对CORS跨域请求设置的，指定哪些网站可参与到跨来源资源共享过程中，在一台机器上可能存在很多的域，不同的端口，它们之间的通信需要达成某种共识，*代表可以接收任何域，除了Access-Control-Allow-Origin，还有其他Access-Control开头的响应字段来控制请求参数，比如Access-Control-Allow-Methods表示可以接收请求的方法（GET,POST,PUT…），Access-Control-Allow-Headers表示可以接收的请求首部（基本的比如Accept开头的首部，Content-Type等等） Cache-Control：控制服务端向客户端所有的缓存机制来缓存这个响应对象，有六种控制方式来设置缓存策略 Cache-directive 说明 public 所有内容都将被缓存(客户端和代理服务器都可缓存) private 内容只缓存到私有缓存中(仅客户端可以缓存，代理服务器不可缓存) no-cache 必须先与服务器确认返回的响应是否被更改，然后才能使用该响应来满足后续对同一个网址的请求。因此，如果存在合适的验证令牌 (ETag)，no-cache 会发起往返通信来验证缓存的响应，如果资源未被更改，可以避免下载。 no-store 所有内容都不会被缓存到缓存或 Internet 临时文件中 must-revalidation/proxy-revalidation 如果缓存的内容失效，请求必须发送到服务器/代理以进行重新验证 max-age=xxx (xxx is numeric) 缓存的内容将在 xxx 秒后失效, 这个选项只在HTTP 1.1可用, 并如果和Last-Modified一起使用时, 优先级较高 Cache-directive说明public所有内容都将被缓存(客户端和代理服务器都可缓存)private内容只缓存到私有缓存中(仅客户端可以缓存，代理服务器不可缓存)no-cache必须先与服务器确认返回的响应是否被更改，然后才能使用该响应来满足后续对同一个网址的请求。因此，如果存在合适的验证令牌 (ETag)，no-cache 会发起往返通信来验证缓存的响应，如果资源未被更改，可以避免下载。no-store所有内容都不会被缓存到缓存或 Internet 临时文件中must-revalidation/proxy-revalidation如果缓存的内容失效，请求必须发送到服务器/代理以进行重新验证max-age=xxx (xxx is numeric)缓存的内容将在 xxx 秒后失效, 这个选项只在HTTP 1.1可用, 并如果和Last-Modified一起使用时, 优先级较高 Content-Length：指明客户端向服务端的请求体的长度，用十进制表示八位字节数组 Date：此条消息被发送时的日期和时间(按照 RFC 7231 中定义的“超文本传输协议日期”格式来表示) Expires：响应请求的超时时间，超过该时间表示响应已经过期了，相对于Cache-Control:max-age而言，max-age表示过期的秒数，Expires表示的是过期的时间，如果两者同时存在，max-age优先级更高，如果两者都不存在，以Date和Last-Modified来判断是否过期 Keep-Alive：这是一个通用的首部，表示持续连接的状态，只有在Connection设置为keep-Alive才有效，如果为timeout表示该连接保持的过期时间，如果是max表示该连接请求的最大数，在HTTP/2.0已经被忽略了 Last-Modified：该请求的资源最后修改的时间，用于请求资源检验的，这在请求首部已经介绍过了 Server：表示处理请求的服务器的软件相关信息 X-Github-Request-Id：github标识的请求ID，由于我的http://pettyandydog.com 这个请求是指向github资源的，所以会返回一个guthub的响应标识 在响应首部中，除了上述出现的首部之外，还有比如Set-Cookie首部字段表示向客户端设置cookie值，Location首部字段用于重定向，指访问的资源已经迁移或者换了新的地址，用Location表示新的地址重定向，Transfer-Encoding首部字段表示当前传输内容的传输编码，包括chunked，gzip，compress等等，vary首部表示后续的请求使用缓存的文件还是请求新的资源，当缓存服务器收到一个请求，只有当前的请求和缓存的请求头以及vary都匹配才使用缓存，否则请求新资源 HTTP状态码在chrome console的首部信息中还有一项通用首部，它包含着请求url和响应的状态码，如下所示上图所示的status code是HTTP请求的响应状态码，标识着客户端和服务端的交互的状态，一般由三位数字和原因短语组成，上图中的状态码304 Not Modified中304表示一个三位的状态数字，Not Moditied代表原因短语，在HTTP的响应请求中，共有五种类别的状态码，分别由1到5的数字开头，下面分别一一介绍 1XX消息1XX类型的状态码表示请求已经被接受，等待下一步处理，在HTTP1.0并不支持 100 Continue：服务器已经接收到了请求头，通知客户端继续发送主体，列如POST请求的请求数据体，一般在服务器检验请求首部时，客户端会在请求首部发送Expect：100-contunue来指定响应100 Continue状态码 101 Switching Protocols：通过Upgrade消息头来通知客户端切换协议来处理请求 2XX成功2XX类型的状态码表示请求已经成功被服务器所接受 200 OK：表示请求被成功处理并返回，适用于请求的资源的方法：GET,POST,HEAD 201 Created：请求创建新的资源成功，适用于创建资源的方法：PUT 202 Accepted：请求被接受，但是可能还没有处理 203 Non-Authoritative Information（自HTTP / 1.1起）：表示请求的是一个转换代理服务器 204 No Content：请求被服务器成功处理，但无内容返回，适用于PUT请求对资源进行了更新，不需要返回内容，不同于201 Created，一个是更新一个资源，一个是创建一个资源 205 Reset Content：与204一样，不同的是要求客户端重置文档视图，比如清空表单内容 206 Partial Content：部分资源请求成功，通常用于指定请求首部Range的范围请求，比如断点续传 3xx重定向3XX类型的状态码表示客户端需要进一步的操作才能完成请求 301 Moved Permanently：请求的资源被永久移动到新的地址，响应在Location首部指定新的地址重新保存 302 Found：与301类似，不同的是资源只是暂时性的移动，并不会更新新的地址 303 See Other：与302类似，只是访问新的地址以GET的方式，这是302的一种补充 304 Not Modified：与请求头If-Modified-Since或If-None-Match指定的版本对比，资源并未改变，无需重新获取资源，在上述的请求http://pettyandydog.com 中就是返回304，表示这个请求没有重新请求资源，资源并未改变，所以访问的是缓存 4xx客户端错误4XX类型的状态码表示客户端出现一些错误，比如违反规范或者与服务器需要的请求预期不符 400 Bad Request：客户端违反了请求的规范，比如格式错误，请求体太大，或者语法错误 401 Unauthorized：没有权限访问资源，会在首部WWW-Authenticate返回该权限的验证信息 403 Forbidden：服务器已经接受请求，但是拒绝执行请求，与401不同的时，401可以访问资源，只是缺少权限而已，加上权限认证就可以访问了 404 Not Found：请求的资源没有被找到，这个在开发过程中也经常遇到，一般都是请求的路径不正确 405 Method Not Allowed：不合理的请求方法，如果客户端使用了服务端禁止的请求方法访问资源就会返回此状态码 5xx服务器错误 500 Internal Server Error：服务器错误，无法处理请求，这个在开发中也经常遇见，泛指服务端出现了异常或者错误 502 Bad Gateway：网关或者代理服务器执行请求，接收到上游的服务器的无效响应 503 Service Unavailable：服务器维护或者过载，无法处理请求，这种情况应该最好发送一个用户友好的界面来解释发生的原因，如果可行时，在Retry-After首部字段指定恢复的时间 504 Gateway Timeout：网关或者代理服务器执行请求，接收到上游的服务器的响应超时，与502的无效响应不同 注意：这里要注意一点的是200 ok和304 Not MoModified这两个状态，因为这两个在请求中出现的频率很高，会经常混淆，，在大多数浏览器中，回车键访问地址返回的是200 ok和刷新访问地址返回的是304 Not Modified，这里举两个例子来区别，第一个例子：首先我发送一个请求（如果上一个请求在响应首部指定了过期时间Cache-Control：max-age=xxx），他会在客户端通过Max-Age进行判断该请求的缓存是否已经过期，如果没有过期就会直接访问缓存服务器的副本，返回200 ok，如果过期了，就会访问服务器重新访问资源，返回200 ok，第二个例子：还是发送一个请求（如果上一个请求在响应首部只是指定了Last-Modified或者Etag），他就会在请求首部加上If-Modified-Since和If-None-Match去请求服务器资源，在服务端会对请求资源的最后修改的时间或者版本号和请求首部If-Modified-Since和If-None-Match的信息进行比较，如果一致表示缓存没有过期，返回304 Not Modified， 直接获取缓存副本，如果不一致，重新请求资源，返回200 OK,这里其实就很清楚了，304 Not Modified是在服务端进行了缓存有效性比较，并且一致性返回的状态码，200 ok是表示访问了服务器的资源注意：这里要注意一点的是200 ok和304 Not MoModified这两个状态，因为这两个在请求中出现的频率很高，会经常混淆，，在大多数浏览器中，回车键访问地址返回的是200 ok和刷新访问地址返回的是304 Not Modified，这里举两个例子来区别，第一个例子：首先我发送一个请求（如果上一个请求在响应首部指定了过期时间Cache-Control：max-age=xxx），他会在客户端通过Max-Age进行判断该请求的缓存是否已经过期，如果没有过期就会直接访问缓存服务器的副本，返回200 ok，如果过期了，就会访问服务器重新访问资源，返回200 ok，第二个例子：还是发送一个请求（如果上一个请求在响应首部只是指定了Last-Modified或者Etag），他就会在请求首部加上If-Modified-Since和If-None-Match去请求服务器资源，在服务端会对请求资源的最后修改的时间或者版本号和请求首部If-Modified-Since和If-None-Match的信息进行比较，如果一致表示缓存没有过期，返回304 Not Modified， 直接获取缓存副本，如果不一致，重新请求资源，返回200 OK,这里其实就很清楚了，304 Not Modified是在服务端进行了缓存有效性比较，并且一致性返回的状态码，200 ok是表示访问了服务器的资源 HTTPS上述的http协议很好的解决了客户端和服务端之间的通信问题，但是同时也有很多缺点，有一些缺点在传输一些很重要的信息时很致命，就是安全性不足，比如 通信使用明文传输，内容容易被窃听 不验证通信双方的身份，可以会遭遇伪装 无法验证报文的完整性，可能会遭到篡改 我们先来说第一点，首先通信明文传输的问题，客户端传输的内容会经过应用层HTTP封装，到传输层TCP封装，再到链路层的IP封装，然后经过各种路由，各种网络设备，才能传输到指定的服务端进行处理，其实从客户端到路由，各种网络设备，再到服务器都有被窃听的可能，他们可以在这里窃听你所传输的任何资源，如果是明文传输的话，你的一切都将不是秘密了，那现在对内容进行加密在通信，这不就可以解决明文传输的隐患了吗？但是这种方式还是会被窃听到，虽然窃听的是加密后的内容，无法破解，但本质上还是被看到了，还是有一定的隐患，其实明文传输的隐患并不是明文，而是传输过程中的窃听，如果我们对对整个通信通道进行加密来屏蔽掉窃听，这样就可以解决窃听的风险了，那怎么对整个通信通道进行加密呢？就是将HTTP协议披上一层加密协议，SSL(Secure Socket Layer 安全套接协议)或者TLS(Transport Layer Security 安全传输协议)，在客户端传输内容时，SSL或者TLS会先进行第一次握手，建立加密通道后才能进行通信，这样就能解决明文传输被窃听的不足了 再来说第二点，对于HTTP通信，并不需要知道对方的正是身份，只要客户端发送请求，服务端就会响应，但不知道是谁请求的，这样不明确身份的传输会有很大的隐患，如果是一个伪装的客户端发送了同样的请求，服务器也会响应，如果是一个伪装的服务器在接收客户端的请求，这样信息也会泄漏，那如何解决身份识别的问题呢？这里还要用到加密协议SSL或者TLS,它除了应用于加密功能之外，还有提供一个证书识别来验证身份的功能，每次客户端要发送请求给服务端前必须要下载服务器提供的证书保存在本地，然后每次请求通过响应服务器的证书和自己本地证书进行对比，一致表示自己要访问就是这个网站，这样就形成了身份识别了，证书一般来说由权威的第三方公司提供，当然也可以自己提供，然后自己维护证书的安全性，典型的就是12306网站 第三点是基于第一点和第二点，在通信明文传输中，可能会遭到窃听，那就有可能会遭到篡改（中间人攻击），在传输的过程中，会经过各种网络设备，有些就会在这里监听请求，继而篡改请求报文，或者响应报文，当然通过SSL加密和认证处理可以解决这一问题 针对上述的三个问题，这里就引出了解决HTTP安全性的方法：HTTP+SSL，这也就是HTTPS（HTTP Secure 超文本传输安全协议），具体的加密（非对称加密）和认证（双向认证）这里就不介绍了，具体可以参考《图解HTTP》的第七章和第八章 参考http://www.jianshu.com/p/37b1258b3b0dhttp://www.cnblogs.com/ttltry-air/archive/2012/08/20/2647898.htmlhttps://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE#.E6.8C.81.E7.BA.8C.E8.BF.9E.E7.B7.9Ahttps://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching?hl=zh-cnhttps://zh.wikipedia.org/wiki/HTTP%E5%A4%B4%E5%AD%97%E6%AE%B5http://www8.org/w8-papers/5c-protocols/key/key.html《图解HTTP》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发包-ConcurrentHashMap]]></title>
      <url>%2F2017%2F07%2F27%2FconcurrentHashMap%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言以前写过介绍HashMap的文章，文中提到过HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。 我们来了解另一个键值存储集合HashTable，它是线程安全的，它在所有涉及到多线程操作的都加上了synchronized关键字来锁住整个table，这就意味着所有的线程都在竞争一把锁，在多线程的环境下，它是安全的，但是无疑是效率低下的。 其实HashTable有很多的优化空间，锁住整个table这么粗暴的方法可以变相的柔和点，比如在多线程的环境下，对不同的数据集进行操作时其实根本就不需要去竞争一个锁，因为他们不同hash值，不会因为rehash造成线程不安全，所以互不影响，这就是锁分离技术，将锁的粒度降低，利用多个锁来控制多个小的table，这就是这篇文章的主角ConcurrentHashMap JDK1.7版本的核心思想 ConcurrentHashMapJDK1.7的实现在JDK1.7版本中，ConcurrentHashMap的数据结构是由一个Segment数组和多个HashEntry组成，如下图所示：Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，也就是上面的提到的锁分离技术，而每一个Segment元素存储的是HashEntry数组+链表，这个和HashMap的数据存储结构一样 初始化ConcurrentHashMap的初始化是会通过位与运算来初始化Segment的大小，用ssize来表示，如下所示123456int sshift = 0;int ssize = 1;while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;&#125; 如上所示，因为ssize用位于运算来计算（ssize &lt;&lt;=1），所以Segment的大小取值都是以2的N次方，无关concurrencyLevel的取值，当然concurrencyLevel最大只能用16位的二进制来表示，即65536，换句话说，Segment的大小最多65536个，没有指定concurrencyLevel元素初始化，Segment的大小ssize默认为16 每一个Segment元素下的HashEntry的初始化也是按照位于运算来计算，用cap来表示，如下所示123int cap = 1;while (cap &lt; c) cap &lt;&lt;= 1; 如上所示，HashEntry大小的计算也是2的N次方（cap &lt;&lt;=1）， cap的初始值为1，所以HashEntry最小的容量为2 put操作对于ConcurrentHashMap的数据插入，这里要进行两次Hash去定位数据的存储位置1static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; 从上Segment的继承体系可以看出，Segment实现了ReentrantLock,也就带有锁的功能，当执行put操作时，会进行第一次key的hash来定位Segment的位置，如果该Segment还没有初始化，即通过CAS操作进行赋值，然后进行第二次hash操作，找到相应的HashEntry的位置，这里会利用继承过来的锁的特性，在将数据插入指定的HashEntry位置时（链表的尾端），会通过继承ReentrantLock的tryLock（）方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用tryLock（）方法去获取锁，超过指定次数就挂起，等待唤醒 get操作ConcurrentHashMap的get操作跟HashMap类似，只是ConcurrentHashMap第一次需要经过一次hash定位到Segment的位置，然后再hash定位到指定的HashEntry，遍历该HashEntry下的链表进行对比，成功就返回，不成功就返回null size操作计算ConcurrentHashMap的元素大小是一个有趣的问题，因为他是并发操作的，就是在你计算size的时候，他还在并发的插入数据，可能会导致你计算出来的size和你实际的size有相差（在你return size的时候，插入了多个数据），要解决这个问题，JDK1.7版本用两种方案123456789101112131415161718192021try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125;finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125;&#125; 第一种方案他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的 第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回 JDK1.8的实现JDK1.8的实现已经摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap，虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本在深入JDK1.8的put和get实现之前要知道一些常量设计和数据结构，这些是构成ConcurrentHashMap实现结构的基础，下面看一下基本属性：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// node数组最大容量：2^30=1073741824private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认初始值，必须是2的幕数private static final int DEFAULT_CAPACITY = 16;//数组可能最大值，需要与toArray（）相关方法关联static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;//并发级别，遗留下来的，为兼容以前的版本private static final int DEFAULT_CONCURRENCY_LEVEL = 16;// 负载因子private static final float LOAD_FACTOR = 0.75f;// 链表转红黑树阀值,&gt; 8 链表转换为红黑树static final int TREEIFY_THRESHOLD = 8;//树转链表阀值，小于等于6（tranfer时，lc、hc=0两个计数器分别++记录原bin、新binTreeNode数量，&lt;=UNTREEIFY_THRESHOLD 则untreeify(lo)）static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64;private static final int MIN_TRANSFER_STRIDE = 16;private static int RESIZE_STAMP_BITS = 16;// 2^15-1，help resize的最大线程数private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;// 32-16=16，sizeCtl中记录size大小的偏移量private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;// forwarding nodes的hash值static final int MOVED = -1; // 树根节点的hash值static final int TREEBIN = -2; // ReservationNode的hash值static final int RESERVED = -3; // 可用处理器数量static final int NCPU = Runtime.getRuntime().availableProcessors();//存放node的数组transient volatile Node&lt;K,V&gt;[] table;/*控制标识符，用来控制table的初始化和扩容的操作，不同的值有不同的含义 *当为负数时：-1代表正在初始化，-N代表有N-1个线程正在 进行扩容 *当为0时：代表当时的table还没有被初始化 *当为正数时：表示初始化或者下一次进行扩容的大小private transient volatile int sizeCtl; 基本属性定义了ConcurrentHashMap的一些边界以及操作时的一些控制，下面看一些内部的一些结构组成，这些是整个ConcurrentHashMap整个数据结构的核心 NodeNode是ConcurrentHashMap存储结构的基本单元，继承于HashMap中的Entry，用于存储数据，源代码如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; //链表的数据结构 final int hash; final K key; //val和next都会在扩容时发生变化，所以加上volatile来保持可见性和禁止重排序 volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + "=" + val; &#125; //不允许更新value public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; //用于map中的get（）方法，子类重写 Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null; &#125;&#125; Node数据结构很简单，从上可知，就是一个链表，但是只允许对数据进行查找，不允许进行修改 TreeNodeTreeNode继承与Node，但是数据结构换成了二叉树结构，它是红黑树的数据的存储结构，用于红黑树中存储数据，当链表的节点数大于8时会转换成红黑树的结构，他就是通过TreeNode作为存储结构代替Node来转换成黑红树源代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; //树形结构的属性定义 TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; //标志红黑树的红节点 TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; return findTreeNode(h, k, null); &#125; //根据key查找 从根节点开始找出相应的TreeNode， final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.findTreeNode(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); &#125; return null; &#125;&#125; TreeBinTreeBin从字面含义中可以理解为存储树形结构的容器，而树形结构就是指TreeNode，所以TreeBin就是封装TreeNode的容器，它提供转换黑红树的一些条件和锁的控制，部分源码结构如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; //指向TreeNode列表和根节点 TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // 读写锁状态 static final int WRITER = 1; // 获取写锁的状态 static final int WAITER = 2; // 等待写锁的状态 static final int READER = 4; // 增加数据时读锁的状态 /** * 初始化红黑树 */ TreeBin(TreeNode&lt;K,V&gt; b) &#123; super(TREEBIN, null, null, null); this.first = b; TreeNode&lt;K,V&gt; r = null; for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (r == null) &#123; x.parent = null; x.red = false; r = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = r;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; this.root = r; assert checkInvariants(root); &#125; ......&#125; 介绍了ConcurrentHashMap主要的属性与内部的数据结构，现在通过一个简单的例子以debug的视角看看ConcurrentHashMap的具体操作细节123456789101112131415public class TestConcurrentHashMap&#123; public static void main(String[] args)&#123; ConcurrentHashMap&lt;String,String&gt; map = new ConcurrentHashMap(); //初始化ConcurrentHashMap //新增个人信息 map.put("id","1"); map.put("name","andy"); map.put("sex","男"); //获取姓名 String name = map.get("name"); Assert.assertEquals(name,"andy"); //计算大小 int size = map.size(); Assert.assertEquals(size,3); &#125;&#125; 我们先通过new ConcurrentHashMap()来进行初始化12public ConcurrentHashMap() &#123;&#125; 由上你会发现ConcurrentHashMap的初始化其实是一个空实现，并没有做任何事，这里后面会讲到，这也是和其他的集合类有区别的地方，初始化操作并不是在构造函数实现的，而是在put操作中实现，当然ConcurrentHashMap还提供了其他的构造函数，有指定容量大小或者指定负载因子，跟HashMap一样，这里就不做介绍了 put操作在上面的例子中我们新增个人信息会调用put方法，我们来看下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public V put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); //两次hash，减少hash冲突，可以均匀分布 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; //对这个table进行迭代 Node&lt;K,V&gt; f; int n, i, fh; //这里就是上面构造方法没有进行初始化，在这里进行判断，为null就调用initTable进行初始化，属于懒汉模式初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;//如果i位置没有数据，就直接无锁插入 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED)//如果在进行扩容，则先进行扩容操作 tab = helpTransfer(tab, f); else &#123; V oldVal = null; //如果以上条件都不满足，那就要进行加锁操作，也就是存在hash冲突，锁住链表或者红黑树的头结点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; //表示该节点是链表结构 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //这里涉及到相同的key进行put就会覆盖原先的value if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; //插入链表尾部 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123;//红黑树结构 Node&lt;K,V&gt; p; binCount = 2; //红黑树结构旋转插入 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果链表的长度大于8时就会进行红黑树的转换 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount);//统计size，并且检查是否需要扩容 return null;&#125; 这个put的过程很清晰，对当前的table进行无条件自循环直到put成功，可以分成以下六步流程来概述 如果没有初始化就先调用initTable（）方法来进行初始化过程 如果没有hash冲突就直接CAS插入 如果还在进行扩容操作就先进行扩容 如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入， 最后一个如果该链表的数量大于阈值8，就要先转换成黑红树的结构，break再一次进入循环 如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容 现在我们来对每一步的细节进行源码分析，在第一步中，符合条件会进行初始化操作，我们来看看initTable（）方法12345678910111213141516171819202122232425/** * Initializes table, using the size recorded in sizeCtl. */private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123;//空的table才能进入初始化操作 if ((sc = sizeCtl) &lt; 0) //sizeCtl&lt;0表示其他线程已经在初始化了或者扩容了，挂起当前线程 Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;//CAS操作SIZECTL为-1，表示初始化状态 try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];//初始化 table = tab = nt; sc = n - (n &gt;&gt;&gt; 2);//记录下次扩容的大小 &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 在第二步中没有hash冲突就直接调用Unsafe的方法CAS插入该元素，进入第三步如果容器正在扩容，则会调用helpTransfer（）方法帮助扩容，现在我们跟进helpTransfer（）方法看看12345678910111213141516171819202122/** *帮助从旧的table的元素复制到新的table中 */final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; //新的table nextTba已经存在前提下才能帮助扩容 int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab);//调用扩容方法 break; &#125; &#125; return nextTab; &#125; return table;&#125; 其实helpTransfer（）方法的目的就是调用多个工作线程一起帮助进行扩容，这样的效率就会更高，而不是只有检查到要扩容的那个线程进行扩容操作，其他线程就要等待扩容操作完成才能工作既然这里涉及到扩容的操作，我们也一起来看看扩容方法transfer（） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 每核处理的量小于16，则强制赋值16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; //构建一个nextTable对象，其容量为原来容量的两倍 nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; // 连接点指针，用于标志位（fwd的hash值为-1，fwd.nextTable=nextTab） ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // 当advance == true时，表明该节点已经处理过了 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 控制 --i ,遍历原hash表中的节点 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 用CAS计算得到的transferIndex else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; // 已经完成所有节点复制了 if (finishing) &#123; nextTable = null; table = nextTab; // table 指向nextTable sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); // sizeCtl阈值为原来的1.5倍 return; // 跳出死循环， &#125; // CAS 更扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 遍历的节点为null，则放入到ForwardingNode 指针节点 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // f.hash == -1 表示遍历到了ForwardingNode节点，意味着该节点已经处理过了 // 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 节点加锁 synchronized (f) &#123; // 节点复制工作 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // fh &gt;= 0 ,表示为链表节点 if (fh &gt;= 0) &#123; // 构造两个链表 一个是原链表 另一个是原链表的反序排列 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 在nextTable i 位置处插上链表 setTabAt(nextTab, i, ln); // 在nextTable i + n 位置处插上链表 setTabAt(nextTab, i + n, hn); // 在table i 位置处插上ForwardingNode 表示该节点已经处理过了 setTabAt(tab, i, fwd); // advance = true 可以执行--i动作，遍历节点 advance = true; &#125; // 如果是TreeBin，则按照红黑树进行处理，处理逻辑与上面一致 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 扩容后树节点个数若&lt;=6，将树转链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; 扩容过程有点复杂，这里主要涉及到多线程并发扩容,ForwardingNode的作用就是支持扩容操作，将已处理的节点和空节点置为ForwardingNode，并发处理时多个线程经过ForwardingNode就表示已经遍历了，就往后遍历，下图是多线程合作扩容的过程：介绍完扩容过程，我们再次回到put流程，在第四步中是向链表或者红黑树里加节点，到第五步，会调用treeifyBin（）方法进行链表转红黑树的过程1234567891011121314151617181920212223242526272829private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; //如果整个table的数量小于64，就扩容至原来的一倍，不转红黑树了 //因为这个阈值扩容可以减少hash冲突，不必要去转红黑树 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; //封装成TreeNode TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; //通过TreeBin对象对TreeNode转换成红黑树 setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; 到第六步表示已经数据加入成功了，现在调用addCount()方法计算ConcurrentHashMap的size，在原来的基础上加一，现在来看看addCount()方法1234567891011121314151617181920212223242526272829303132333435363738394041private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //更新baseCount，table的数量，counterCells表示元素个数的变化 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; //如果多个线程都在执行，则CAS失败，执行fullAddCount，全部加入count if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; //check&gt;=0表示需要进行扩容操作 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //当前线程发起库哦哦让操作，nextTable=null else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125; put的流程现在已经分析完了，你可以从中发现，他在并发处理中使用的是乐观锁，当有冲突的时候才进行并发处理，而且流程步骤很清晰，但是细节设计的很复杂，毕竟多线程的场景也复杂 get操作我们现在要回到开始的例子中，我们对个人信息进行了新增之后，我们要获取所新增的信息，使用String name = map.get(“name”)获取新增的name信息，现在我们依旧用debug的方式来分析下ConcurrentHashMap的获取方法get()123456789101112131415161718192021public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); //计算两次hash if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123;//读取首节点的Node元素 if ((eh = e.hash) == h) &#123; //如果该节点就是首节点就返回 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //hash值为负值表示正在扩容，这个时候查的是ForwardingNode的find方法来定位到nextTable来 //查找，查找到就返回 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123;//既不是首节点也不是ForwardingNode，那就往下遍历 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; ConcurrentHashMap的get操作的流程很简单，也很清晰，可以分为三个步骤来描述 计算hash值，定位到该table索引位置，如果是首节点符合就返回 如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回 以上都不符合的话，就往下遍历节点，匹配就返回，否则最后就返回null size操作最后我们来看下例子中最后获取size的方式int size = map.size();，现在让我们看下size()方法1234567891011121314151617public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125;final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; //变化的数量 long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 在JDK1.8版本中，对于size的计算，在扩容和addCount()方法就已经有处理了，JDK1.7是在调用size()方法才去计算，其实在并发集合中去计算size是没有多大的意义的，因为size是实时在变的，只能计算某一刻的大小，但是某一刻太快了，人的感知是一个时间段，所以并不是很精确 总结与思考其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,相对而言，总结如下思考 JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点） JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了 JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档 JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了 JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据 参考http://blog.csdn.net/u010412719/article/details/52145145http://www.jianshu.com/p/e694f1e868echttps://my.oschina.net/liuxiaomian/blog/880088https://bentang.me/tech/2016/12/01/jdk8-concurrenthashmap-1/http://cmsblogs.com/?p=2283]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发包-lock]]></title>
      <url>%2F2017%2F07%2F12%2Flock%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言在并发访问一些共享资源的时候，锁是一种实现安全并发访问的手段，在深入并发关键字-synchronized一文中对JVM内置的锁机制进行了深入的分析，而里程碑意义的JDK1.5版本，JAVA大神Doug lea在java的代码层面上开发了一套锁机制，如下图所示： Lock在最顶层是一个Lock的接口，他实现了比使用Synchronized的方法和语句更加广泛的锁定操作，代码如下所示（以下代码基于JDK1.8）1234567891011121314public interface Lock &#123;//获取锁void lock();//获取未中断线程的锁void lockInterruptibly() throws InterruptedException;//尝试在锁为空闲状态获取锁boolean tryLock();//尝试在一定的时间段内，并且锁为空闲状态和为中断时获取锁boolean tryLock(long time, TimeUnit unit) throws InterruptedException;//释放锁void unlock();//获取一个绑定该锁的conditionCondition newCondition();&#125; 如上代码所示，Lock接口定义了锁的基本语义和生命周期，而在获取锁的方式上，Lock提供了三种不同方式的获取锁操作：（1）可中断，（2）不可中断，（3）定时，适应不同的生产环境中，在其性能特征，排序保证或者其他的实现质量上会有所不同 ReentrantLock在上一篇文章深入并发包-AQS中，以ReentrantLock为例介绍了AQS在并发同步上的控制，这里就不在赘述了 ReadWriteLock在ReentrantLock中，每一次获取锁都是独占锁，每一次只能是一个线程进行访问，但是在一些只是读取一些共享变量的场景下，并不需要独占锁来访问，这样并不利于并发性能，于是乎Doug lea将锁分割成一对相关的读锁和写锁更小的两个粒度，这和MySQL中的共享锁和排它锁类似（共享读锁，独享写锁），读锁允许多个线程同时保持运行，写锁是独占锁，只能一个线程保持运行，他们保持着一致性的内存同步，读锁的线程会看见写锁之前的版本所做的更新，ReadWriteLock接口提供了这样的语义，代码如下所示123456public interface ReadWriteLock &#123; //获取读锁 Lock readLock(); //获取写锁 Lock writeLock();&#125; ReentrantReadWriteLockReentrantReadWriteLock是ReentrantLock接口的实现，在读写锁的基础上加上了重入性，来避免死锁，现在通过一个例子来进入ReentrantReadWriteLock的源码世界12345678910111213141516171819202122232425public class RWLock &#123; ReadWriteLock readWriteLock ; private int i; public RWLock()&#123; readWriteLock= new ReentrantReadWriteLock(); i = 0; &#125; public void setI(int i) &#123; Lock lock = readWriteLock.writeLock(); lock.lock(); this.i = i; lock.unlock(); &#125; public int getI() &#123; Lock lock = readWriteLock.readLock(); lock.lock(); int r = i; lock.unlock(); return r; &#125;&#125; 对于共享变量i的读与写，通过读写锁来控制，利用语句new ReentrantReadWriteLock()来创建对象12345678public ReentrantReadWriteLock() &#123; this(false);&#125;public ReentrantReadWriteLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this);&#125; 和ReentrantLock一样，锁的机制有两种，默认的是非公平锁，另一种是公平锁，sync实现了AQS，用于并发锁控制（这里不再赘述了，详情可以查看深入并发包-AQS），读写锁共享一个同步器sync，ReadLock和WriteLock是内部类，是Lock的实现类1234public static class WriteLock implements Lock, java.io.Serializable &#123;......&#125;public static class ReadLock implements Lock, java.io.Serializable &#123;......&#125; 我们先来看写锁的获取与释放 WriteLock获取锁在上述的例子，i的setter中，会创建一个写锁来控制共享变量i的写入，通过readWriteLock.writeLock();来创建一个写锁1public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125; 然后再通过lock.lock();获取写锁123public void lock() &#123; sync.acquire(1);&#125; 这里会调用前面实现的同步器sync的acquire方法123456789public final void acquire(int arg) &#123; // 这里通过tryAcquire(1)会尝试获取锁，如果获取成功，直接返回true // 因为有可能直接就成功了呢，也就不需要进队列排队了， // 对于公平锁的语义就是：本来就没人持有锁，根本没必要进队列等待(又是挂起，又是等待被唤醒的) if (!tryAcquire(arg) &amp;&amp; // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 当前线程会调用tryAcquire(arg)方法,尝试去获取锁1234567891011121314151617181920212223242526272829303132333435363738protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread();//获取当前线程 int c = getState();//c是锁状态为：高位16位表示共享锁的数量，低位16位表示独占锁的数量 int w = exclusiveCount(c);//取低16位的值，也就是写锁状态位：不等于0表示写锁被占用 if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) //这里c != 0 and w == 0表示当前没有写锁，只有读锁被占用或者当前线程不是当前独占锁的线程（重入锁的特性），就直接失败，返回false if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) //锁的最大值限制最多支持65535个写锁和读锁 throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires);//运行到这里，表示是重入锁，并修改锁的状态 return true; &#125; //c==0表示如果当前没有线程获取锁，该线程会获取锁并且CAS设置状态 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); //成功就设置当前线程获取独占锁 return true;&#125;//运行完tryAcquire方法我们回头看看上一级的语句，如下if (!tryAcquire(arg) &amp;&amp; // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt() 如果当前尝试获取失败，会调用acquireQueued(addWaiter(Node.EXCLUSIVE), arg)放入阻塞队列中，再中断挂起，接下来看看addWaiter方法（注意：加入阻塞队列的方法和ReentrantLock是一样的，如果在深入并发包-AQS已经了解了，可以忽略）12345678910111213141516171819202122232425262728293031323334/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ // 此方法的作用是把线程包装成node，同时进入到队列中 // 参数mode此时是Node.EXCLUSIVE，代表独占模式 private Node addWaiter(Node mode) &#123; //mode值下一个等待的线程节点，默认为null Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后 Node pred = tail; // tail!=null =&gt; 队列不为空(tail==head的时候，其实队列是空的，不过不管这个吧) if (pred != null) &#123; // 设置自己的前驱 为当前的队尾节点 node.prev = pred; // 用CAS把自己设置为队尾, 如果成功后，tail == node了 if (compareAndSetTail(pred, node)) &#123; // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连， // 上面已经有 node.prev = pred // 加上下面这句，也就实现了和之前的尾节点双向连接了 pred.next = node; // 线程入队了，可以返回了 return node; &#125; &#125; // 仔细看看上面的代码，如果会到这里， // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队) enq(node); return node; &#125; 如果队列是空的，或者有竞争，就调用enq方法采用自旋的方式来加入阻塞队列，如下所示123456789101112131415161718192021222324252627282930313233343536373839/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */ // 采用自旋的方式入队 // 之前说过，到这个方法只有两种可能：等待队列为空，或者有线程竞争入队， // 自旋在这边的语义是：CAS设置tail过程中，竞争一次竞争不到，我就多次竞争，总会排到的 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 之前说过，队列为空也会进来这里 if (t == null) &#123; // Must initialize // 初始化head节点 // 细心的读者会知道原来head和tail初始化的时候都是null，反正我不细心 // 还是一步CAS，你懂的，现在可能是很多线程同时进来呢 if (compareAndSetHead(new Node())) // 给后面用：这个时候head节点的waitStatus==0, 看new Node()构造方法就知道了 // 这个时候有了head，但是tail还是null，设置一下， // 把tail指向head，放心，马上就有线程要来了，到时候tail就要被抢了 // 注意：这里只是设置了tail=head，这里可没return哦，没有return，没有return // 所以，设置完了以后，继续for循环，下次就到下面的else分支了 tail = head; &#125; else &#123; // 下面几行，和上一个方法 addWaiter 是一样的， // 只是这个套在无限循环里，反正就是将当前线程排到队尾，有线程竞争的话排不上重复排 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; // 然后再次回到这段代码了 // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); 我们再来看一看acquireQueued方法，在进入阻塞队列中，他会再次尝试获取锁，如下所示1234567891011121314151617181920212223242526272829303132333435// 下面这个方法，参数node，经过addWaiter(Node.EXCLUSIVE)，此时已经进入阻塞队列// 注意一下：如果acquireQueued(addWaiter(Node.EXCLUSIVE), arg))返回true的话，// 意味着上面这段代码将进入selfInterrupt()，所以正常情况下，下面应该返回false// 这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//获取当前node的前一个node // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列 // 所以当前节点可以去试抢一下锁 // 这里我们说一下，为什么可以去试试： // 首先，它是队头，这个是第一个条件，其次，当前的head有可能是刚刚初始化的node， // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程 // 也就是说，当前的head不属于任何一个线程，所以作为队头，可以去试一试， // tryAcquire已经分析过了, 忘记了请往前看一下，就是简单用CAS试操作一下state if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 到这里，说明上面的if分支没有成功，要么当前node本来就不是队头， // 要么就是tryAcquire(arg)没有抢赢别人，继续往下看 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 当前线程获取锁失败会调用shouldParkAfterFailedAcquire方法，如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 刚刚说过，会到这里就是没有抢到锁呗，这个方法说的是："当前线程没有抢到锁，是否需要挂起当前线程？" // 第一个参数是前驱节点，第二个参数才是代表当前线程的节点 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; //下面的三个判断符合下列三种规则 // 规则1：如果前继的节点状态为SIGNAL，表明当前节点需要unpark(唤醒)，则返回成功，此时 acquireQueued方法的第12行（parkAndCheckInterrupt）将导致线程阻塞 // 规则2：如果前继节点状态为CANCELLED(ws&gt;0)，说明前置节点已经被放弃，则回溯到一个非取消的前继节点，返回false，acquireQueued方法的无限循环将递归调用该方法，直至规则1返回true，导致线程阻塞 // 规则3：如果前继节点状态为非SIGNAL、非CANCELLED，则设置前继的状态为SIGNAL，返回false后进入acquireQueued的无限循环，与规则2同 // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点 waitStatus大于0 ，之前说过，大于0 说明前驱节点取消了排队。这里需要知道这点： // 进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。 // 所以下面这块代码说的是将当前节点的prev指向waitStatus&lt;=0的节点， if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 仔细想想，如果进入到这个分支意味着什么 // 前驱节点的waitStatus不等于-1和1，那也就是只可能是0，-2，-3 // 在我们前面的源码中，都没有看到有设置waitStatus的，所以每个新的node入队时，waitStatu都是0 // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;// 回到下面的代码// if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;// parkAndCheckInterrupt()) 如果此线程取消了竞争（也就是waitStatus&gt;0），就会进入阻塞中断，这个时候需要一个契机将他唤醒，所有要不断循环前一个节点作为需要作为唤醒的契机（这在后面的释放锁操作会有说明），返回false，如果返回true的话，接下来会调用parkAndCheckInterrupt方法来检查中断操作，如下所示123456// 这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的// 这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒=======private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放锁上述就是获取写锁的过程，在i的setter方法中，将i写入之后会调用lock.unLock()方法去释放锁(这里与深入并发包-AQS中独占锁的解锁过程一样，如有了解，可以忽略)12345678910111213public void unlock() &#123; sync.release(1);&#125;他会调用release(1)方法,如下所示public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 上述会尝试执行释放锁的操作，调用FairSync实现的tryRelease方法，和获取锁的路子类似1234567891011121314protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 是否完全释放锁 boolean free = false; // 其实就是重入的问题，如果c==0，也就是说没有嵌套锁了，可以释放了，否则还不能释放掉 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 如果释放锁成功，且head不为空就会调用unparkSuccessor方法来唤醒后继的线程，如下所示：1234567891011121314151617181920212223242526272829303132// 唤醒后继节点// 从上面调用处知道，参数node是head头结点private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 如果head节点当前waitStatus&lt;0, 将其修改为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 下面的代码就是唤醒后继节点，但是有可能后继节点取消了等待（waitStatus==1） // 从队尾往前找，找到waitStatus&lt;=0的所有节点中排在最前面的 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后往前找，仔细看代码，不必担心中间有节点取消(waitStatus==1)的情况 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 唤醒线程 LockSupport.unpark(s.thread);&#125; 唤醒的线程会在如下代码继续进行1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 刚刚线程被挂起在这里了 return Thread.interrupted();&#125; 注意：LockSupport是并发包中针对线程阻塞操作的工具类 ReadLock分析完例子中i的setter方法中写锁的获取锁与释放锁，现在来看看例子中i的getter方法中读锁的获取锁与释放锁 获取锁在例子中i的getter方法，通过readWriteLock.readLock()获取读锁1public ReentrantReadWriteLock.ReadLock readLock() &#123; return readerLock; &#125; 下面再通过lock.lock()获取读锁123public void lock() &#123; sync.acquireShared(1);&#125; 这里会调用同步器sync的acquireShared方法12345//这里会调用tryAcquireShared方法来尝试以共享的模式获取锁，忽略中断public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);//阻塞排队&#125; 和独占锁的套路一样，都会先去通过tryAcquireShared尝试获取共享锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); //c是锁状态为：高位16位表示共享锁的数量，低位16位表示独占锁的数量 int c = getState(); //exclusiveCount(c) 取低16位的值，也就是写锁状态位：不等于0表示写锁被占用 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) //有写锁被其他线程占用，获取读锁失败 return -1; //取高16位的值，读锁状态位 int r = sharedCount(c); //readerShouldBlock()根据读锁获取策略，返回是否阻塞当前读锁获取操作。后面会详细说明此方法 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; //cas修改高16位的读锁状态，即获取读锁 compareAndSetState(c, c + SHARED_UNIT)) &#123; //首次获取读锁 if (r == 0) &#123; //缓存首次获取读锁的线程，及其读锁重入次数 firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; //如果获取锁（并不是第一个），直接读锁的数量++ firstReaderHoldCount++; &#125; else &#123;//如果是重入锁 //cachedHoldCounter是最后获取锁的线程的读锁重入次数 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) //readHolds是缓存了当前线程的读锁重入次数的ThreadLocal //当前线程自然是最后获取锁的线程，故将当前线程的holdCounter赋给cachedHoldCounter cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) //缓存当前线程的holdCounter //fullTryAcquireShared()方法中， //获取读锁失败的线程会执行：readHolds.remove()，故此时需要重新设置 readHolds.set(rh); rh.count++; &#125; return 1; &#125; //首次获取读锁失败后，重试获取 return fullTryAcquireShared(current);&#125; 获取读锁失败的话，会调用fullTryAcquireShared方法以自旋的方式去重新获取锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * Full version of acquire for reads, that handles CAS misses * and reentrant reads not dealt with in tryAcquireShared. */ final int fullTryAcquireShared(Thread current) &#123; //rh表示当前线程的锁计数器 HoldCounter rh = null; for (;;) &#123; int c = getState(); //写锁被占用 if (exclusiveCount(c) != 0) &#123; //如果其他线程占用，读锁获取失败。如果当前线程占用，表示“锁降级”。 if (getExclusiveOwnerThread() != current) return -1; &#125; else if (readerShouldBlock()) &#123; //重入锁不需要阻塞。 // Make sure we're not acquiring read lock reentrantly if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; //当前线程就是第一个获取读锁的线程，那么此时当然是重入锁。 &#125; else &#123; if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) &#123; rh = readHolds.get(); if (rh.count == 0) //线程阻塞之前，清空readHolds readHolds.remove(); &#125; &#125; if (rh.count == 0) //当前线程的锁计数器为0，非重入锁，需要阻塞。 return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT) throw new Error("Maximum lock count exceeded"); //cas设置读锁状态位 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; //缓存首次获取读锁的线程，以及锁计数器 firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) rh = readHolds.get(); else if (rh.count == 0) //锁计数器放入ThreadLocal readHolds.set(rh); rh.count++; //此时rh就是最后获取读锁的线程的锁计数器 cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125; &#125;//回头再看看上一级的方法if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);//阻塞排队 注意：这里涉及到锁降级的情况，如果在当前线程内，已经拥有了写锁了，再去获取读锁的话，就会将当前线程的写锁降级为读锁，在代码 if (exclusiveCount(c) != 0) 和if (getExclusiveOwnerThread() != current)两个去判断 如果获取读锁失败的话,调用doAcquireShared方法排队阻塞，和独占锁的acquireQueued方法类似123456789101112131415161718192021222324252627282930private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//加入阻塞等待队列 boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//获取当前node的前一个node // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列 // 所以当前节点可以去试抢一下锁 if (p == head) &#123; int r = tryAcquireShared(arg);//尝试获取锁 if (r &gt;= 0) &#123; //如果获取成功 setHeadAndPropagate(node, r);//设置当前节点为head，并且唤醒后续的节点 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 我们来看看setHeadAndPropagate方法来唤醒后续的节点12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node);//设置当前节点为头结点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared())//后继节点为共享节点，即读锁 doReleaseShared();//唤醒后续的节点 &#125;&#125; 我们接下来看看唤醒后续节点的doReleaseShared方法123456789101112131415161718192021222324252627private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 判断同步等待队列是否为空 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))&#123; continue; // loop to recheck cases &#125; // 唤醒 h 的后继节点（同时将 h 等待状态置为 CANCELED） unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))&#123; continue; // loop on failed CAS &#125; &#125; if (h == head)&#123; break;// loop if head changed &#125; &#125;&#125; 因为读锁和写锁不同，他是共享锁，他会在队列中唤醒共享锁的所有线程 释放锁在读完共享变量，就会调用lock.unlock()去释放锁123public void unlock() &#123; sync.releaseShared(1);&#125; 在这里会调用releaseShared方法1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 调用tryReleaseShared方法尝试去释放读锁1234567891011121314151617181920212223242526272829303132protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); //如果想要释放锁的线程为第一个获取锁的线程 if (firstReader == current) &#123; //仅获取了一次，则需要将firstReader 设置null，否则 firstReaderHoldCount - 1 if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; &#125; //获取rh对象，并更新“当前线程获取锁的信息” //HoldCounter是一个绑定共享锁的数量和当前线程ID，相当于锁的计数器 else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; //CAS更新同步状态 for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT;// state读锁状态减一 if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; 如果状态更新成功的话就会直接调用doReleaseShared方法去唤醒后续的节点1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head;//取头结点 if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123;//如果头结点状态为signal if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h);//唤醒线程 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))//更新状态为PROPAGATE continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 总结锁在并发场景中是比较重量级的，但是随着JDK版本的发展，以及对锁的一步步改进，在很多情况下已经显得并不是那么重，这里通常会与JVM内置锁synchronized来相比，这里借用JDK的描述：Lock 实现提供了比使用 synchronized 方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的 Condition 对象。 参考http://www.cnblogs.com/haolong/p/6268550.htmlhttp://blog.csdn.net/chenssy/article/details/68059443]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发包-AQS]]></title>
      <url>%2F2017%2F06%2F27%2FAQS%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言在java.util.concurrent并发包中，很多类的并发同步控制都是基于AbstractQueuedSynchronizer（简称AQS）这个同步器抽象类来实现的，比如ReentrantLock，Semaphore，CountDownLatch，ReentrantReadWriteLock，SynchronizerQueue和FutureTask，它通过依赖状态来实现获取锁或者一种许可的机制，下面通过源码来分析AQS以及ReentrantLock可重入锁中AQS的运用 AQS获取锁先看下他的继承体系：123public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; AQS继承于AbstractOwnableSynchronizer，顾名思义：线程独有的同步器，这为创建需要所有权的锁和相关的同步器提供了基础，在AbstractOwnableSynchronizer中只提供了一个线程属性的setter和getter方法12345678private transient Thread exclusiveOwnerThread;protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread;&#125;protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread;&#125; AQS继承了exclusiveOwnerThread属性，表示当前拥有独占锁的的线程，这也引入了锁的另一个特性：重入性，当前线程直接通过if (currentThread == getExclusiveOwnerThread()){state++}判断是否已经拥有了锁 现在我们再回到AQS，查看AQS的属性结构1234567// 头结点，你直接把它当做 当前持有锁的线程 可能是最好理解的private transient volatile Node head;// 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个隐视的链表private transient volatile Node tail;// 这个是最重要的，不过也是最简单的，代表当前锁的状态，0代表没有被占用，大于0代表有线程持有当前锁// 之所以说大于0，而不是等于1，是因为锁可以重入嘛，每次重入都加上1private volatile int state; 如上所示就是AQS定义的三个属性，其实线程在AQS会被抽象成一个Node的执行单元，我们再来看一看Node的结构：123456789101112131415161718192021222324252627282930313233343536static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ // 标识节点当前在共享模式下 static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 代表此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 表示线程处于等待的条件下的值，与下面的waitStatus对应，这在Lock中的condition中会使用 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; // ===================================================== // 取值为上面的1、-1、-2、-3，或者0(以后会讲到) // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // 也许就是说半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程本尊 volatile Thread thread;&#125; 这就是AQS的数据结构了，其实就是一个FIFO的队列，队列中的每一个节点Node就是代表一个具有状态的线程，如下图所示 我们新进的线程会插入队列的尾端tail，而队列的执行序列从head开始，AQS的工作就是维护这个队列以及node中线程的各种状态，下面以ReentrantLock的公平锁来分析AQS在其中发挥的作用 我们以下面ReentrantLock的使用方法来进入AQS1234567891011public class LockTest&#123; private ReentrantLock reentrantLock = new ReentrantLock(true); //构建ReentrantLock public void lockService() &#123; try &#123; reentrantLock.lock(); //获得锁 // do业务代码 &#125; finally &#123; reentrantLock.unlock();// 释放锁 &#125; &#125;&#125; ReentrantLock的构造方法如下 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 当fair参数为true时，将会创建内部类FairSync类，这是一个公平锁的实现，源码继承结构如下123static final class FairSync extends Sync &#123; ......&#125; FairSync继承与Sync，这是AQS的实现类，我们再来看一下Sync的源码继承结构123abstract static class Sync extends AbstractQueuedSynchronizer &#123; ......&#125; ReentrantLock只支持以独占锁的方式来获取锁，所以会实现AQS中的tryAcquire和tryRelease和isHeldExclusively这三个核心的方法，内部会用名叫Sync的内部抽象类来管理线程锁，当线程调用lock方法获取锁时，我们来看看FairSync的lock方法 123final void lock() &#123; acquire(1); &#125; 他会调用继承于AQS的acquire的方法，如下所示 123456789101112// 我们看到，这个方法，如果tryAcquire(arg) 返回true, 也就结束了。// 否则，acquireQueued方法会将线程压到队列中public final void acquire(int arg) &#123; // 此时 arg == 1 // 首先调用tryAcquire(1)一下，名字上就知道，这个只是试一试 // 因为有可能直接就成功了呢，也就不需要进队列排队了， // 对于公平锁的语义就是：本来就没人持有锁，根本没必要进队列等待(又是挂起，又是等待被唤醒的) if (!tryAcquire(arg) &amp;&amp; // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; selfInterrupt(); &#125;&#125; 当前线程会尝试去获取锁，调用FairSync实现的tryAcquire(1)方法,如下所示 1234567891011121314151617181920212223242526272829303132333435// 尝试直接获取锁，返回值是boolean，代表是否获取到锁// 返回true：1.没有线程在等待锁；2.重入锁，线程本来就持有锁，也就可以理所当然可以直接获取protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 如果state == 0 表示此时此刻没有线程持有锁 if (c == 0) &#123; // 虽然此时此刻锁是可以用的，但是这是公平锁，既然是公平，就得讲究先来后到， // 看看有没有别人在队列中等了半天了 if (!hasQueuedPredecessors() &amp;&amp; // 如果没有线程在等待，那就用CAS尝试一下，成功了就获取到锁了， // 不成功的话，只能说明一个问题，就在刚刚几乎同一时刻有个线程抢先了 =_= // 因为刚刚还没人的，我判断过了😂😂😂 compareAndSetState(0, acquires)) &#123; // 到这里就是获取到锁了，标记一下，告诉大家，现在是我占用了锁 setExclusiveOwnerThread(current); return true; &#125; &#125; // 判断是否是重入的线程，需要操作：state=state+1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; // 如果到这里，说明前面的if和else if都没有返回true，说明没有获取到锁 // 回到上面一个外层调用方法继续看: // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); return false;&#125; 如果返回false的话，会把当前线程加入阻塞队列中，现在我们继续来进入AQS中的addWaiter方法12345678910111213141516171819202122232425262728293031323334/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ // 此方法的作用是把线程包装成node，同时进入到队列中 // 参数mode此时是Node.EXCLUSIVE，代表独占模式 private Node addWaiter(Node mode) &#123; //mode值下一个等待的线程节点，默认为null Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后 Node pred = tail; // tail!=null =&gt; 队列不为空(tail==head的时候，其实队列是空的，不过不管这个吧) if (pred != null) &#123; // 设置自己的前驱 为当前的队尾节点 node.prev = pred; // 用CAS把自己设置为队尾, 如果成功后，tail == node了 if (compareAndSetTail(pred, node)) &#123; // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连， // 上面已经有 node.prev = pred // 加上下面这句，也就实现了和之前的尾节点双向连接了 pred.next = node; // 线程入队了，可以返回了 return node; &#125; &#125; // 仔细看看上面的代码，如果会到这里， // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队) enq(node); return node; &#125; 如果队列是空的，或者有竞争，就调用enq方法采用自旋的方式来加入阻塞队列，如下所示 123456789101112131415161718192021222324252627282930313233343536373839/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */ // 采用自旋的方式入队 // 之前说过，到这个方法只有两种可能：等待队列为空，或者有线程竞争入队， // 自旋在这边的语义是：CAS设置tail过程中，竞争一次竞争不到，我就多次竞争，总会排到的 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 之前说过，队列为空也会进来这里 if (t == null) &#123; // Must initialize // 初始化head节点 // 细心的读者会知道原来head和tail初始化的时候都是null，反正我不细心 // 还是一步CAS，你懂的，现在可能是很多线程同时进来呢 if (compareAndSetHead(new Node())) // 给后面用：这个时候head节点的waitStatus==0, 看new Node()构造方法就知道了 // 这个时候有了head，但是tail还是null，设置一下， // 把tail指向head，放心，马上就有线程要来了，到时候tail就要被抢了 // 注意：这里只是设置了tail=head，这里可没return哦，没有return，没有return // 所以，设置完了以后，继续for循环，下次就到下面的else分支了 tail = head; &#125; else &#123; // 下面几行，和上一个方法 addWaiter 是一样的， // 只是这个套在无限循环里，反正就是将当前线程排到队尾，有线程竞争的话排不上重复排 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; // 然后再次回到这段代码了 // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); 我们再来看一看acquireQueued方法，在进入阻塞队列中，他会再次尝试获取锁，如下所示1234567891011121314151617181920212223242526272829303132333435// 下面这个方法，参数node，经过addWaiter(Node.EXCLUSIVE)，此时已经进入阻塞队列// 注意一下：如果acquireQueued(addWaiter(Node.EXCLUSIVE), arg))返回true的话，// 意味着上面这段代码将进入selfInterrupt()，所以正常情况下，下面应该返回false// 这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//获取当前node的前一个node // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列 // 所以当前节点可以去试抢一下锁 // 这里我们说一下，为什么可以去试试： // 首先，它是队头，这个是第一个条件，其次，当前的head有可能是刚刚初始化的node， // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程 // 也就是说，当前的head不属于任何一个线程，所以作为队头，可以去试一试， // tryAcquire已经分析过了, 忘记了请往前看一下，就是简单用CAS试操作一下state if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 到这里，说明上面的if分支没有成功，要么当前node本来就不是队头， // 要么就是tryAcquire(arg)没有抢赢别人，继续往下看 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 当前线程获取锁失败会调用shouldParkAfterFailedAcquire方法，如下所示12345678910111213141516171819202122232425262728293031323334353637383940414243444546 // 刚刚说过，会到这里就是没有抢到锁呗，这个方法说的是："当前线程没有抢到锁，是否需要挂起当前线程？" // 第一个参数是前驱节点，第二个参数才是代表当前线程的节点 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; //下面的三个判断符合下列三种规则 // 规则1：如果前继的节点状态为SIGNAL，表明当前节点需要unpark(唤醒)，则返回成功，此时 acquireQueued方法的第12行（parkAndCheckInterrupt）将导致线程阻塞 // 规则2：如果前继节点状态为CANCELLED(ws&gt;0)，说明前置节点已经被放弃，则回溯到一个非取消的前继节点，返回false，acquireQueued方法的无限循环将递归调用该方法，直至规则1返回true，导致线程阻塞 // 规则3：如果前继节点状态为非SIGNAL、非CANCELLED，则设置前继的状态为SIGNAL，返回false后进入acquireQueued的无限循环，与规则2同 // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点 waitStatus大于0 ，之前说过，大于0 说明前驱节点取消了排队。这里需要知道这点： // 进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。 // 所以下面这块代码说的是将当前节点的prev指向waitStatus&lt;=0的节点， if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 仔细想想，如果进入到这个分支意味着什么 // 前驱节点的waitStatus不等于-1和1，那也就是只可能是0，-2，-3 // 在我们前面的源码中，都没有看到有设置waitStatus的，所以每个新的node入队时，waitStatu都是0 // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;// 回到下面的代码// if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;// parkAndCheckInterrupt()) 如果此线程取消了竞争（也就是waitStatus&gt;0），就会进入阻塞中断，这个时候需要一个契机将他唤醒，所有要不断循环前一个节点作为需要作为唤醒的契机（这在后面的释放锁操作会有说明），返回false，如果返回true的话，接下来会调用parkAndCheckInterrupt方法来检查中断操作，如下所示 123456// 这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的// 这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒=======private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放锁看完了获取锁，现在来看看释放锁的实现，在前面reentrantLock的使用用例中，当线程执行完会在finally块中执行reentrantLock.unlock()来释放锁，如下所示123public void unlock() &#123; sync.release(1);&#125; 他会调用release(1)方法,如下所示 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 上述会尝试执行释放锁的操作，调用FairSync实现的tryRelease方法，和获取锁的路子类似 1234567891011121314protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 是否完全释放锁 boolean free = false; // 其实就是重入的问题，如果c==0，也就是说没有嵌套锁了，可以释放了，否则还不能释放掉 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 如果释放锁成功，且head不为空就会调用unparkSuccessor方法来唤醒后继的线程，如下所示：1234567891011121314151617181920212223242526272829303132// 唤醒后继节点// 从上面调用处知道，参数node是head头结点private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 如果head节点当前waitStatus&lt;0, 将其修改为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 下面的代码就是唤醒后继节点，但是有可能后继节点取消了等待（waitStatus==1） // 从队尾往前找，找到waitStatus&lt;=0的所有节点中排在最前面的 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后往前找，仔细看代码，不必担心中间有节点取消(waitStatus==1)的情况 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 唤醒线程 LockSupport.unpark(s.thread);&#125; 唤醒的线程会在如下代码继续进行1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 刚刚线程被挂起在这里了 return Thread.interrupted();&#125; 注意：LockSupport是并发包中针对线程阻塞操作的工具类 执行完，这时会返回到acquireQueued(final Node node, int arg)方法，而方法中的无限循环for(;;)就是为了唤醒的线程重新去获取锁，直到异常退出或者执行完 总结AQS是由CLH锁实现的,是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋，在整个并发包中，很多地方你都会看见AQS的身影，他在并发控制的作用无法替代 参考https://hongjiev.github.io/2017/06/16/AbstractQueuedSynchronizer/http://blog.csdn.net/chen77716/article/details/6641477]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发包-线程池]]></title>
      <url>%2F2017%2F06%2F13%2Fthreadpool%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言线程是应用程序执行任务的最小单元，在jvm中允许应用程序在多个线程同时执行，竟可能利用服务器的性能来最大化提高应用程序的吞吐量和响应性，但是往往在生产环境中，如果我们为每一个任务分配一个线程，当创建足够多的时候，就会存在一些明显的缺陷： 线程生命周期开销高：线程的创建和销毁是需要一定的时间，并且需要JVM和操作系统相互辅助操作，在应用程序创建足够多的线程时，这个消耗也是很可观的 资源消耗：活跃的线程会消耗大量的内存，如果你的处理器数量少于你的处理线程的数量，这将会产生大量的闲置线程，这会占用大量的内存，以及在共享资源的竞争上会产生其他的性能开销，同时也给GC带来压力 稳定性：每个平台对于线程都会有一定的限制，对于JVM来讲，在JVM的启动参数或者Thread构造函数请求栈的大小这都对线程的数量造成一定的限制，如果超过了这些限制，很有可能会造成难以恢复的OutOfMemoryError的异常，还有操作系统本身对线程的一些限制，都会造成应用程序的不稳定基于以上的一些缺陷，所以需要有一种机制来管理线程，这就出现了Executor框架 Executor框架Executor框架是JDK1.5提出的，由JAVA大神Doug Lea编写，他很详细的描述了线程的生命周期，现在我们来看一看Executor框架的结构图 ExecutorExecutor是Executor框架最顶层的接口，也是最核心的功能，我们进入Executor接口的源码（JDK1.8）看一看12345678910111213public interface Executor &#123; /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &#123;@code Executor&#125; implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);&#125; 由上可知，Executor接口只有一个execute方法，他的功能从注释中可知：就是提交一个任务命令，然后在将来的某个时间段执行该（一组或者一个）任务命令，显而易见，这是个执行线程的方法，他将线程的提交过程和线程的执行过程解耦出来，这就相当于生产者-消费者模式，提交过程相当于生产者，执行过程相当于消费者，然后以一个异步的执行策略来执行任务（当然这并不是严格要求的），这提交和执行过程中要符合内存一致性效果，就是线程中将Runnable对象提交到Executor执行之前要遵循happen-before原则 ExecutorService在上述的Executor中，只是对于线程的提交，执行的描述，并没有考虑到任务线程的关闭，在线程的整个生命周期中，关闭线程也是非常重要的一部分，如果不能正常的关闭，会导致应用程序一些意想不到的异常，所以ExecutorService的作用是扩展了Executor，完善了任务线程的生命周期的管理，以及跟踪一个或多个异步的任务线程执行状况而生成Future，主要的方法如下： isShutdown() ：判断当前应用程序是否关闭，如果已关闭返回true shutdown()：启动顺序关闭机制，执行此前提交的任务，不再接受新的任务 shutdownNow() ：试图立刻执行关闭所有正在执行的任务，并且返回等待执行的任务列表 submit(Runnable task):submit是对 Executor接口中的execute方法的一个扩展，使用Future对异步任务线程的执行控制 isTerminated() ：判断所有的任务是否都已经完成，完成就返回true invokeAny(Collection&lt;? extends Callable&gt; tasks):执行给定的任务，如果某个任务完成则返回该结果 invokeAll(Collection&lt;? extends Callable&gt; tasks):执行给定的任务，当所有的任务完成之后，返回保持任务状态和结果的Futrue列表 AbstractExecutorServiceAbstractExecutorService是ExecutorService的默认实现，主要是使用RunnableFuture（它是一个Runnable的Futrue，指可以执行Runnable并可以访问其结果）实现submit，invokeAny和invokeAll等方法，而生成RunnableFuture的核心方法就是newTaskFor，他的含义给执行的任务线程生成一个RunnableFuture ScheduledExecutorService和ScheduledThreadPoolExecutorScheduledExecutorService是一种延迟执行的ExecutorService，ScheduledThreadPoolExecutor是其实现类，指安排指定的延迟时间来执行任务，主要方法schedule是指创建并执行在给定延迟时间启用的ScheduledFuture（它是一个scheduled的Future,指一种延迟并可结果化的操作） ForkJoinPoolForkJoinPool是对AbstractExecutorService的扩展，是基于分而治之的思想，将复杂的任务异步的分解成多个小任务去执行，该类也是ForkJoin框架核心的类，这里就不在赘述了 ThreadPoolExecutor任务的状态ThreadPoolExecutor顾名思义线程池，是Executor框架的主要实现方法，他实现了主要的任务线程执行和关闭过程，下面通过源码来分析一下（基于JDK1.8） ThreadPoolExecutor定义了五种任务线程的状态，它记录了线程池中的线程的声明周期： RUNNING：可以接受新的任务，也可以处理阻塞队列里的任务 SHUTDOWN：不接受新的任务，但是可以处理阻塞队列里的任务 STOP：不接受新的任务，不处理阻塞队列里的任务，中断正在处理的任务 TIDYING：过渡状态，也就是说所有的任务都执行完了，当前线程池已经没有有效的线程，这个时候线程池的状态将会TIDYING，并且将要调用terminated方法 TERMINATED：终止状态。terminated方法调用完成以后的状态 状态之间可以进行转换： RUNNING -&gt; SHUTDOWN：手动调用shutdown方法，或者ThreadPoolExecutor要被GC回收的时候调用finalize方法，finalize方法内部也会调用shutdown方法 (RUNNING or SHUTDOWN) -&gt; STOP：调用shutdownNow方法 SHUTDOWN -&gt; TIDYING：当队列和线程池都为空的时候 STOP -&gt; TIDYING：当线程池为空的时候 TIDYING -&gt; TERMINATED：terminated方法调用完成之后 源码定义如下：123456789private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; ThreadPoolExecutor处理某个状态拥有的活跃线程数量是用一个整形常量来表示，用前三位来表示状态，后29位来表示数量，我们先来看COUNT_BITS常量,通过计算可知它的值为29，在java中一个整形占用四个字节，一个字节是八位，所以一个整形占用32位，而COUNT_BITS表示的就是整形中的后29位，它的含义是来存储有效线程的线程数，那状态又怎么表示了，我们来看RUNNING状态：-1&lt;&lt;COUNT_BITS这个左移位运算（丢弃COUNT_BITS数量的最高位，0补最低位），通过-1&lt;&lt;29得到11100000000000000000000000000000，前3位为111，就是表示RUNNING的状态标志，其它四种状态也跟此表示方法一样来标志上述代码中，常量ctl表示的是初始线程池的状态和数量，默认是RUNNING状态和0个活跃任务线程数量，而CAPACITY表示的是线程池的容量，通过（1&lt;&lt;29）-1运算获得，清楚了任务线程的状态和数量的含义，我们来看一下三个重要的对任务线程的状态和数量操作的内部静态方法 123456// 得到状态，CAPACITY的非操作得到的二进制位11100000000000000000000000000000，然后做在一个与操作，相当于直接取前3位的的值private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 得到线程数，也就是后29位的数字。 直接跟CAPACITY做一个与操作即可，CAPACITY就是的值就 1 &lt;&lt; 29 - 1 = 00011111111111111111111111111111。 与操作的话前面3位肯定为0，相当于直接取后29位的值private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 或操作。相当于更新数量和状态两个操作private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 任务的初始化ThreadPoolExecutor提供了初始化的构造方法，如下所示：123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; corePoolSize：线程池中的线程数，如果执行的线程数大于该数量，就进入阻塞队列进行等待 maximumPoolSize：线程池允许最大的线程数 keepAliveTime：执行的线程数大于该线程池中的线程数，多余的空闲线程在回收前等待新任务的时间 unit：时间单位 workQueue：保存执行任务的阻塞队列 threadFactory：创建线程的线程工厂 handler：执行被阻止时使用的处理程序，因为线程已达到线程限制和队列容量 但是JDK并不推荐直接用构造函数来进行线程池的初始化，直接初始化的灵活性和管理上并不好，于是提供了executors线程池工厂类，它应用与各种不同场景下对线程池的初始化需求，主要有如下方法： newFixedThreadPool：创建一个固定数量级的线程池，如果活跃线程数超过线程池数量，它们将在等待队列中知道线程池中的线程可用 newSingleThreadExecutor：创建单个线程的线程池，如果该单线程由于故障等原因停止，想要执行后续的任务，则会创建新的线程去执行 newCachedThreadPool：创建一个可缓存的线程池，根据需要，如果有新的任务进来，线程池没有多余的线程可用，则在线程池中创建新的线程执行，有就复用已创建的线程，如果线程有60秒未被使用则会从缓存中回收 newSingleThreadScheduledExecutor：创建单个线程的线程池，以延迟或定时的方式来执行任务，如果该单线程由于故障等原因停止，想要执行后续的任务，则会创建新的线程去执行 newScheduledThreadPool：创建一个固定的线程池，以延迟或者定时的方式来执行任务 任务的执行ThreadPoolExecutor实现了execute方法，具体代码如下12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 执行execute方法总共有三个步骤，也就是上述代码的三个判断 if (workerCountOf(c) &lt; corePoolSize) ：如果当前的工作线程数量少于线程池的基本数量，则直接创建新的工作线程执行，调用addWorker方法 if (isRunning(c) &amp;&amp; workQueue.offer(command))：如果当前的工作线程数量大于等于线程池的基本数量，且是RUNNING的状态，就加入等待阻塞队列，如果成功的话，再进行第二次验证，如果在阻塞队列中由于另一个线程关闭线程池或者线程出现死亡了，这个时候线程并不在RUNNING状态，就把刚加入的线程remove掉，成功的话就调用reject方法，否则判断工程线程是否为0，是就调用addWorker()加入一个新线程 如果放进阻塞等待队列失败的话，那我们尝试添加一个新的线程执行，如果失败的话，则应该是线程池饱和或者关闭了，调用reject方法 注意：在addWorker方法中，第二boolean参数的true代表以corePoolSize为标准，false以maximumPoolSize为基准 execute方法的核心就是在线程池中如何启动一个线程，也就是addWorker方法，在深入addWorker方法之前先要了解线程在线程池的表现的基本单元载体类Worker，Worker是一个内部类，我们来看看他的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; // 使用ThreadFactory构造Thread，这个构造的Thread内部的Runnable就是本身，也就是Worker。所以得到Worker的thread并start的时候，会执行Worker的run方法，也就是执行ThreadPoolExecutor的runWorker方法 //把状态位设置成-1，这样任何线程都不能得到Worker的锁，除非调用了unlock方法。这个unlock方法会在runWorker方法中一开始就调用，这是为了确保Worker构造出来之后，没有任何线程能够得到它的锁，除非调用了runWorker之后，其他线程才能获得Worker的锁 setState(-1); this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; worker是线程池的执行单元，实现了AQS同步锁和runnable接口，接下来看一下addWorker源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 两个参数，firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用线程池的基本大小，为false使用线程池最大大小// 返回值是boolean类型，true表示新任务被接收了，并且执行了。否则是falseprivate boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 线程池当前状态 // 这个判断转换成 rs &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty)。 // 概括为3个条件： // 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态 // 2. 线程池不在RUNNING状态，线程池接受了新的任务 // 3. 线程池不在RUNNING状态，阻塞队列为空。 满足这3个条件中的任意一个的话，拒绝执行任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 线程池线程个数 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) // 如果线程池线程数量超过线程池最大容量或者线程数量超过了基本大小(core参数为true，core参数为false的话判断超过最大大小) return false; // 超过直接返回false if (compareAndIncrementWorkerCount(c)) // 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环 break retry; c = ctl.get(); // 重新检查状态 if (runStateOf(c) != rs) // 如果状态改变了，重新循环操作 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 走到这一步说明cas操作成功了，线程池线程数量+1 boolean workerStarted = false; // 任务是否成功启动标识 boolean workerAdded = false; // 任务是否添加成功标识 Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; // 得到线程池的可重入锁 w = new Worker(firstTask); // 基于任务firstTask构造worker final Thread t = w.thread; // 使用Worker的属性thread，这个thread是使用ThreadFactory构造出来的 if (t != null) &#123; // ThreadFactory构造出的Thread有可能是null，做个判断 mainLock.lock(); // 锁住，防止并发 try &#123; // 在锁住之后再重新检测一下状态 int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // 如果线程池在RUNNING状态或者线程池在SHUTDOWN状态并且任务是个null if (t.isAlive()) // 判断线程是否还活着，也就是说线程已经启动并且还没死掉 throw new IllegalThreadStateException(); // 如果存在已经启动并且还没死的线程，抛出异常 workers.add(w); // worker添加到线程池的workers属性中，是个HashSet int s = workers.size(); // 得到目前线程池中的线程个数 if (s &gt; largestPoolSize) // 如果线程池中的线程个数超过了线程池中的最大线程数时，更新一下这个最大线程数 largestPoolSize = s; workerAdded = true; // 标识一下任务已经添加成功 &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; if (workerAdded) &#123; // 如果任务添加成功，运行任务，改变一下任务成功启动标识 t.start(); // 启动线程，这里的t是Worker中的thread属性，所以相当于就是调用了Worker的run方法 workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) // 如果任务启动失败，调用addWorkerFailed方法 addWorkerFailed(w); &#125; return workerStarted;&#125; 在上述的代码中，如果任务添加成功，就会执行t.start()方法，也就是执行worker中的run方法，而worker中的run方法调用了runWorker(this)方法，接下来看一下runWorker方法： 1234567891011121314151617181920212223242526272829303132333435363738394041final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 得到当前线程 Runnable task = w.firstTask; // 得到Worker中的任务task，也就是用户传入的task w.firstTask = null; // 将Worker中的任务置空 w.unlock(); // allow interrupts。 boolean completedAbruptly = true; try &#123; // 如果worker中的任务不为空，继续知否，否则使用getTask获得任务。一直死循环，除非得到的任务为空才退出 while (task != null || (task = getTask()) != null) &#123; w.lock(); // 如果拿到了任务，给自己上锁，表示当前Worker已经要开始执行任务了，已经不是闲置Worker(闲置Worker的解释请看下面的线程池关闭) // 在执行任务之前先做一些处理。 1. 如果线程池已经处于STOP状态并且当前线程没有被中断，中断线程 2. 如果线程池还处于RUNNING或SHUTDOWN状态，并且当前线程已经被中断了，重新检查一下线程池状态，如果处于STOP状态并且没有被中断，那么中断线程 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); // 任务执行前需要做什么，ThreadPoolExecutor是个空实现 Throwable thrown = null; try &#123; task.run(); // 真正的开始执行任务，调用的是run方法，而不是start方法。这里run的时候可能会被中断，比如线程池调用了shutdownNow方法 &#125; catch (RuntimeException x) &#123; // 任务执行发生的异常全部抛出，不在runWorker中处理 thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); // 任务执行结束需要做什么，ThreadPoolExecutor是个空实现 &#125; &#125; finally &#123; task = null; w.completedTasks++; // 记录执行任务的个数 w.unlock(); // 执行完任务之后，解锁，Worker变成闲置Worker &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); // 回收Worker方法 &#125;&#125; 在runWorker方法中，如果任务为空，while表达式有个轮询的方式去获取任务，如果task为null的话，会去获取新的任务，接下来看一下获取任务的方法getTask() 123456789101112131415161718192021222324252627282930313233343536373839404142434445private Runnable getTask() &#123; boolean timedOut = false; // 如果使用超时时间并且也没有拿到任务的标识 retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 如果线程池是SHUTDOWN状态并且阻塞队列为空的话，worker数量减一，直接返回null(SHUTDOWN状态还会处理阻塞队列任务，但是阻塞队列为空的话就结束了)，如果线程池是STOP状态的话，worker数量建议，直接返回null(STOP状态不处理阻塞队列任务)[方法一开始注释的2，3两点，返回null，开始Worker回收] if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; boolean timed; // 标记从队列中取任务时是否设置超时时间，如果为true说明这个worker可能需要回收，为false的话这个worker会一直存在，并且阻塞当前线程等待阻塞队列中有数据 for (;;) &#123; int wc = workerCountOf(c); // 得到当前线程池Worker个数 // allowCoreThreadTimeOut属性默认为false，表示线程池中的核心线程在闲置状态下还保留在池中；如果是true表示核心线程使用keepAliveTime这个参数来作为超时时间 // 如果worker数量比基本大小要大的话，timed就为true，需要进行回收worker timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if (wc &lt;= maximumPoolSize &amp;&amp; ! (timedOut &amp;&amp; timed)) // 方法一开始注释的1，4两点，会进行下一步worker数量减一 break; if (compareAndDecrementWorkerCount(c)) // worker数量减一，返回null，之后会进行Worker回收工作 return null; c = ctl.get(); // 重新检查线程池状态 if (runStateOf(c) != rs) // 线程池状态改变的话重新开始外部循环，否则继续内部循环 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; try &#123; // 如果需要设置超时时间，使用poll方法，否则使用take方法一直阻塞等待阻塞队列新进数据 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; // 闲置Worker被中断 &#125; &#125;&#125; 任务线程会从阻塞队列中获取，如果发生如下情况，那么worker需要被回收： Worker个数比线程池最大大小要大 线程池处于STOP状态 线程池处于SHUTDOWN状态并且阻塞队列为空 使用超时时间从阻塞队列里拿数据，并且超时之后没有拿到数据(allowCoreThreadTimeOut || workerCount &gt; corePoolSize) 回收会在runWorker方法中发生如上事件抛出异常，在finally块中调用processWorkerExit方法进行回收 1234567891011121314151617181920212223242526272829303132private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // 如果Worker没有正常结束流程调用processWorkerExit方法，worker数量减一。如果是正常结束的话，在getTask方法里worker数量已经减一了 decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发问题 try &#123; completedTaskCount += w.completedTasks; // 记录总的完成任务数 workers.remove(w); // 线程池的worker集合删除掉需要回收的Worker &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池 int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; // 如果线程池还处于RUNNING或者SHUTDOWN状态 if (!completedAbruptly) &#123; // Worker是正常结束流程的话 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // 不需要新开一个Worker &#125; // 新开一个Worker代替原先的Worker // 新开一个Worker需要满足以下3个条件中的任意一个： // 1. 用户执行的任务发生了异常 // 2. Worker数量比线程池基本大小要小 // 3. 阻塞队列不空但是没有任何Worker在工作 addWorker(null, false); &#125;&#125; 在回收Worker的时候线程池会尝试结束自己的运行，tryTerminate方法： 123456789101112131415161718192021222324252627282930313233343536final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 满足3个条件中的任意一个，不终止线程池 // 1. 线程池还在运行，不能终止 // 2. 线程池处于TIDYING或TERMINATED状态，说明已经在关闭了，不允许继续处理 // 3. 线程池处于SHUTDOWN状态并且阻塞队列不为空，这时候还需要处理阻塞队列的任务，不能终止线程池 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 走到这一步说明线程池已经不在运行，阻塞队列已经没有任务，但是还要回收正在工作的Worker if (workerCountOf(c) != 0) &#123; // 由于线程池不运行了，调用了线程池的关闭方法，在解释线程池的关闭原理的时候会说道这个方法 interruptIdleWorkers(ONLY_ONE); // 中断闲置Worker，直到回收全部的Worker。这里没有那么暴力，只中断一个，中断之后退出方法，中断了Worker之后，Worker会回收，然后还是会调用tryTerminate方法，如果还有闲置线程，那么继续中断 return; &#125; // 走到这里说明worker已经全部回收了，并且线程池已经不在运行，阻塞队列已经没有任务。可以准备结束线程池了 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发 try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; // cas操作，将线程池状态改成TIDYING try &#123; terminated(); // 调用terminated方法 &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); // terminated方法调用完毕之后，状态变为TERMINATED termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; // else retry on failed CAS &#125;&#125; ThreadPoolExecutor的关闭线程池的关闭有两个重要的方法：shutdown和shutdownNow，下面看一下shutdown方法的源码：12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 关闭的时候需要加锁，防止并发 try &#123; checkShutdownAccess(); // 检查关闭线程池的权限 advanceRunState(SHUTDOWN); // 把线程池状态更新到SHUTDOWN interruptIdleWorkers(); // 中断闲置的Worker onShutdown(); // 钩子方法，默认不处理。ScheduledThreadPoolExecutor会做一些处理 &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池，上面已经分析过了&#125; 再看看中断线程的interruptIdleWorkers方法方法： 1234567891011121314151617181920212223242526// 调用他的一个重载方法，传入了参数false，表示要中断所有的正在运行的闲置Worker，如果为true表示只打断一个闲置Workerprivate void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 中断闲置Worker需要加锁，防止并发 try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 拿到worker中的线程 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; // Worker中的线程没有被打断并且Worker可以获取锁，这里Worker能获取锁说明Worker是个闲置Worker，在阻塞队列里拿数据一直被阻塞，没有数据进来。如果没有获取到Worker锁，说明Worker还在执行任务，不进行中断(shutdown方法不会中断正在执行的任务) try &#123; t.interrupt(); // 中断Worker线程 &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); // 释放Worker锁 &#125; &#125; if (onlyOne) // 如果只打断1个Worker的话，直接break退出，否则，遍历所有的Worker break; &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125;&#125; 轮询所有的worker,判断是不是中断的线程且可以拿到锁（判断闲置的worker）,就中断该线程,现在来看一看另一个关闭的shutdownNow方法12345678910111213141516// shutdownNow方法会有返回值的，返回的是一个任务列表，而shutdown方法没有返回值public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // shutdownNow操作也需要加锁，防止并发 try &#123; checkShutdownAccess(); // 检查关闭线程池的权限 advanceRunState(STOP); // 把线程池状态更新到STOP interruptWorkers(); // 中断Worker的运行 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池，上面已经分析过了 return tasks;&#125; shutdownNow方法的语义是立刻关闭所有的worker,而不是shutdown方法关闭闲置的方法,而且shutdownNow直接将状态改为STOP，这样的话，不会执行新的任务，同时回收所有的worker，而shutdown只是将状态变为SHUTDOWN,接下来看一看shutdownNow的中断worker方法interruptWorkers():12345678910private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 中断Worker需要加锁，防止并发 try &#123; for (Worker w : workers) w.interruptIfStarted(); // 中断Worker的执行 &#125; finally &#123; mainLock.unlock(); // 解锁 &#125;&#125; Worker的interruptIfStarted方法中断Worker的执行： 12345678910void interruptIfStarted() &#123; Thread t; // Worker无论是否被持有锁，只要还没被中断，那就中断Worker if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); // 强行中断Worker的执行 &#125; catch (SecurityException ignore) &#123; &#125; &#125;&#125; 总结在不同的应用场景下，线程池的生态也越来越大，它的意义是让用户更加高效的应用线程去执行不同的任务，为线程提供完整的生命周期，虽然线程池提供了很好的线程复用机制，但是并不是就可以滥用线程池来创建去执行任务，在操作系统或者JVM平台下都有对于线程一定的限制，合理的使用才能更加的高效！！！ 参考http://www.jianshu.com/p/758a99c83ef1http://fangjian0423.github.io/2016/03/22/java-threadpool-analysis/《java并发编程实战》第六章]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发关键字-synchronized]]></title>
      <url>%2F2017%2F05%2F24%2Fsynchronized%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言synchronized（同步）是java中在多处理器中实现线程安全最基本的手段，在java语言规范（第三版）中提到锁的同步机制，指在java中，线程之间通信的机制最基本的就是同步化，此方法是使用监视器（monitor，后面会讲到）实现的，每个对象与一个监视器关联，一个线程可以加锁和解锁此监视器，而且同一时间段只有一个线程持有监视器上的锁，其他线程就会被阻塞，直到他们可以在该监视器上获取锁 其实一个对象都可以看做一个锁，在java中，有三种对于synchronized的用法 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 当一个线程访问synchronized修饰的代码块时，他必须要获取一个锁，根据不同的修饰方式来获取所对应的对象的锁，退出或者是发生异常时释放锁，下面将一步一步深入锁的实现 锁的实现原理我们先将通过一个简单的同步代码开始12345678public class SynchronizedTest &#123; public static Object object = new Object(); public static void main(String[] args)&#123; synchronized(object) &#123; // synchronized test &#125; &#125;&#125; 上述代码main函数中获取了object的锁，我们用javap命令工具反编译该生成的class文件，信息如下1234567891011121314151617181920212223242526272829303132333435363738394041Compiled from &quot;SynchronizedTest.java&quot;public class SynchronizedTest &#123; public static java.lang.Object object; public SynchronizedTest(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return public static void main(java.lang.String[]); Code: 0: getstatic #3 // Field object:Ljava/lang/Object; 3: dup 4: astore_1 5: monitorenter 6: aload_1 7: monitorexit 8: goto 16 11: astore_2 12: aload_1 13: monitorexit 14: aload_2 15: athrow 16: return Exception table: from to target type 6 8 11 any 11 14 11 any static &#123;&#125;; Code: 0: new #4 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: putstatic #3 // Field object:Ljava/lang/Object; 10: return&#125; 由上述反编译class文件的执行代码可知，在main函数中执行synchronized代码块使用了monitorenter和monitorexit两个字节码指令，JVM通过monitorenter字节码指令来获取对象的锁，通过monitorexit字节码指令来释放该对象的锁，当执行monitorenter字节码指令时，首先会尝试获取对象的锁，如果该对象没有没有被锁定或者当前线程已经拥有了该锁，则锁的计数器加1，相应的执行monitorexit字节码指令释放锁的时候会减1，当计数器为0表示对象没有锁定，如果一个线程获取锁失败时，那当前线程就必须被阻塞等待，直到对象锁被另一对象释放，下面我们通过介绍对象头和monitor以及JVM对锁的优化措施进一步了解如何获取对象的锁和释放对象的锁。 对象头在HotSpot虚拟机中，对象的内存布局分为三部分：对象头，实例数据和对齐填充，其中对象头是对象的内存布局中很重要的部分，他分为两个部分的信息，第一个部分存储的是对象本身运行时的数据，比如哈希码，GC分代年龄等，空间大小根据32位和64位的虚拟机分别为32bit和64bit，这还有另一个官方称号叫做“Mark Word“，他是实现轻量级锁和偏向锁的关键，这个后面会讲到，另一个部分用于存储指向方法区对象类型数据的指针，如果存储的是对象数组的话，还有一部分空间存储该数组的长度，默认的存储结构如下所示（32位虚拟机为例）： 考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构，以便在极小的空间内存储更多的信息，他会根据不同的状态复用自己的存储空间，如下所示 注意：其中偏向锁和轻量级锁这两个锁状态是JDK1.6之后引入的对锁的优化，之后会介绍 monitormonitor是线程私有的数据结构，每一个线程都有一个可用的monitor record列表，同时还有一个全局的可用列表，每一个锁住的对象都会和一个monitor关联，下面是monitor的结构组成： Owner：初始时为NULL表示当前没有任何线程拥有该monitor，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL； EntryQ：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor失败的线程。 RcThis：表示blocked或waiting在该monitor上的所有线程的个数。 Nest：用来实现重入锁的计数。 HashCode：保存从对象头拷贝过来的HashCode值（可能还包含GC age）。 Candidate：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值：0表示没有需要唤醒的线程，1表示要唤醒一个继任线程来竞争锁。 当一个线程进入同步代码块时，该代码块的同步对象通过Mark Work中的LockWord指向monitor的起始地址来关联monitor，由monitor来获取锁和释放锁 由于在java中，synchronized是一个重量级的锁，在多处理器并发中，效率总是不尽人意，JVM团队认为还有很大的改进空间，所以进行了锁的一系列的优化，下面将介绍锁的优化措施 偏向锁偏向锁是JDK1.6引入的一项锁优化，他的目的是消除在无竞争的情况下的同步原语，进一步提高程序的运行性能，说白了就是将同步的操作都消除掉，下面介绍如何获取锁和释放锁 获取锁当一个线程访问同步代码块时，会执行monitorenter字节码指令，对象会在Mark Word利用CAS操作记录关联的线程ID标识，操作成功就将标志位置为“01”，即偏向锁状态，再标记是否是偏向锁置为“1”,这样以后该线程,再次进入或者退出同步块时不需要其他的同步操作 释放锁如果有另一个线程尝试获取这个锁，偏向锁就会失效，这时会等待全局安全点（在这个时间点上没有字节码正在执行）撤销偏向锁状态到无锁状态（标志位“01”）或者膨胀到轻量级锁状态（标志位“00”），把是否是偏向锁置为0，它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 轻量级锁轻量级锁也是JDK1.6之中加入的新型锁机制，他的作用是在没有多线程的竞争下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗 获取锁当线程进入代码块时，该同步块的对象没有被锁定，当前线程会在自己的栈内创建一片空间来存储锁记录，然后再将Mark Word复制到锁记录中（官方在复制时会加一个Displaced前缀，就是Displaced Mark Word），然后尝试用CAS操作将Mark Word指向该线程的栈帧中的锁记录地址，如果成功了就会拥有该对象的锁，锁的标志位就变成了“00”，此时属于轻量级锁的状态，如果更新失败的话，说明当前对象存在竞争，那轻量级锁就会失效，膨胀成重量级锁，锁的标志位就变成了“10”，Mark Word指向的就是重量级锁的指针，后面的线程就会进程阻塞 释放锁轻量级锁释放锁是通过CAS操作将当前的Mark Word和当前线程的栈帧中的锁记录替换回去，如果成功的话，表示访问完整个同步块了，如果失败的话，表示有竞争出现，那就要马上放弃该锁，唤醒被挂起的线程在多核处理器的并发情况下，锁的状态会因为竞争的关系而变化，然而对于锁的状态会随着膨胀升级，从最开始的无锁，到偏向锁，再到轻量级锁，最后是重量级锁，锁只能是升级，不能降级，下面是三种锁状态的优缺点比较 JVM的团队在锁的优化下了很大的功夫，其实还有包括自旋锁和自适应自旋锁：以消耗CPU的代价换取加锁解锁的消耗，锁消除：最小的粒度消除加锁解锁的消耗，锁粗化：用一次加锁解锁的消耗来替代多次的加锁解锁的消耗，Synchronized的性能也越来越好，在合理的情况下使用不会比concurrent包下的lock机制性能差。 参考http://ifeve.com/java-synchronized/ 周志明《深入理解java虚拟机》第十三章 http://developer.51cto.com/art/201702/532564.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发关键字-volatile]]></title>
      <url>%2F2017%2F05%2F22%2Fvolatile%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言关键字volatile可以说是JVM提供的最轻量的同步机制了，也被称为轻量级的 synchronized，他在多处理器并发编程中提供了两个重要的特性： 保证共享变量的可见性，指一个线程修改了一个共享变量的值，其他线程能够读取到最新的修改值 禁止重排序，指禁止代码在执行过程中为优化性能而编译的执行顺序 如果在合适的情况下使用volatile关键字，程序会更加的高效，因为他对于synchronized来讲不会使线程上下文的调度和切换 volatile的实现原理volatile是如果实现可见性和禁止指令重排序的？先通过一段双重检查单例模式（double checked singleton）代码开始1234567891011121314public class DoubleCheckedSingleton &#123; private volatile static DoubleCheckedSingleton instance; private DoubleCheckedSingleton ()&#123;&#125; public static DoubleCheckedSingleton getInstance() &#123; if (instance == null) &#123;//single checked synchronized (DoubleCheckedSingleton.class) &#123; if (instance == null) &#123;//double checked instance = new DoubleCheckedSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 在上述代码中，由volatile修饰的赋值代码片段instance = new DoubleCheckedSingleton()；在x86处理器下通过工具获取JIT编译器生成的汇编代码指令如下所示：120x01a3de1d: movb $0x0,0x1104800(%esi);0x01a3de24: lock addl $0x0,(%esp); 相对于普通变量的赋值操作来讲，volatile修饰的共享变量的在赋值后多执行了lock addl $0x0,(%esp)指令操作，其中lock指令前缀在多核处理器中会做两件事： 将当前CPU缓存行的数据写回到主内存； 这个写回内存的操作会导致在其它CPU里缓存了该内存地址的数据无效。 处理器为了更加高效的运行，他不会直接与主内存进行通信，而是在先读取到其处理器内部缓存进行一系列的操作，但是不是立刻会回写到主内存中，对于volatile修饰的共享变量进行写操作，JVM会向该处理器发送一条Lock前缀的指令，锁住该缓存（早期的处理器是通过锁住整个总线，效率较低），并使用缓存一致性来确保修改的原子性，该操作称为“缓存锁定”，然后引起该处理器将内部缓存回写到主内存中，在确保缓存一致性的情况下，处理器通过嗅探技术访问主内存和内部缓存，确保处理器内部缓存和主内存上的状态保持一致，如果一个处理器在内部缓存对一个共享地址进行写操作时，该处理器会无效其对应的缓存，再下次访问该内存地址时，进行读取主内存到该处理器内部缓存。 lock前缀指令也相当于一个内存屏障（Memory Barrier），如上所述，由于缓存锁定操作，这样让该指令执行完，下一个指令才能执行，这个就实现了禁止了指令重排序，回写主内存同时使其他cpu该内存地址无效化，这样也就实现了可见性。 volatile关键字的使用如何使用volatile关键字，这里要了解确保并发安全的三个要素：原子性，可见性，顺序性，其中原子性指该操作不可分割，不受其他线程干扰，顺序性就是禁止指令重排序，对于关键字volatile来讲，volatile关键字保证了可见性和顺序性，同时它也是一个轻量级的synchronized,它在多处理器上的安全性体现在更加细微的操作，上述也提到，由于缓存一致性会保证单个读写操作的原子性，这样就符合并发安全的三要素了，然而在大多数程序中，大多数都是对一些共享变量的复合操作，比如i++操作，这就涉及到从主内存读取i到缓存中，在缓存中进行i+1的操作和将i写入主内存三个操作，这个就无法保证i++操作的原子性了，对于类似的复合操作来讲，如果共享变量具有原子性或者在一些原子操作的场合下，比如共享变量被concurrent包下的一些原子类修饰或者做一些CAS的一些操作，使用volatile是一个好的选择。 参考http://ifeve.com/volatile/ 周志明《深入理解java虚拟机》第十二章]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[NIO学习笔记]]></title>
      <url>%2F2017%2F03%2F17%2Fnio_note%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Channel和Buffer概述与实现所有的IO在NIO中都是从channel开始，channel像是流，buffer像是缓冲区，流可以读到缓冲区中，缓冲区可以写到流中，如下图所示 channel主要实现：FileChannel（文件流），DatagramChannel（数据报流-UDP），SocketChannel（socket流-TCP），ServerSocketChannel（服务端socket流-TCP） Buffer主要实现（主要是七个IO的基本类型）：ByteBuffer，CharBuffer，DoubleBuffer，FloatBuffer，IntBuffer，LongBuffer，ShortBuffer 简单的FileChannel读取数据到bufferbuffer内存模型的三个标记位：1.capacity(容量):buffer初始化时分配的容量2.position(位置):buffer内读取或写入的位置(读取或写入时position从0开始，如果在get(position)方法中有赋值，则从该位置开始)3.limit(最大容量):读取或写入的最大位置(读取时，置为position的位置，写入时，置为catacity的位置) 总结：不管是读取还是写入，都是从position标志的位置开始，到limit的位置结束 将channel读入buffer的示例如下：12345678910111213141516171819202122232425262728293031public void simpleChannelToBuffer(String fromPath)&#123; ByteBuffer buffer=null; RandomAccessFile file=null; FileChannel fileChannel=null; try &#123; file = new RandomAccessFile(fromPath,"rw"); fileChannel = file.getChannel();//建立到目的文件的通道 buffer = ByteBuffer.allocate(48);//分配48bytes的缓存区 int bytesRead =0 ; while((bytesRead=fileChannel.read(buffer))!=-1)&#123;//将通道内的文件数据读取到缓存区中 System.out.print(bytesRead); buffer.flip();//切换读模式，position置为0，limit置为写入时的position的位置 while(buffer.hasRemaining())&#123;//缓存区中是否有数据 System.out.print((char)buffer.get()); &#125; buffer.clear();//清空所有的数据，切换成写模式 //buffer.compact();//清空已经读取的数据，切换成写模式 &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; fileChannel.close(); file.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Scatter（分散）与Gather（聚集）Scatter（分散）：从channel读取数据写入多个buffer中 代码如下：1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray); //依次写入到buffer中 Gather（聚集）：将多个buffer的数据写入同一个channel中 代码如下1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.write(bufferArray); //依次写入到channel中 通道之间的数据传输12345678RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0; //读取的位置long count = fromChannel.size(); //读取的大小toChannel.transferFrom(position, count, fromChannel); //数据从fromChannel到toChannel//另一种写法：fromChannel.transferTo(position, count, toChannel); 注意：在SocketChannel中，传输的只会是准备好的数据，可能不足count大小，但是一有数据就会传输，只到buffer被填满 Selector如果你想单线程异步处理多个流，或者是你的应用打开了多个链接（通道），但是每个链接的的流量又很低，这就是Selector的工作 Selector首先要注册Channel，调用select()方法，一直阻塞到有某个注册的通道（Channel）有事件（数据或者新接连）就绪，等到这个方法返回，线程就开始处理这个通道中的事件 注意：与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以 selector可以监听channel以下四种不同类型的事件： OP_CONNECT(连接就绪) ：比如：socketChannel OP_ACCEPT(接收就绪)：比如：ServerSocketChannel OP_READ(读就绪) OP_WRITE(写就绪) 代码如下：123456789101112131415161718192021222324Selector selector = Selector.open();//创建一个selectorchannel.configureBlocking(false);//设置非阻塞模式//selector注册channel，事件可以多选，比如SelectionKey.OP_READ | SelectionKey.OP_WRITESelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); //返回读就绪的channel if(readyChannels == 0) continue; //如果还没有就继续监听 Set selectedKeys = selector.selectedKeys();//获取已就绪的channel的集合 Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next();//如下是判断哪种事件的channel的处理 if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();//该事件处理完就移除 &#125;&#125; pipeJava NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取 首先创建Pipe：Pipe pipe = Pipe.open();ThreadA向管道写数据，访问sink通道，代码如下：123456789Pipe.SinkChannel sinkChannel = pipe.sink();String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125; ThreadB向管道读取数据，访问source通道，代码如下：123Pipe.SourceChannel sourceChannel = pipe.source();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf); NIO和IONIO与IO的差异如下: IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 面向流和面向缓冲IO是面向流的，是一个不可控制处理方式，必须从头到尾直到读取所有的字节，没有缓冲的余地，而NIO是面向缓冲区的，它先将流中的数据读取到缓冲区中，然后再对数据进行处理，这样增加了数据处理的灵活性 阻塞和非阻塞IO是阻塞IO，当一个线程在读取数据的时候是阻塞的，再次期间不能做其他的任何事情，直到读写数据结束NIO是非阻塞IO，当一个线程在读取数据时，在该数据变成可读性之前，也就是空闲时间，可以做其他事情 选择器Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道 参考http://ifeve.com/java-nio-all/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM加载机制]]></title>
      <url>%2F2017%2F03%2F06%2Fjvm_classLoad%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 类加载过程类加载是指类通过JVM加载到内存开始到从内存中卸载出去的过程，其生命周期包括七个阶段：加载（Loading），验证（Verification），准备（Preparation），解析（Resolution），初始化（Initialization），使用（Using），卸载（Unloading），其中验证，准备和解析统称为链接过程，如下图所示： 类加载器类加载器作用于类的加载过程，每一个加载器都拥有独立的类名称空间，而JVM中，有两种类型的类加载器，一种是由C++语言实现的启动类加载器（Bootstrap ClassLoader），另一种是由java语言实现的，独立于虚拟机外部，并且全部继承抽象类java.lang.ClassLoader的类加载器 双亲委派模型在大部分开发程序中，一般都会使用三种系统提供的类加载器 启动类加载器（Bootstrap ClassLoader）：由C++语言编写，负责加载核心java库（存储在/jre/lib） 扩展类加载器（Extension ClassLoader）:由sun.misc.Launcher$ExtClassLoader实现，负责加载java扩展库（存储在） 应用程序类加载器（Application ClassLoader）：由sun.misc.Launcher$AppClassLoader实现，负责加载应用程序的java库（存储在java.class.path或CLASSPATH下的类库） 除了以上三个由系统实现的类加载器，还可以自己实现自定义的类加载器，而这些类的关系如下图所示： 如上类加载器的层次关系图，展示类加载器与类加载器之间的层次关系，这被称为双亲委派模型，每一层上面相当于是自己的父类加载器，以组合的模式来复用父类加载器的功能双亲委派模型的工作过程是：当一个加载器收到加载请求时，他首先会该请求委派给父类加载器去完成，最终传递到顶层的启动类加载器加载，只有当父类加载器加载不了，才会让子加载器自己去尝试加载，这样的话，可以防止代码的重复，比如A类的加载器要加载System，B类加载器也要加载System，双亲委派机制可能在系统实现的三个类加载器就可以加载了。 参考https://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM垃圾收集]]></title>
      <url>%2F2017%2F02%2F14%2Fjvm_gc%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 JVM垃圾收集技术需要关注三个步骤：1.哪些对象需要被回收，2.什么时候进行回收，3.如何进行回收 哪些对象需要被回收引用计数算法引用技术算法大致的过程是给对象分配一个引用计数器，当该对象被引用时，引用计数器就加一，该引用失效时，计数器就减一，当计数器为零时，说明该对象没有任何引用，就判定该对象可以被回收，虽然它的实现简单即高效，不过现代主流的JVM收集器都没有使用该算法，它有一个致命的缺陷是无法解决对象之间相互循环引用的问题 可达性分析算法可达性分析算法大致的过程是通过一系列的成为GC Roots的对象作为起点，他会向下进行搜索，所走过的路径成为引用链，如果一个对象到GC Roots没有任何的引用链（指该对象在程序中没有任何关系了），则说明该对象是可以被回收的在java语言中，可以作为GC Roots的对象包括如下： 虚拟机栈中的栈帧内的本地变量表中引用的对象 方法区中类静态属性引用和常量引用的对象 本地方法栈中引用的对象 什么时候进行回收在现代的内存分配中，堆被分为年轻代（8：1比例分配的1个Eden区和2个Survivor（FromSurvivor 和 ToSurvivor））和老年代，那什么时候会对年轻代和老年代的对象进行回收呢？ 首先，创建一个对象，JVM会给该对象分配一个对象年龄计数器，该对象大部分情况下会被优先分配到年轻代中的Eden区中（对于大对象，直接分配到老年代中），当Eden区中没有被分配的空间时，这时候JVM会触发一次Minor GC（年轻代GC），该对象的年龄置为1，存活下来的对象会往ToSurvivor区中移动，FromSurvivor区中存活的对象也复制到ToSurvivor区中，这时，ToSurvivor区和FromSurvivor区身份调换，当该对象的年龄增加到一定程度（默认是15）时，该对象会被晋升到老年代中，当然如果FromSurvivor中的相同年龄段的对象超过了一般，则大于该年龄段的对象直接晋升到老年代，在老年代中如果最大可用的连续空间小于晋升到老年代的对象大小，会进行一次Full GC 如何进行回收垃圾收集算法标记-清除算法（Mark-Sweep）标记-清除算法的回收过程分为两个阶段：标记和清除，标记就是标记哪些对象可以被回收（上面已经介绍过了），清除就是回收哪些被标记的可回收对象，这两个阶段的效率都不是很高，而且会产生大量的空间碎片，过程如下图 复制算法（Copying）复制算法的回收过程是将内存分成两块等量大小的内存块，一块是存储对象数据，另一块是保留区域（不存储任何数据），当存储对象数据的内存块用完了，就将还存活的对象复制到保留区域，然后将已使用过的内存块清理掉，原来存储对象数据的内存块变成了保留区，原来的保留区变成了存储对象数据的内存块，复制过程只需要移动堆顶的指针可以，简单高效，而且没有内存碎片化的存在，但是却将原有的内存缩小了一般，这也适合现代新生代的回收机制，因为新生代大部分都是朝生夕死，当然他们的内存划分比例不需要到达1：1，典型的就是8：1的eden区和survivor区，具体过程如下图： 标记-整理算法标记-整理算法的回收过程分为标记和整理两个阶段，它是标记-清除算法的改进版本，标记和标记-清除算法一致，不同的是，他不是直接对可回收的对象进行清除，而是将存活下来的对象往一端移动，再清理掉存活边界外的内存，它解决了标记-清除算法的内存碎片化问题，但是效率不是很高，具体过程如下图： 分代收集算法分代收集算法是指按照对象的存活周期，在堆中分为新生代和老年代，根据不同年代的特点使用不同收集算法的组合，比如新生代的特点是朝生夕死，对象存活周期短，使用复制算法，只需要少量的存活对象的复制成本即可，而老年代存活周期长，使用标记-清除或者标记-整理算法，因为它们的内存不大，没有额外的空间进行担保，这样就会形成一个组合来进行垃圾收集 垃圾收集器JVM的发展中，发布了很多的收集器，从最开始的单线程版的收集器serial(针对新生代)/serial old（针对老年代）收集器（JDK1.3以前）到多线程的并行收集器parallel scavenge（针对新生代）/parallel old(针对老年代)收集器，一直到现在针对多核，多CPU的环境下，充分的利用其硬件资源和重视快速响应的CMS收集器（JDK1.5以后）和G1收集器（JDK1.7以后） CMS收集器cms（Concurrent Mark Sweep）收集器是一款针对于最短回收时间停顿的老年代收集器，从名称上就可以知道该收集是基于标记-清除算法，它是把最耗时间的标记（GC Root Tracing）和清除过程使用了并发机制，和用户线程共同运行，大大的减少了停顿时间，具体过程如下：该收集器可以分为五个步骤： 初始标记：标记GC Roots所能关联的对象 并发标记：根据第一步的对象并发的遍历其他的对象（GC Roots Tracing） 重新标记：由于第二步的运行时间较长，对象可能会产生变化，开启多个线程重新标记已标记的对象 并发清理：并发的从需要被收集的对象集合中清除这些对象 并发重置：重置CMS收集器的数据，为下一次收集做准备 上述的五大步骤就是CMS收集的过程，整的来说已经实现了并发收集，低停顿，响应快等优点，但是还有三个明显的缺点： 由于CMS收集器是并发收集，它会占用其他线程的CPU资源，导致吞吐量低，部分线程变慢 CMS收集器无法处理在重新标记这个时间段里的垃圾，因为在重新标记期间，程序会产生新的对象或者变动，这是CMS收集器会预先预留一部分内存来处理，所以在一定的比例下（默认老年代空间使用率到达68%），就会触发CMS收集 CMS收集器采用的是标记-清除算法，所以会产生大量的内存碎片 G1收集器G1收集器（Garbage-First）是一款服务器型的垃圾收集器，它是由一个个大小相等的Regoin（内存区域）组成，通过一系列的标记阶段之后，之后优先收集那些垃圾最多的区域，它也保存了以往的分代收集的概念，但是新生代和老年代不需要设定固定的大小来控制，这样在内存的使用上提供了很大的灵活性，传统的堆分区如下：上述的是传统的把堆分成年轻代（1个eden区和2个survivor区），老年代，和永久代，在G1收集器中也保持了分代的理念，如下图: 如上图所述，他是用一个个内存区域的概念来存储分代对象，和CMS收集器不同的是它是用标记-整体算法来进行收集过程，整体的解决了内存碎片的问题 参考http://zhaoyanblog.com/archives/397.htmlhttps://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM运行时数据区域]]></title>
      <url>%2F2017%2F02%2F10%2Fjvm_list_range%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Java虚拟机（英语：Java Virtual Machine，缩写为JVM），一种能够运行Java bytecode的虚拟机，以堆栈结构机器来进行实做。最早由太阳微系统所研发并实现第一个实现版本，是Java平台的一部分，能够运行以Java语言写作的软件程序(来自wiki) 运行时数据区域JVM运行时数据区域由java栈，PC寄存器，本地方法栈，堆和方法区等五大数据区域组成，其结构图如下： 线程私有java栈java栈是线程私有的，它的生命周期会随着线程的创建而开始，摧毁而结束，它描述着java执行方法的内存模型：每个线程在执行方法时，会创建一个栈帧，该栈帧存储着方法的所有信息（局部变量表，操作数栈，栈数据区和方法出口等信息），一个方法的调用就好像是JVM对栈帧进行进栈到出栈的过程，由于其生命周期和线程一样，所以不需要GC PC寄存器PC寄存器也是线程私有的，是一块很小的内存，它是存储JVM当前方法执行的指令地址，就像是执行字节码的指示器，控制着当前程序的执行方向，JVM执行方法时就需要获取该计数器的指令来进行下一步的操作 本地方法栈本地方法栈与java栈类似，不同的是java栈执行的是java方法服务（字节码），而本地方法栈执行的JVM自己定义的本地方法服务，也就native修饰的方法 线程共享堆堆是线程共享的，所以它的声明周期由虚拟机创建时开始，主要存放的是对象的实例和数组，是JVM内存分配最大的，由于其生命周期较长，所以被垃圾回收收集器管理，由于现代的垃圾收集器都采用分代收集算法，所以还能以8比1的比例细分成一个Eden区和两个Survivor区（FromSurvivor和ToSurvivor） 方法区方法区也是线程共享的，它用于存储类的信息，常量，静态变量等信息（类的元数据在JAVA1.8已经移动到一块本地内存空间，也就是元空间），还有运行时常量池是方法区很重要的部分，存放编译器编译期间各种class中的常量值和类的描述信息。 对象在内存区域是如何运行对象在内存中是如果创建我们在代码中直接用new来表示创建一个对象，而在虚拟机中，会碰到一个new指令，首先会检查指令的参数在常量池中是否有这个类的符号引用，再检查此类是否已经被加载，解析和初始化过了，如果没有就会执行相应的加载过程，然后就会在堆中为对象分配内存，分配内存有两种方式： 指针碰撞：如果GC使用的是复制算法，把堆内存一分为二，一边是已分配内存，一边是空闲内存，没有内存碎片，那么只需从中间开始，指针往空闲内存空间移动相应大小的距离即可 空闲列表：如果GC是没有使用标记-整体的算法，存在内存碎片，这时候会维护一种记录可用内存的表，再从表中寻找一块足够大小的内存空间分配给对象实例。 由于堆是线程共享的，在分配内存时存在着线程安全，比如T1线程准备在表中选取A内存分配，还没有开始分配，这时T2线程也准备在表中选取A内存分配，这就会造成冲突，解决线程安全问题有下面两个方案： CAS同步，在分配操作上使用CAS操作保证分配内存的原子性 每个线程在堆上预先分配自己的一小块内存（本地线程分配缓冲 TLAB），只需要在该内存用完了，再同步分配新的TLAB 对象在内存中的结构组成对象存储在内存中分为三个部分：对象头，实例数据，对齐填充 对象头对象头包括两个部分，第一部分是存储对象自身的运行时数据（哈希码，GC分代年龄，锁标志等），也叫Mark Word，第二部分是类型指针，也叫元数据指针，来确定该对象是哪个类的实例 实例数据实例数据存储的是该对象内部所定义的类型的字段信息，包括从父类继承下来的，还是在子类定义的 对齐填充这是一个占位符，JVM规定对象的大小为8字节的整数倍，如果不是就用对齐填充来补全 对象在内存中如何被访问在内存中访问对象有两种方式：句柄池和直接引用 句柄池句柄池访问是指在栈中的reference引用指向的是句柄池上的地址，再由句柄池指向相应的对象信息，句柄池的内容包括对象实例数据的指针和对象类型数据的指针，在java堆划分一小块内存来存储它，具体访问过程如下图： 直接引用直接引用访问是指栈中的reference引用直接指向堆中对象实例的地址，访问过程如下图：以上两种访问方式各有优劣，句柄池在对象实例频繁的更替时，不需要改动reference中的指针，只需改变句柄池的指针即可，但是直接引用的访问速度比句柄池更快，省去了句柄池的指针指向对象实例的消耗，总结出来就是，对象更替频繁的使用句柄池，对象访问频繁的使用直接引用 参考https://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis持久化策略]]></title>
      <url>%2F2017%2F01%2F17%2Fredis_data_persistence%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Redis提供了两种不同级别的持久化策略，RDB（redis database）持久化和AOF(append only file)持久化，它们应用在不同的场景中，各有千秋，以下是两种策略的实现方案 RDB（redis database）持久化RDB（redis database）持久化是将内存中的数据生成一个特定格式的二进制的rdb文件，保存在磁盘中，在redis服务进程开启时通过读取磁盘中的rdb文件，数据又会还原到内存中。rdb文件结构如下： 写入指令写入（1）SAVE：SAVE命令是在当前服务进程进行持久化操作，会阻塞其他的操作命令，直到RDB文件创建完毕（2）BGSAVE：BGSAVE命令是创建一个子服务进程来专门处理持久化操作，其它操作命令在父服务进程继续执行 间隔性写入在配置文件中设置写入触发条件,比如:SAVE 900 1,代表在900秒内对数据库进行一次修改，就触发写入程序。 载入在服务器启动时，会对当前的持久化策略进行一个判断，如果当前已经开启了AOF持久化功能，那就会优先载入AOF还原程序，否则才载入RDB文件，整个载入过程都是阻塞的，保持数据的一致性。 AOF(append only file)持久化AOF(append only file)持久化是基于redis服务器对键值对的操作命令生成的aof文件，保存在磁盘中,AOF文件的结构就是一串操作命令的文本文件 写入AOF持久化通过以下步骤来进行持久化操作： 1. 命令追加（append）在redis服务器中提供了一个sds（简单动态字符串）类型的缓冲区aof_buff,它用于记录redis的操作命令，也就是利用命令追加（append）模式将redis的操作命令一条一条的追加到该缓冲区的末尾 2. 写入AOF文件将存储到缓冲区aof_buff中的指令通过调用flushAppendOnlyFile函数写入AOF文件中，写入AOF文件有三个策略： ● always：每一次数据操作，就将aof_buff缓冲区中的所有数据同步写入到AOF文件中 ● everysec：启动一个线程，定时（每隔一秒）将aof_buff缓冲区中的所有数据同步写入AOF文件中 ● no：不要求同步的情况下（aof_buff存储满溢），将aof_buff缓冲区中的数据写入AOF文件中三个策略的安全性：always&gt;everysec&gt;no , 效率：no&gt;everysec&gt;always 载入AOF持久化的载入方式是创建一个伪客户端去读取AOF文件，再在伪客户端中执行读取AOF文件中的一条条指令，直到完毕，数据库就恢复了之前的状态 重写AOF文件就像是数据库操作的日志文件，记录了数据库各种操作的指令，但是会出现冗余的指令记录，长时间下去，会导致文件体积变得太大，比如，执行如下操作1234RPUSH msg &apos;a&apos;RPUSH msg &apos;b&apos;RPUSH msg &apos;c&apos;RPUSH msg &apos;d&apos; 如上所示，最后msg的结果是’a’,’b’,’c’,’d’，AOF文件就会有四条指令的记录，其实只要一条指令记录就可以了，这时，AOF持久化提供了一种重写的机制，它会创建一个子进程来处理，在子进程中创建一个新的AOF文件，针对上面情况，对一个对象的多次操作，它会用一条指令来表示，这样新的AOF文件就大大减少了存储体积，由于在子进程进行重写的时候，父进程还会处理操作指令，在重写期间执行的操作指令会被写到一个aof重写缓冲区中，所以不仅仅是aof缓冲区写入新的AOF文件中，aof重写缓冲区也会写进新的AOF文件中，这样和旧的AOF文件保存的数据库状态是一致的，最后替换旧的AOF文件 思考优劣比较RDB持久化的优点在于：（1）RDB文件是一个非常紧凑的二进制文件，所以在远程传输上有很大的优势，可用于灾备中心的存储文件（2）在载入数据库上，大数据量的情况下，RDB比AOF更加快速（3）在持久化上，RDB持久化方式会fork一个子进程来执行，这样会保证Redis最大的性能缺点如下：（1）Redis的数据存储是基于内存的，如果碰上意外（宕机或者电源中断），如果你是每个五分钟甚至更长进行一次持久化，那么将会损失这几分钟的数据（2）RDB是fork子进程来进行持久化的，所以当大数据集的时候，这会加大cpu的响应时间，影响Redis的处理速度AOF持久化的优点在于：（1）AOF使用的是fsync策略进行持久化，所以即使碰上意外，也只是损失1秒的数据（2）AOF文件是一个日志文件，由指令集组成，通俗易懂，使使用者更加的好维护缺点如下：（1）相对于RDB文件来说，AOF文件相对过大了 如何选择使用哪种持久化方式一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快， 除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug 参考http://www.redis.cn/topics/persistence.htmlhttps://read.douban.com/ebook/7519526/（数据库的设计与实现）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis基本数据类型及其实现]]></title>
      <url>%2F2016%2F12%2F28%2Fredis_datatype%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库(来自wiki)，它提供丰富的数据结构类型：字符串（Strings），列表（Lists），哈希（Hashed），集合（Sets），有序集合（Sorted sets）来满足数据存储的需求，下面分别对这五大数据类型及其实现进行详述 字符串（String）实现的数据结构1. REDIS_ENCODING_INT（long类型整数）场景：SET的value为整数指令：SET msg 123 2. REDIS_ENCODING_RAW（大于32字节的字符串）场景：SET的value为大于32字节的字符串指令：SET msg LongString...... 注意：SDS是redis内部构建基于字符串的数据结构（不是直接使用C字符串），它由free（未分配空间），len（字符串长度或已使用长度），buf（存储字符数组）三部分组成，降低操作字符串的复杂度，len属性解决了不需要遍历整个字符串才能获取，free属性降低了内存重新分配的次数 3. REDIS_ENCODING_EMBSTR（小于32字节的字符串）场景：SET的value为小于32字节的字符串指令：SET msg hello 注意：对于字符串存储，对于raw编码模式，需要调用两次连续分配内存函数构建RedisObject和SDS这两块内存，而embstr的编码只需要一次性的内存分配一块连续的内存空间即可， 列表（Lists）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩列表）场景：（1）列表保存的元素都少于64个字节 （2）列表保存的元素数量少于512个指令：RPUSH msg &#39;a&#39; &#39;b&#39; &#39;c&#39;注意：ZipList是redis基于小数值和短字符串而构建的数据结构，由zlbytes（压缩列表占用的字节数），zltail（压缩列表尾节点到起始地址的偏移量），zllen（节点数），entryx（压缩列表的各个节点），zlend（压缩列表的尾端标记值） 2. REDIS_ENCODING_LINKEDLIST（链表）场景：（1）列表保存的元素都大于64个字节 （2）列表保存的元素数量大于512个指令：RPUSH msg &#39;a&#39; &#39;b&#39; &#39;c&#39; ......注意：LinkedList是类似于java中的LinkedList，由一个双向链表构成，自带长度计数器和表头表尾指针，在对于增加删除时能高效的进行调整（前后指针重新指定） 哈希（Hashes）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩列表）场景：（1）哈希对象中的键值对的长度都小于64字节 （2）哈希对象中的键值对的数量小于512个指令：HSET msg name &quot;andy&quot;注意：利用压缩列表实现键值对，实现方法是：key在前，value在后，形成一个链 2. REDIS_ENCODING_HASHTABLE（哈希表）场景：（1）哈希对象中的键值对的长度都大于64字节 （2）哈希对象中的键值对的数量大于512个指令：HSET msg name &quot;andy&quot; age &quot;24&quot; ......注意：HashTable也叫字典表，是整个redis的核心，类似于java中的HashTable，但是在其特殊的应用场景下，做出了一些改进，比如渐进式的rehash等等 集合（Sets）实现的数据结构1. REDIS_ENCODING_INTSET（整数集合）场景：（1）集合中的元素为整数 （2）集合中的元素个数小于512个指令：SADD msg 1 2 3注意：IntSet是redis存储整数集合的数据结构，有encoding（编码，保存的位数类型），length（长度）和contents（整数数组）构成，可以灵活的根据整数的存储位数来选择相应的存储方式来节省内存 2. REDIS_ENCODING_HASHTABLE（哈希表）场景：（1）集合中的元素不为整数 （2）集合中的元素个数大于512个指令：SADD msg &quot;a&quot; &quot;b&quot; &quot;c&quot; 有序集合（Sorted Sets）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩表）场景：（1）有序集合中的元素小于128个 （2）有序集合中所有元素的集合都少于64个字节指令：ZADD a 8 b 5 2. REDIS_ENCODING_SKIPLIST（跳跃表）场景：（1）有序集合中的元素大于128个 （2）有序集合中所有元素的集合有多于64个字节指令：ZADD a 8 b 5 ......注意：跳跃表是一种有序的数据结构，它通过每个节点指向其它多个节点的指针，来到达最快的访问节点速度，由header（表头节点），tail（表尾节点），level（节点最大层数），length（节点数），简单的实现就是通过一个有序的链表，表示为第一层，再取其中头结点和尾节点，中间随机多个不重复节点组成新的链表，即为第二层，如下重复下去，直到到达随机（1-32层）的阈值，这样到达中间的节点的复杂度将会大大的降低。上图中是还使用了哈希来获取元素的分数值来进行排序。 参考http://www.redis.cn/topics/data-types.htmlhttps://read.douban.com/ebook/7519526/（数据库的设计与实现）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[源码解析String，StringBuffer，StringBuilder的区别]]></title>
      <url>%2F2016%2F11%2F18%2FString%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 String，StringBuffer，StringBuilder三者是处理字符串的常用类，String是在JDK1.0时就存在的字符串处理类，也是使用最广泛的，StringBuffer也是JDK1.0开始发布的线程安全的字符串处理类，他改变了原有String不可改变的字符串，增加了一个缓冲的概念，StringBuilder是JDK1.5提出的字符串处理类，他取消了StringBuffer原有的线程安全的特性，增加了字符串处理的效率。 其实要说哪种处理字符串是性能最好的，我觉得是哪种场景上的字符串处理性能是最好的，因为他们是各有千秋，下面是基于JDK1.8的源码解析这三种字符串处理方式的区别 String123public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char value[]; 由上可知，String实现了序列化和字符序列两个接口，这会带来两个特性，一个是可传输的特性，一个是字符处理的特性，再看String的核心属性value，value是存储字符串的载体，由于被final修饰了，所有该字符串载体一旦初始化了就是不可变的，正是String不可变这一特性，所以它在处理字符串的方式只能通过构造初始化的方式来实现 1.初始化一个空串123public String() &#123; this.value = "".value;&#125; 2.初始化一个字符串对象1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125; 3.初始化一个字符串123public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length);&#125; 4.初始化字节类型的字符串123public String(byte ascii[], int hibyte) &#123; this(ascii, hibyte, 0, ascii.length);&#125; 当然还可以初始化StringBuffer，StringBuilder来构建，String的构造方法很丰富，提供了很多类型且多样的数据源来支持，如果你想要构建一个不变的或者变化不多的字符串，String很适合你 StringBuffer123public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123; 在StringBuffer继承体系来看，StringBuffer拥有String应有的特性，而且还继承了AbstractStringBuilder这个抽象类，这个类定义了StringBuffer的存储载体(也是StringBuilder的存储载体)，现在通过一个append方法来看看StringBuffer处理字符串的方式 12345public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this;&#125; 由上可知，这是一个StringBuffer拼接字符串的方法，由synchronized来修饰，所以StringBuffer是线程安全的（其实StringBuffer几乎所有的方法都是由synchronized修饰），这里它是调用的父类的append方法 123456789public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;&#125; 这是父类AbstractStringBuilder的append方法，在方法内有是两个很重要方法，也就是缓冲区的实现 扩容方法：ensureCapacityInternal(int minimumCapacity) 赋值方法：str.getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) 我们先看看扩容方法1234private void ensureCapacityInternal(int minimumCapacity) &#123; if (minimumCapacity - value.length &gt; 0) expandCapacity(minimumCapacity);&#125; 这里会对所拼接的字符串做一个判断，也就是所拼接的字符串不能为空1234567891011void expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity);&#125; 以上代码可知，他会先对原有的字符数组的容量扩大两倍再加二，在和最小的容量(原有的容量+拼接字符串的容量)比较，没有最小容量大就取最小容量，这里也有一个以防内存溢出导致容量为负数的一个处理，最后核心的就是 Arrays.copyOf(value, newCapacity)，Arrays这是一个数组的工具类，copyOf方法是针对数组在原有的基础上改变其容量，这就是等于对原有的字符串数组进行了扩容，在回来看看将拼接的字符数组重新添加到新的字符数组的方法 123456789101112public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) &#123; if (srcBegin &lt; 0) &#123; throw new StringIndexOutOfBoundsException(srcBegin); &#125; if (srcEnd &gt; value.length) &#123; throw new StringIndexOutOfBoundsException(srcEnd); &#125; if (srcBegin &gt; srcEnd) &#123; throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); &#125; System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin);&#125; 该方法开始会对不符合条件进行异常处理，最后的调用System.arraycopy方法将拼接字符数组添加到新的字符数组，这就完成了一个字符串拼接的过程，也就是缓冲池的实现，在多线程的情况下保证安全的前提字符串大量的变动，使用StringBuffer是最好的 StringBuilder123public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence 其实从父类体系来看，StringBuilder和StringBuffer是一样的，那StringBuilder与StringBuffer有什么区别呢？让我们看看它的append的方法 1234public StringBuilder append(String str) &#123; super.append(str); return this;&#125; 这里你就会方法它也是调用父类的append方法，而他们的父类又是同一个，这里不同的就是StringBuilder的append方法没有用synchronized修饰，所以它是不安全的，当然也就意味着在单线程的情况下比StringBuffer的性能是要好的，其实对于StringBuffer和StringBuilder来讲，它们都是对于AbstractStringBuilder类的实现，或许会有其他细节处理的不同，大致来讲，他们的区别就是一个是线程安全的实现，一个是线程不安全的实现，只是要你自己去权衡线程安全与性能之间的抉择 总结StringBuilder或者StringBuffer并不一定比String的效率高，在各个场景中有不同的用法而已，对于StringBuilder和StringBuffer来讲，也不是施了什么魔法，只是实现了CopyOnWrite的思想，对字符串的操作的性能更高了，应对不同情况的选择而已]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解刨单例模式]]></title>
      <url>%2F2016%2F11%2F01%2Fsingleton%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 单例模式，也叫单子模式，是一种常用的软件设计模式。在应用这个模式时，单例对象的类必须保证只有一个实例存在。许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。这种方式简化了在复杂环境下的配置管理。——来自wikipedia 单例模式大致上分为两种模式，饿汉模式和懒汉模式，在开发环境中有很多的应用，比如Spring的bean工厂就应用了单例模式来对bean进行初始化，他对类的实例进行了统一的管理，每次返回该类的唯一实例，也优化了实例化类的资源利用。 饿汉模式123456789public class HungrySingleton &#123; private final static HungrySingleton INSTANCE = new HungrySingleton(); private HungrySingleton() &#123;&#125; public static HungrySingleton getInstance() &#123; return INSTANCE; &#125;&#125; 饿汉模式指在类的实例在全局定义，利用static和final修饰，保持类的唯一性，在类装载的时候就初始化了， 因为创建实例本身是线程安全的，所以饿汉模式也是线程安全的。 但是饿汉模式的应用场景是明确类本身实例的信息，因为这是在类装载前就实例化了，无法改变，但是如果想根据上下文或者所依赖参数的变化来动态的实例化类，饿汉模式就不匹配了，于是另一种懒汉模式就登场了。 懒汉模式懒汉模式指全局的实例在第一次调用的时候才加载 简单模式123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;// 线程1 instance = new LazySingleton();// 线程2 &#125; return instance; &#125;&#125; 这是一个很简单的懒汉模式，在单线程的环境下，通过第一次检查instance是否为空来获取唯一的实例，但是在多线程的环境下，由于instance = new LazySingleton()不是一个原子性的操作，会受到其他线程的干扰，如上所示： 如果线程1在if (instance == null) {挂起，线程2在instance = new Singleton()开始执行，instance指向了一个内存空间，但是还没有开始初始化对象( 指令重排序，下面会讲到 )，线程2挂起，线程1这个时候继续，这个时候判断instance不为null，返回的只是一个空内存块(没有实例化对象)，很容易造成NullPointException， 如果线程2在instance = new Singleton()挂起，线程1在if (instance == null) {开始执行，这个时候instance还没有指向内存，instance为null，也进来进行了创建实例的步骤，线程1和线程2创建了两个实例，违背了单例的思想 所以以上两种情况表明这种简单模式是线程不安全的 单重检验锁模式（single checked locking pattern）123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static synchronized LazySingleton getInstance() &#123; if (instance == null) &#123;// single check instance = new LazySingleton(); &#125; return instance; &#125;&#125; 以上的模式是在获取实例的方法getInstance()加上同步锁synchronized来修饰，以保证线程的安全性，但是虽然保证了线程安全，但是这种暴力的同步严重影响了程序执行的性能，在执行getInstance()方法时，频繁的线程的更换调度，对于性能是一个很大的开销。 如果instance已经实例化了，对于上述模式来讲，他还是要等待前面的线程获取完实例才能获取实例，这样实现很低效，其实同步只是针对实例化对象的过程，对于已经实例化对象的instance来说，只需要返回就可以了，不需要同步。 双重检验锁模式（double checked locking pattern）1234567891011121314151617public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;//single check 线程1 synchronized (LazySingleton.class) &#123; if (instance == null) &#123;//double check instance = new LazySingleton(); //线程2 &#125; &#125; &#125; return instance; &#125;&#125; 双重检验锁模式又对单重检验锁模式进行了优化，他用两次检查来判断instance是否被实例化，同步锁只是针对instance的实例化，对于instance已经实例化的情况下，直接返回instance，不进入同步锁的代码块，大大的提高了性能 但是，又重现了简单模式的第一种情况，如上代码所示，假设线程2在实例化对象只是在instance指向了内存空间，但是还没有实例化对象(指令重排序)，这个时候线程1的instance！=null，直接返回instance，造成NullPointException，现在问题来了，什么是指令重排序？ 一般的情况下，程序运行代码是顺序运行的，但是会存在一些指令的重排序问题，比如123int a=1；int b=1；int c=a+b; 以上代码使用指令来执行，分为以下5个步骤： 对a赋值1 对b赋值1 获取a的值 获取b的值 运算a+b的值存在c的内存中 上述的五个步骤有时并不是按照顺序进行的，有时你执行步骤1对a赋值1时，就会执行步骤3获取a的值，因为他们存在数据依赖，这就是发生了指令重排(具体了解，访问 http://tech.meituan.com/java-memory-reordering.html )，对于实例化对象来讲，具体的步骤如下： 分配内存 实例化对象 引用指向内存对象 正常的情况下只有实例化了对象才会引用指向内存对象，但是如果这时发生了指令重排序，执行顺序变成了1,3,2，在执行步骤3还没有执行步骤2就执行线程1了，这个时候就会造成异常错误，这个时候就会使用volatile关键字来避免指令重排序。 volatile式模式（double checked locking pattern with ）volatile的定义是：java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 正如上所说，java线程内存模型确保所有线程看到这个变量的值是一致的就是volatile的可见性，正是因为他的可见性，要求所有线程看见该变量要一致，所以代表着volatile的另一个特性:禁止指令重排序，其实，在JDK1.5之前volatile是不能保证能够禁止指令重排序的，在JDK1.5之后才能应用于双重检查模式。 1234567891011121314151617public class LazySingleton &#123; private volatile static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;//single check synchronized(LazySingleton.class)&#123; if (instance == null) &#123;//double check instance = new LazySingleton(); &#125; &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类模式(static nested class pattern)静态内部类模式也是一种懒汉模式，他利用内部类的特性(调用时才加载）来创建实例 123456789public class LazySingleton &#123; private static class SingletonClass &#123; private static final LazySingleton INSTANCE = new LazySingleton(); &#125; private LazySingleton ()&#123;&#125; public static final LazySingleton getInstance() &#123; return SingletonClass.INSTANCE; &#125; &#125; 这种模式也能保证线程的安全性，JVM在保持类的信息的一致性，加载类的时候是线程安全的，而且不需要同步来执行getInstance()方法。 参考https://zh.wikipedia.org/wiki/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8Fhttp://tech.meituan.com/java-memory-reordering.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[动态代理]]></title>
      <url>%2F2016%2F10%2F05%2Fproxy%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 代理模式 在代理模式中,角色分配如下： Subject(1-k) : 委托对象所实现的所有接口(i&gt;=1) RealSubject : 委托对象，也就是被代理的对象 ProxySubject : 代理对象 在JDK实现的代理模式是面向接口的，不管是委托类还是代理类都应该实现相同的接口，这样才会保持行为的一致性，因为对于Client来说，它只要输出它所想要的结果，不会管你是谁实现的，所以为了减轻委托对象的压力，就必须要克隆出其他跟自己一样的帮手来帮助自己，就好像火车票代售点一样，代理对象就由此而生了。 静态代理静态代理是指在JVM执行前就把你的代理类给定义好了，例子如下： Subject 123public interface Subject &#123; public void doSomething();&#125; RealSubject 1234567public class RealSubject implements Subject&#123; @Override public void doSomething() &#123; // TODO Auto-generated method stub System.out.println("i am just do something!!!!!"); &#125;&#125; ProxySubject 12345678910public class ProxySubject implements Subject&#123; Subject realSubject = null ; @Override public void doSomething() &#123; //类似于Spring的@Before do something realSubject = new RealSubject(); realSubject.doSomething(); //类似于Spring的@After do something &#125;&#125; 由上可知，其实调用代理类(ProxySubject)和调用委托类(RealSubject)是一样的效果，等于是代理类对委托类又重新封装了一层，但是为什么要这样做呢？ 如果每次Client调用委托类来完成业务操作，那么每次委托类就得创建对象来完成业务，如果是大业务场景，消耗的内存是巨大的，这个时候，如果是代理类来实现，可以在代理类内对委托类实现缓存操作，这样就会减少很大的内存消耗。 如果你想对原生的委托类进行扩展(比如Spring中的@After和@Before的思想），你可以对委托类进行修改，但是这会影响原有已经实现的程序逻辑，如果使用代理类，在不影响原生的委托类情况下再进行逻辑的扩展，使程序变得更加健壮。 由上可知，代理类的作用使原生的委托类更加的灵活被运用，能够应付不同的不同应用场景，但是，如果委托类的一些应用方法的删减，实现接口的减少，对于代理类来说也要进行很大的修改，这样的改动有时使代理模式变得更加的复杂，变得不是那么的灵活，如果有一种代理类能够需要调用的时候才加载，不管接口的变动，代理类都会自动的更新，无需改变，那么这就是动态代理。 动态代理动态代理是在静态代理的基础上对代理类进行了优化，利用java反射的原理来创建代理类，使代理类在JVM运行时创建。 如上图所示，这个代理类会根据现有的接口数或者实现的方法动态的去创建对象，对于业务频繁更替的场景下，不需要对代理类进行频繁的更改，更加的灵活，而在java中，对于动态代理的实现，有两种方法，一种是JDK形式的实现，一种是第三方包cglib的实现形式。 JDK动态代理在JDK实现中，主要是一个类，一个接口：动态代理类Proxy和调用处理器InvocationHandler 1.Proxy Proxy是动态创建代理类的类，它主要是利用接口的信息在类加载器中动态的生成代理类，而其中主要的生成代理类的方法就是newProxyInstance方法，实现如下： 123456789101112131415161718192021222324252627public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; // 检查调用处理器是否为空，为空抛异常 if (h == null) &#123; throw new NullPointerException(); &#125; // 获得与制定类装载器和一组接口相关的代理类类型对象 Class cl = getProxyClass(loader, interfaces); // 通过反射获取构造函数对象并生成代理类实例 try &#123; Constructor cons = cl.getConstructor(constructorParams); return (Object) cons.newInstance(new Object[] &#123; h &#125;); &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString()); &#125; catch (IllegalAccessException e) &#123; throw new InternalError(e.toString()); &#125; catch (InstantiationException e) &#123; throw new InternalError(e.toString()); &#125; catch (InvocationTargetException e) &#123; throw new InternalError(e.toString()); &#125; &#125; 由上就很容易发现，这是个简单的java反射创建对象，获取Class对象，再获取构造器，最后反射成对象，这是个静态方法，所以直接类本身就可以调用了。 Proxy还有很多的实现，比如利用一个HashMap来实现对代理类的缓存，key就是接口列表，value就是代理类的对象，还有关联调用处理器的方法等等。 2.InvocationHandler InvocationHandler是调用处理器，是负责方法调用时，利用java反射机制在JVM运行时调用该方法，其中主要的方法就是invoke方法，有三个参数proxy,method,args，这是需要自己去实现的，以下是invoke方法的实现 12345public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //方法反射 Object obj = method.invoke(proxyObj, args); return obj; &#125; 3.代码实现 MyInvocationHandler 1234567891011public class MyInvocationHandler implements InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; ////类似于Spring的@Before do something //方法反射 Object obj = method.invoke(proxyObj, args); //类似于Spring的@After do something return obj; &#125;&#125; JdkProxyFactory 1234567891011public class JdkProxyFactory &#123; private Object proxyObj = null;//代理类 // 创建代理 public Object createProxy(Object targetObject,InvocationHandler myInvocationHandler) &#123; if (null != targetObject) &#123; this.proxyObj = targetObject; &#125; return Proxy.newProxyInstance(this.proxyObj.getClass().getClassLoader(), this.proxyObj.getClass().getInterfaces(), myInvocationHandler); &#125;&#125; 以上就是一个简单的JDK实现的代理类，直接用以下的代码调用就可以了 123Subject proxySubject = (Subject)new JdkProxyFactory().createProxy(new RealSubject(),new MyInvocationHandler());proxySubject.doSomething(); 当我们调用doSomething方法时，你以为是调用RealSubject对象的doSomething方法，其实是调用代理类$ProxyN(生成代理类的名称，N从1开始)的doSomething方法，他会触发该方法的调用处理器invoke方法来调用doSomething方法。 cglib动态代理CGLib是面向类的，而cglib动态代理的实现也是一个类和一个接口：Enhancer和MethodInterceptor，和JDK的Proxy和InvocationHandler职能是一样的，一个是负责创建类，一个是负责调用方法的处理 1.Enhancer Enhancer可以说是CGLib的一个字节码增强器，它的作用通过委托类的子类来实现代理类的创建，创建过程如下： 通过委托类创建它的子类，在子类中的每个方法设置回调方法，然后获取它的Class对象 利用Class对象根据GeneratorStrategy.generate方法生成代理类的字节码 通过反编译生成代理类的Class对象 再通过反射机制创建代理类的对象 2.MethodInterceptor MethodInterceptor是一个方法拦截器，它的作用就是在代理类每执行一个方法时执行拦截方法并返回，其中最主要的方法intercept实现如下 123456public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //相当于调用了代理类本身的方法 Object result = proxy.invokeSuper(obj, args); return result; &#125; CGLib实现了Fastclass机制，对代理类的方法建立了索引，把方法存储在索引中，通过方法名和它的信息就可以获取该方法，不需要进行反射来进行方法的调用。 3.代码实现 MyMethodInterceptor 1234567891011public class MyMethodInterceptor implements MethodInterceptor &#123; public Object intercept(Object obj, Method method, Object[] arg, MethodProxy proxy) throws Throwable &#123; ////类似于Spring的@Before do something //方法反射 Object object = proxy.invokeSuper(obj, arg); //类似于Spring的@After do something return object; &#125;&#125; CglibProxyFactory 12345678910111213public class CglibProxyFactory &#123; private Object proxyObj = null;//代理类 // 创建代理 public Object createProxy(Object targetObject,MethodInterceptor MyMethodInterceptor) &#123; if (null != targetObject) &#123; this.proxyObj = targetObject; &#125; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.proxyObj.class); enhancer.setCallback(MyMethodInterceptor); return enhancer.create(); &#125;&#125; 这是一段Cglib代理类的实现，调用代码如下： 12Subject proxySubject = (Subject)new CglibProxyFactory().createProxy(new RealSubject(),new MethodInterceptor());proxySubject.doSomething(); 相比于JDK代理实现，Cglib的实现更快，它的不同之处在于 Cglib代理摒除了JDK代理利用反射来调用方法(反射的效率是很低的），利用索引来实现。 Cglib代理是面向extends的，意味着一些不能继承的类无法用Cglib来实现，而JDK代理是面向implements,这方面更规范。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neo4j的导入方案]]></title>
      <url>%2F2016%2F09%2F27%2Fneo4j-import%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 概述Neo4j是一种强大的，可扩展的和高性能的图形数据库，由边，属性和节点组成，是用来描述节点与节点之间的关系，由位于美国旧金山的Neo技术公司进行开发和维护，它属于NoSql的范围内，在一些社交的项目中处理人与人或物之间的关系挥发这巨大的作用，以下列举它的一些特点 支持ACID事务 高可用性 可扩展到数十亿的节点和关系 高效且快速的遍历查询(图的遍历) 强大的结构化查询语言Cypher 导入方案如果你想选择Neo4j作为你的处理关系的数据库，首先处理的问题就是导入外部数据，将MySQL，Oracle或者PostgreSQL的关于用户的关系数据导入Neo4j中，这里有两种导入数据的方式： 1. LOAD CSVLOAD CSV是Cypher语言的指令，是将csv文件中的属性插入Neo4j中，首先先将原数据库的数据导出成csv文件，以电影信息为例，导出CSV文件如下： movies.csv：1234id,title,country,year1,Wall Street,USA,19872,The American President,USA,19953,The Shawshank Redemption,USA,1994 Neo4j提供了一个WEB端的客户端系统，利用可视化的方式展示节点与节点的关系，在上面可以利用Cypher语言对数据进行操作，代码如下：1234LOAD CSV WITH HEADERS FROM &quot;CSV地址&quot; AS csvLineMERGE (country:Country &#123; name: csvLine.country &#125;)CREATE (movie:Movie &#123; id: toInt(csvLine.id), title: csvLine.title, year:toInt(csvLine.year)&#125;)CREATE (movie)-[:MADE_IN]-&gt;(country) 上面的意思是创建country和movie节点，然后将country和movie建立MADE_IN的关系，这样就将csv的数据导入了Neo4j中了，LOAD CSV指令导入的形式只是相当于多个CRATE指令，通过繁杂的JAVA程序向硬盘写数据，所以只是适于小数据量的导入 注意：csv中属性的数据都是String类型的，Neo4j是由JAVA写的，每个属性是有类型的，所以内置了toInt这样的类型转换方法 2. neo4j-importneo4j内置了一个批量导入的脚本，存储在/BIN目录下的neo4j-import.bat,它直接在数据库存储文件目录中生成你所需创建节点和关系文件，所以它的限制也很多，第一点是导入前，还没有创建数据库，讲白了只能是第一次导入才有效，第二点是节点和关系要分开导入就是要额外进行导出存储关系的csv，第三点是如果不进行强制指定类型，每个节点(包括不同类型的节点)的id不能相同， movie.csv：1234id,title,year1,Wall Street,19872,The American President,19953,The Shawshank Redemption,1994 country.csv：1234id,name4,USA5,CHINA6,UK MADE_IN.csv：1234:START_ID,:END_ID1,42,53,6 （1）由于配置文件的默认读取的位置在import中，所以导出的csv格式的文件要存储在neo4j存储目录下的import目录（2）使用neo4j-import工具,在neo4j的bin目录下执行以下的指令1neo4j-import --into ../data/databases/graph.db --id-type string --nodes:movie ../import/movie.csv --nodes:country ../import/country.csv --relationships:MADE_IN ../import/MADE_IN.csv --multiline-fields=true --skip-bad-relationships=true --bad-tolerance=2000 这样就完成了neo4j的批量导入了，大约1000万的数据量，十几分钟就完成了 注意：在导入过程中有可能遇到如下错误（1）./data/databases/graph.db already contains a database错误，表示graph.db已经包含了一个数据库，需要将其删除才能导入（2）Duplicate input ids that would otherwise clash can be put into separate id space，表示有ID重复，按提示查询（3）panic called，so exiting表示出现特殊符号，可检查列中可含有特殊符号 –multiline-fields=true :多行导入–skip-bad-relationships=true：过滤错误的关系不导入，可以在log中查看–bad-tolerance=2000：错误的最大限制在2000个]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LRU(Least recently used-最久未使用算法)]]></title>
      <url>%2F2016%2F09%2F22%2FLeast_recently_used%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 现在的数据越来越多的被存储，对于数据库来讲，访问大数据量会变得越来越慢，于是为了提高访问的速度，将小范围区域的数据存储在一个高速缓冲存储器，以至于不会每次去读取磁盘，而是在内存中直接访问数据。内存存储的代价远远的大于磁盘存储的价值，所以缓存很小，并不能存储你所有的数据，所以你不得不保存你所认为重要的数据(使用次数较多的数据)，那就要淘汰最少使用的数据，如何从缓存中淘汰最少使用的数据，一个简单而且有效的算法，最近最少使用算法LRU. LRU原理最久未使用算法（LRU）：最久没有访问的内容作为替换对象 —– 来自wiki LRU翻译过来就是最久未使用，当缓存到达一定的阀值时，剔除掉最久未使用的数据，通俗来讲，比如一个缓存只能缓存10000条数据，10000条就是这个缓存的阀值，小于10000条时可以随意添加，一旦数据量到达了10000条时，这个时候就要删除最久未使用的数据了，以保持最大程度的使用缓存。 LRU实现LRU的实现最简单的就是单链表的实现，这里引用的就是JDK中的LinkedHashMap,它有两种形式，一个是最晚读的数据放在前面，最早读的数据放在后面，另一个就是FIFO，也就是先进先出。 晚读放前，早读放后 每次新的数据从头部开始插入，当链表缓存空间满了的时候，就从尾部对数据进行删除，如果有数据命中的话，就将该数据移动到头部。 而基于LinkedHashMap的实现有两种方法，一种就是继承LinkedHashMap的方式，叫做inheritance，一种直接使用LinkedHashMap,叫做delegation，这两种都可以实现LRU算法，而大部分功能LinkedHashMap已经实现了,但是淘汰的删除方法就需要重写了。12345678public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 这是LinkedHashMap的构造方法和删除元素的方法，默认情况下，LinkedHashMap是根据元素的添加顺序进行存储的,如果构造参数accessOrder为true的话，就会按照访问数据，最晚访问的放在最前，最早访问的放在最后。 inheritance12345678910111213public class LruInheritance&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int MAX_SIZE=100; public LruInheritance(int cacheSize) &#123; super((int) Math.ceil(cacheSize / 0.75)+1, 0.75f, true); MAX_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_SIZE; &#125;&#125; 在构造方法中，由于将负载因子设置为0.75，所以在原有容量要除以该负载因子，因为Map中的阀值是原有容量*负载因子，以此来判断是否超标。而原本LinkedHashMap删除的机制返回的都是false，所以要重写removeEldestEntry方法,如果超过当前容量就返回true，就会删除当前元素了。 delegation12345678910111213141516public class LruDelegation&lt;K, V&gt; &#123; private final int MAX_SIZE; LinkedHashMap&lt;K, V&gt; map; public LruDelegation(int cacheSize) &#123; MAX_CACHE_SIZE = cacheSize; int capacity = (int) Math.ceil(MAX_SIZE / 0.75) + 1; map = new LinkedHashMap(capacity, 0.75f, true) &#123; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_SIZE; &#125; &#125;; &#125;&#125; 在这个构造方法中，它内部就是用已经重写removeEldestEntry方法的LinkedHashMap实现的，他与inheritance不同的是，对LinkedHashMap不同使用，一个当爹使，一个当朋友使。 FIFO(先进先出)其实与第一种方式相比，对于LinkedHashMap来讲，就是accessOrder参数的变化，上面也提到，LinkedHashMap默认的是FIFO的，构造参数accessOrder默认是false的，所以与第一种相比，只要将accessOrder置为false，或者使用一个无参构造，就可以实现了。1234567final int MAX_SIZE= 100;LinkedHashMap&lt;Integer, String&gt; lru = new LinkedHashMap&lt;Integer, String&gt;() &#123; @Override protected boolean removeEldestEntry(Map.Entry&lt;Integer, String&gt; eldest) &#123; return size() &gt; MAX_SIZE; &#125;&#125;; 这种是基于单链表实现LRU缺点是：由于LinkedHashMap本身特性，所以是线程不安全的，而且命中率不高。优点是：实现起来简单，很多东西LinkedHashMap已经帮你实现了 其实多链表或者多队列的组合使用，效率和命中很更高，一个链表或队列专门用来维护命中概率（作为访问历史数据存储），另一个作为多次访问数据存储 ### 新的数据都会从历史数据的队列的头部插入,如果当前队列容量满了之后，就会从尾部淘汰，如果当前历史数据被访问多次，就会移动到正式的LRU数据队列中，然后按时间排序，当该队列满了之后，就会从尾部淘汰。多个链表或队列组合的LRU能够应该复杂的场景,能够应对不同情况，不同的淘汰机制,提高数据的命中率，同时响应的维护成本也响应的提高了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初识HTTP-1]]></title>
      <url>%2F2016%2F09%2F06%2Fmeet-http-1%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 定义HTTP译为超文本传输协议,是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）,也是基于超文本为载体在客户端和服务器端进行传输的协议。 超文本是基于超文本构建语言构建的文档，比如HTML(HyperText Markup Language 超文本标记语言)就是标准的构成超文本的语言,而传输（转移）是基于超文本的内容在客户端和服务器端进行通信。 如上图所示，这是一个简单的超文本传输的过程，]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java反射笔记(java reflection)]]></title>
      <url>%2F2016%2F09%2F04%2Fjava_reflection%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 java是一门静态语言，一般来讲，类的定义需要在JVM运行前完成，要通过JVM编译环节，才能运行在JVM上，而java反射机制使java的类定义能够在JVM运行时动态的加载，让在某些功能上更加灵活多用，根据不同的上下文来决定类的功能 Class在每一个类都有Class对象，在JVM编译的环节中，他会检查类的信息，这个时候就会获取该类的Class对象，它包含了该类的所有信息,获取Class对象有很多种方法。 获取Class对象1.利用类本身的情况下 1Class myClass = className.class; 2.利用类名的情况下 1Class myClass = Class.forName("className"); 注意：在使用类名获取Class对象时，参数名称必须是类的全称，包括包的名称，这样才能找得到 3.利用类对象的情况下 1Class myClass = new Object().getClass(); 当然，你拥有Class对象，等于你就知道该类的所有信息，包括变量，方法，修饰符，注解，甚至它的父类，实现的接口，所在包的信息，具体的方法可以参考相应的文档：http://docs.oracle.com/javase/6/docs/api/java/lang/Class.html Constructor在java中，创建实例对象是根据构造器来实现的，JVM编译环节通过Constructor来检查类中构造方法的信息，Constructor拥有构造方法所有的信息，如果我们获取了Constructor对象，也就可以反射出拥有该构造器的对象。 获取Constructor对象1.获取所有的Constructor对象 1Constructor[] constructors = myClass.getConstructors(); 2.获取指定的构造器 1Constructor constructor = myClass.getConstructor(String.class); getConstructor方法的参数是构造方法的参数的Class对象 实例化对象12Object obj = constructor.newInstance("参数值"); 相当于SimpleReflection simpleReflection = new SimpleReflection(“参数值”)，newInstance方法的参数是构造方法的参数的实例 Field在java的JVM编译环节中，通过Field来检查类变量的信息,它拥有类变量所有的信息。 获取Field对象公有(public)变量1.获取所有Field 1Field[] fields = myClass.getFields(); 2.获取指定的Field 1Field field = myClass.getField(); 私有(private)变量1.获取所有Field 1Field[] privateFields = myClass.getDeclaredFields(); 2.获取指定的Field 1Field privateField = myClass.getDeclaredField(); 获取变量属性1.获取变量名称 1String fieldName = field.getName(); 2.获取变量类型 1Class fieldType = field.getType(); set&amp;get变量公有(public)变量12Object value = field.get(new Object());field.set(new Object(), value); 私有(private)变量通常情况下，外部类是不能访问内部的私有变量的，因为在访问对象变量时，JVM会有一个反射访问检查(reflection access check),私有变量没有访问权限是不能访问的，在Field对象有一个setAccessible方法，true表示在外部对象的作用域里可以访问私有变量。 123privateField.setAccessible(true);Object value = privateField.get(new Object());privateField.set(new Object(), value); 非静态变量的Field.get()和Field.set()方法需要指定该变量所属的对象，因为每个对象里有很多相同变量，它们独自享有一块内存，如果不指定对象，就会有歧义，而对于静态变量，可以将参数设置为NULL，因为在类加载时，是先加载静态变量，后加载构造方法，所以静态变量和对象没有必要的关系。 Method在java的JVM编译环节中，通过Method来检查方法的信息,它拥有方法所有的信息。 获取Method对象公有(public)方法1.获取所有的方法1Method[] methods = myClass.getMethods(); 2.获取指定的方法1Method method = myClass.getMethod("methodName", new Class[]&#123; String.class&#125;); 私有(private)方法1.获取所有的方法1Method[] privateMethods = myClass.getDeclaredMethods(); 2.获取指定的方法1Method privateMethod = myClass.getDeclaredMethod("methodName", new Class[]&#123; String.class&#125;); 获取Method信息1.获取方法名1String methodName = method.getName(); 2.获取返回类型1Class methodType = method.getReturnType(); 3.获取参数类型1Class[] types = method.getExceptionTypes(); Method访问方法公有(public)方法1Object returnValue = method.invoke(new Object(), "方法参数列表"); 私有(private)方法原理和Field一样，在JVM反射访问检查时，通过setAccessible方法来设置私有方法的访问权限。12privateMethod.setAccessible(true);Object returnValue = privateMethod.invoke(new Object(), "方法参数列表"); 方法也有静态的，所以在invoke方法中如果是静态方法可以设置成NULL. Annotation注解在java 5才出现，它扩展了类，属性，方法，参数等，在JVM编译时，通过Annotation来检查注解的信息 类注解1.获取所有的注解1Annotation[] annotations = myClass.getAnnotations(); 2.获取指定的注解1Annotation annotation = myClass.getAnnotation(MyAnnotation.class); 方法注解1.获取所有的注解1Annotation[] annotations = method.getAnnotations(); 2.获取指定的注解1Annotation annotation = method.getAnnotation(MyAnnotation.class); 参数注解12345Annotation[][] parameterAnnotations = method.getParameterAnnotations();for(Annotation[] annotations : parameterAnnotations)&#123; for(Annotation annotation : annotations)&#123; &#125;&#125; 变量注解1.获取所有的注解1Annotation[] annotations = field.getAnnotations(); 2.获取指定的注解1Annotation annotation = field.getAnnotation(MyAnnotation.class); 访问注解信息1234if(annotation instanceof MyAnnotation)&#123; MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println("name: " + myAnnotation.name());//假设注解中有name属性，就可以这样访问了&#125; Array在java中，数组是一个很特殊的对象，它不继承于Object，它们没有Object的所有属性和方法，所以它不是有某个类实例化出来的，它是由JVM动态创建的，JVM有一个Array通过反射机制来处理数组 创建数组1String[] arrays = (int[]) Array.newInstance(String.class, 3); 相当于String[] arrays = new String(3),newInstance方法中的参数为数组的类型和大小 访问数组set(对数组赋值)12Array.set(arrays, 0, 'hello');Array.set(arrays, 1, 'world'); set方法参数为别为目标数组，数组下标，值。 get(获取数组值)1Array.get(arrays,0); get方法参数分别是目标数组，数组下标。 获取Class对象通过class属性1Class class = String[].class; 通过forName方法1Class intArray = Class.forName("[I"); “[“代表的是数组，”I”代表的是int类型(针对于基本类型)，这个是原生的数组创建，因为在JVM创建数组，类名就是”[I”。 而对于普通类型来讲，创建数组就需要明确类型：1Class intArray = Class.forName("[Ljava.lang.String;"); “[L”声明普通类型数组，”java.lang.String”表示类型(类型全称)，”;”表示结束 通过getClass方法1Class class = arrays.getClass(); 获取数组属性获取数组类型1Class type = class.getComponentType(); 参考http://ifeve.com/java-reflection/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap的死循环(HashMap infinite loop)]]></title>
      <url>%2F2016%2F08%2F28%2FHashMap_infinite_loop%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 HashMap是一个线程不安全的key-value的存储集合，也意味着它在多线程的环境中也存在很大的风险。 HashMap的存储结构： 通常来讲，HashMap是由一个数组和一个链表组成，在初始化的时候，HashMap会初始化一个数组table[],在不指定容量的情况下默认为16，负载系数为0.75，HashMap在put的时候会通过key的hash值来计算这个数组的下标，然后就把这个存储集合存储在该下标的数组中，在查找时的复杂度为O(1),然而在Hash算法中，很有可能存在不同的key算出相同的值，HashMap就会把相同的值用链表来表示，这个时候就要遍历链表了，查找复杂度为O(n) 正是由于链表的存在，在多线程的环境下，共享链表，这就会变得不安全了 什么时候链表会变得不安全呢？HashMap的容量是动态的，随着容量的增加而增量，在每次put的时候都会检查当前的容量是否满足，假设上述图片的容量为4，如果当前的容量大于4乘以0.75(负载因子)，就会创建一个4乘以2的容量的新数组，将老的数组Copy到新的数组，然后所有的值就会重新hash，也就是rehash 现在我们模拟两个线程下的rehash情况，我们有两个线程：Thread1，Thread2，我们先看看HashMap中的rehash方法transfer(). 123456789101112131415// tranfer()片段// 这是在resize()中调用的方法,resize()就是HashMap扩容的方法 for (int j = 0; j &lt; src.length; j++) &#123; Entry e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry next = e.next; //假设线程1停留在这里就挂起了,线程2登场 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125;&#125; 此时运行完Thread1： 此时Entry e是e1，Entry next = e.next中的next是next1,红色是还没有完成，指针指向步骤还没有开始。现在Thread2登场了，Thread2运行完结构如下： 发现与Thread1的情况刚好反过来了，此时Entry e是e2，Entry next = e.next中的next是next2，是的，Thread2已经完成了指针指向操作了 12345Entry next = e.next; int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next;//假设Thread2已经走了这里 这个时候Thread1要登场了，从Entry next = e.next;开始继续运行下去,此时在Thread2的影响下Thread1运行的结构已经变了 此时由于Thread2的影响，(key:2 ,value:b)已经指向了(key:1,value:a),而红线是Thread1接下来的操作,完成指针指向操作，当Thread1完成时结构如下 这个时候你就会发现圆圈内形成了一个闭环，infinite loop就形成了！！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[exports和module.exports的区别]]></title>
      <url>%2F2016%2F08%2F22%2Fexports_module.exports%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 首先得明确两个的含义 exports:首先对于本身来讲是一个变量（对象），它不是module的引用，它是{}的引用，它指向module.exports的{}模块 module.exports:首先，module是一个变量，指向一块内存，exports是module中的一个属性，存储在内存中，然后exports属性指向{}模块 内存示意图如下： 现在来看看它们在运用中的异同：12exports.bar=function()&#123;&#125;;module.exports.bar=function()&#123;&#125; 上面的两行代码，分别来暴露相同的模块，两个方式是等价的，因为他们改变的内存是暴露模块的{}，使暴露模块变成了 exports和module.exports的等价是由于他们在操作同一块内存，所以意义是一样的12exports=function()&#123;&#125;;module.exports=function()&#123;&#125; 现在我们把bar属性给去掉，这时候效果就完全不一样了 这时候exports和module.exports操作的就不是同一块内存了,exports指向了新的内存,实际上module.exports也指向了新的内存，但是nodejs中寻找的是module变量下的exports属性所指向的内存块,如果exports和module.exports操作的不是同一个内存块的话，exports就不起作用了，所以不管怎么样，使用module.exports是万无一失的。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker学习笔记]]></title>
      <url>%2F2016%2F07%2F07%2Fdocker%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 什么是dockerdocker是基于linux内核（涉及cgroup，namespace，以及 AUFS 类的 Union FS 等技术），由go语言开发的，实际上是linux的一个独立和被隔离的进程，也可以称之为容器，其中含义如上鲸鱼船的图标（docker的图标）一样形象，鲸鱼船就像是linux一样，船本身相当于内核，船上可以载重的空间相当于文件存储系统，而在船上的箱子就是docker，他只是运行在linux内核上，箱子内部的空间相当于小型的文件存储系统，自成一体，不会受到外部空间（宿主）的影响，可以随时搬到另一艘船(内核)进行运输 docker和传统虚拟机的区别docker属于一种轻量级的虚拟机，那它比传统的虚拟机相比有什么区别 由上图可知，传统的虚拟机运行了一个完整的Guest OS(操作系统)，通过虚拟技术运行在宿主上，而docker上没有运行一个完整的操作系统，它只是一个容器，由docker引擎运行在宿主上，本质上来讲传统的虚拟机是在宿主之上虚拟出一套硬件，独立运行，而docker是直接运行在宿主的内核上，共享硬件资源，所以它的优势很明显 资源利用上更高效(接近宿主) 运行速度高(不需要另外一个完整的操作系统) 可移植性高(共享内核，可以在其他的宿主上运行) 安装docker支持很多主流平台的安装，包括windows，mac，linux各大发行版，在官网上写的很详细，这里说安装的一些注意点 docker对于安装环境有两个很重要的要求 宿主是linux的64位系统 宿主的内核版本不能低于3.10 如果不是linux64位的系统，那只有更换成64位的，内核版本可以通过uname -rshell命令查看你系统的内核版本，如果内核版本过低，通过sudo apt-get install -y --install-recommends linux-generic-lts-xenialshell命令去升级内核，这样就可以开始docker的安装了 如果在使用脚本安装的时候出错，可能是由于国内的防火墙的原因，可以使用国内云服务提供的修改版本 阿里云版本：1curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - DaoCloud版本：1curl -sSL https://get.daocloud.io/docker | sh 如果你的系统内核缺少AUFS内核驱动（这是docker最佳实践的内核）的话，可执行以下指令安装1sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual 如果官网的GPG密钥地址无法识别，可以执行如下指定进行安装 12sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 如果你已经安装好了docker引擎，进行docker服务的启动，linux旧版本(CentOS 7之前，Ubuntu 12.04/14.04,Debian 7 Wheezy)的启动方式： 1sudo service docker start 如果是高版本(CentOS 7之后，Ubuntu 16.04,Debian 8 Jessie/Stretch)的启动方式：12sudo systemctl enable dockersudo systemctl start docker docker核心：镜像，容器，仓库开始docker的第一个例子hello world 1docker run hello-world 以上指令是运行一个名为‘hello-world’的镜像，分解成下面的操作 运行完成会生成一个容器，利用docker ps 指令就可以查询你所生成的容器 由上可知，运行hello-world镜像可以分解成两步： 从本地镜像库查找，如果匹配则运行 如果本地镜像库没有找到，则会从官方维护的镜像库开始查找进行，如果匹配则运行，不匹配则报错 上面无论是本地镜像库，还是官方镜像库都是存储镜像的仓库，其实对于镜像，容器和仓库这三者，如果基于JAVA这种面向对象的语言来理解，镜像相当于一个声明类，而容器相当于一个实例对象，仓库就是JDK,而docker引擎就是等于JVM，当然这不是很严谨，但是很形象 镜像镜像是docker一个很重要的组件，通过docker images指令来查看所有的镜像，如下图所示 由上可知，镜像由五个属性组成： REPOSITORY：镜像实体，一般来讲名为‘hello-world’此类镜像是有官方维护的，‘andy/hello-world’此类镜像是由用户维护的，andy是用户名 TAG：标签，对于软件而言，理解也可以成版本，laster表示是该镜像的最终版本 IMAGE ID：镜像的唯一标识 CREATED：指镜像的创建时间 VIRTUAL SIZE：虚拟大小，并不是实际的大小，跟docker的分层存储有关 利用docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt;命令来加载镜像，如果没有Docker Registry地址，则默认会加载官方的镜像，标签如果没有指定，则默认下载laster版本 也可以利用docker rmi &lt;IMAGE ID&gt;指令去删除指定的镜像，也可以使用docker rmi $(docker iamges -q)去删除所有的镜像 容器简单的说，容器是一组独立运行的应用，由docker引擎提供它的上下文，镜像提供内容，利用docker run 指令可以新建和运行容器，如下图所示 利用docker ps -a指令来查看你所有的容器，如下图所示 由上可知，容器由七项属性组成 CONTAINER ID：容器唯一标识 IMAGE：所依赖的镜像 COMMAND：运行容器的命令 CREATE：容器的创建时间 STATUS：容器的状态 PORTS：所暴露的端口 NAMES：容器名 利用docker stop &lt;container id&gt; 指令停止指定容器运行，也可以使用docker stop $(docker ps -a)停止所有的容器如果你想启动它，可以利用docker start &lt;container id&gt;命令，如果你还想重新启动，可以利用docker restart &lt;container id&gt;,如果你想删除一个容器,可以使用docker rm &lt;container id&gt;，这跟删除镜像有点相似，rm指令是删除容器的，rmi指令是删除镜像的 仓库仓库是存放镜像的地方，官方维护了一个类似于github的dockerhub公共仓库来存放镜像，它的设计思想跟github很像，在这里你可以托管你的镜像，你可以点击dockerhub注册一个dockerhub的账户，然后在终端利用docker login命令输入你的用户名，密码和邮箱进行登录，在本地用户目录就会生成一个.dockercfg文件来保存用户信息，可以利用docker search &lt;image&gt;命令查询你所要镜像的信息，如下图所示 由上可知，你所查询的该镜像在公共仓库的信息，以下五项组成 NAME：相关镜像的名称 DESCRIPTION：相关镜像的描述 STARS：喜欢程度，表示该镜像的受欢迎程度 OFFICIAL：是否是官方的镜像 AUTOMATED：是否是自动创建的镜像 然后使用docker pull &lt;image&gt;命令加载公共仓库的镜像到本地，当然如果想要将自己的镜像推送到公共仓库上只需要两步 将你自己的镜像打上标签：docker tag &lt;IMAGE ID&gt; &lt;USERNAME&gt;/&lt;IAMGE NAME&gt;:&lt;TAG&gt;. 推送到公共仓库：docker push &lt;USERNAME&gt;/&lt;REPOSITORY&gt;. 自定义镜像：dockerfile现实中，官方的镜像是根本不能满足我们的需求的，所以我们需要自己去自定义镜像，首先我们需要创建dockerfile文件 123mkdir myimagecd myimagetouch Dockerfile 现在可以开始来构建一条鲸鱼的镜像，首先用文本编辑器打开Dockerfile，编辑以下内容123FROM docker/whalesay:latestRUN apt-get -y update &amp;&amp; apt-get install -y fortunesCMD /usr/games/fortune -a | cowsay Dockerfile内容一条指令会加载一层镜像，以下会分成三步执行 加载鲸鱼的镜像 更新软件源，并下载安装fortunes应用 运行这个应用 现在在该目录下利用docker build -t docker-whale .指令就完成了自己的镜像构建了，这里要注意一点，在构建的时候，镜像名后会跟随一个.，这个往往会被忽略掉，这表示运行该镜像的上下文，不是Dockerfile文件的位置，Dockerfile里所运行的上下文都是基于这个定义的，你自己也可以定义你想要的上下文，比如使用/usr/local替换.最后使用docker run docker-whale指令运行该镜像，如下图所示： 这就是一个基于官网的例子的自定义镜像，自定义镜像让docker更加灵活，更加强大，让就像编程一样，拥有无限魔力 这里列举自定义镜像最佳实践和建议 Dockerfile的定义尽量是简短的，合理而又简短的配置，一站化停止和销毁 每个Dockerfile目录尽量只有Dockerfile文件，如果有其他文件，在构建的时候，可以新建一个.dockerignore的文件到该目录进行排除其他不必要的文件 尽量避免安装不必要的包，即使他是很有用的 多数情况下，一个容器只是运行一个进程，这样能够更容易扩展和重复使用(使用容器连接) 减少构建层数来减少构建的复杂度，使用‘\’和连接符‘&amp;&amp;’来进行一次性构建 这里再列举一些常用的Dockerfile指令 LABEL记录你的Dockerfile的信息 比如：LABEL version=”0.0.1-beta” RUN运行你的应用程序或者是指令 比如：RUN apt-get update &amp;&amp; apt-get install -y curl注意：如果以上命令分成两层写，会导致获取缓存内以前的版本，导致安装无效 CMD运行该镜像包含的软件 比如：CMD [“sh”,”-s”“server tomcat start”] ENTRYPOINT运行你的应用程序和指令，或者是脚本 ENTRYPOINT [“server”]注意：如果指定了ENTRYPOINT，那么后面的CMD都变成了它的参数 EXPOSE指定该容器所监听连接的默认端口，如果docker run -p指定端口，则会覆盖该端口，比如EXPOSE 8080 ENV更新或添加你当前容器的环境变量 比如：ENV PATH /user/local/nginx/bin:$PATH ARG构建临时的环境变量，在容器运行时不会存储这些环境变量 比如：ARG NAME [=jack] COPY本地文件复制到容器 比如：COPY usr/local/ /usr/local/ ADD也有复制的功能，但在其上多了远程url下载，和自动解压包的功能 比如：ADD http://source.com/a.tar /usr/local (先下载url的资源，再解压到目标目录中)注意：推荐使用COPY，因为他的目标更明确，ADD相当于使用了多层的RUN，还不如使用RUN加连接符 VOLUME指定数据存储区，使容器和宿主进行映射存储 比如：VOLUME /data 然后使用docker run -dv mydata:/data 命令指定宿主的mydata作为容器中data目录的存储区 WORKDIR指定当前目录(目录必须存在，应使用绝对路径)，比如： WORKDIR /usr/local/ USER指定当前用户 比如：USER docker ONBUILD指定当前的镜像后面的指令不会马上构建，只有在别的镜像引用时才构建加载，适合一些基础的组件构建 总结：这是一篇docker的学习笔记，docker很强大，特别在云服务平台发挥很大的重要，现在在很多集群管理也使用docker来构建，学习docker也会有很大的提升。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[原子操作-CAS]]></title>
      <url>%2F2016%2F06%2F06%2Fcas%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 概念CAS(compare and swap)，比较和交换，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值—来自wikipedia 现代的大多数CPU都实现了CAS,它是一种无锁(lock-free),且非阻塞的一种算法，保持数据的一致性，原理并不难理解，下面是一段CAS的简单实现： 1234567891011121314public boolean cas(int old_v)&#123; for(;;)&#123; int new_v = old_v+1; int except_v = getMemoryValue(); if(expect_v == old_v)&#123; setMemoryValue(new_v); break; &#125;else&#123; old_v = except_v; &#125; &#125; return true;&#125; 其中getMemoryValue()方法指在内存中取出最新的值，setMemoryValue(new_v)方法指在讲新的值放入内存中，整个if-else就是CAS的操作（expect_v==old_v是compare，而setMemoryValue(new_v)是swap），假设有两个线程访问以上代码，用分段图表示如下： 以上图就是CAS的操作表现，由此可知，在CAS中，有三个核心的属性：old_i(旧值)，new_i(新值)，expect_i(期望值)，它每次通过旧值通过计算得到新值，然后利用旧值与期望值(从内存读取的最新的值)相比较，如果相同，就将新值写入内存中替换期望值，如果不相同，则表示操作失败，重新执行。 ABA问题CAS并不是一个完美的无锁算法，在以上的CAS操作中，getMemoryValue()方法只是在内存中取出最新的值，它不会在乎它的变化，如下图所示 如上图所示，如果线程2期间发生了两次变化，线程1是察觉不到的，经典的例子就是堆的pop和push，线程1入栈时，top的值是A，然后线程2进行了两次入堆，第二次入栈的值也是A，线程1对top进行compare，发现和旧值是一样的，就执行入堆操作，其实这时堆已经发生了改变当然如果想要解决这个问题，只有加上一个标志或者版本号来监视它的变化，这样由两个值来最为compare的根据，如还是堆的pop和push问题，只要加上一个操作标志，当每次对进行pop或者push就加1，那compare的时候再加上对原来的改变次数和现在的改变次数进行比较，这样就可以避免ABA问题了 应用乐观锁乐观锁是在最理想的情况下去执行，只有在发生冲突的时候再进行处理，其实这跟CAS的理念是很符合的，也可以这么讲，CAS也是一种乐观锁技术 JAVAjava中实现了大量的CAS操作，在JDK1.5发布的java.util.concurrent包就是建立在CAS之上的，相对比与synchronized这种锁机制且阻塞的算法，无锁且非阻塞的CAS无疑在性能上有质的提升，来看看java对CAS的实现，以AtomicInteger的增量方法为例(基于JDK1.8)123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 这里会调用sun.misc包下的Unsafe类，这是一个调用底层指令集的final类，下面看一下getAndAddInt方法12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 在这里你会看见compareAndSwapInt方法，这是一个native的方法，用来调用CPU的CAS指令实现无锁且非阻塞的增量操作，这在concurrent包下有很多这样的操作，JDK1.8的concurrentHashMap放弃了分段锁的概念，采用了CAS操作，这大大的增加了多线程下的性能 总结很多时候在线程安全和性能方面很难得到权衡，线程安全的三大特性：可见性，原子性和顺序性，原子性往往就要加上锁去实现，现在用CAS去替代原子性，volatile保证可见性和顺序性，大大增加了多线程在操作上的性能 参考https://zh.wikipedia.org/wiki/%E6%AF%94%E8%BE%83%E5%B9%B6%E4%BA%A4%E6%8D%A2http://zl198751.iteye.com/blog/1848575]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库索引]]></title>
      <url>%2F2016%2F05%2F12%2Fdatabase_index%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 索引概述 索引（英语：Index）：又稱引得，通檢，備檢，是一本书籍的重要组成部分，它把书中的重要名词列罗列出来，并给出它们相应的页码，方便读者快速查找该名 词的定义和含义—-来自维基百科。 数据库索引：是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据——来自维基百科。 索引很普遍，也很方便，他能使人能更好更快的找到自己想要的东西，在生活中也都能有很好的应用，比如一些书籍目录，指示牌，门牌号，而下面讲到的是在数据库中的应用。 数据库索引二叉树查找树要知道数据库索引之前，必须知道一种数据结构二叉查找树 二叉查找树是一种特殊的二叉树，必须要符合一定的结构规则： 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 如上图所示可知，我们这颗二叉查找树一共有7个节点，比如我们现在要搜索122这个节点，从根节点100开始遍历： 由于100&lt;122，所以我们需要查找根节点的右节点150 由于122&lt;150，所以我们现在需要查找它的左节点122 由于122==122，返回当前的节点(如果122节点绑定了当前数据库的信息，我们就可以通过索引来查找数据了) 二叉查找树是根据查找的层数来决定你的查找效率，当然最坏的查找效率也就O(n),但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(log n),如SBT,AVL树，红黑树等。 其实在这里你就能够想象到在数据库中使用索引的查找时的整个结构过程，以上我们会发现，二叉搜索树太依赖搜索的层数，数据太多也意味着层数也会增加，查询的效率也会相应的下降，面对百万级，甚至亿级的查询时，分分钟崩溃，而且你也会发现二叉搜索树应对的是单值查询（where p=2），在范围查询（where 1&lt;p&lt;3）中就捉襟见肘了（要遍历很多次），其实在单值查询中还有一种索引结构叫做哈希表 哈希表哈希表（Hash table，也叫散列表），是根据键（Key）而直接访问在内存存储位置的数据结构。 也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。 这个映射函数称做散列函数，存放记录的数组称做散列表。—-来自维基百科 其实在数据库中一些简单常见的连接操作叫做hash连接，这个数据结构也被数据库用来保存一些内部的东西（比如锁表或者缓冲池） 哈希表的定义： 关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。 关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。 由图可知，这个Hash table中有0-9十个哈希桶，我们想象成是一个数组（以0-9下标组成）,比如你所要查找的关键字通过哈希函数对10去模，保留整数有效位最后一位，用它利用比较函数（比如equals）来定位哈希桶的位置： 如果元素最后一位是 0，则进入哈希桶0， 如果元素最后一位是 1，则进入哈希桶1， 如果元素最后一位是 2，则进入哈希桶2 。依次类推 比方说你要找元素 78： 哈希表计算 78 的哈希码，等于 8。 查找哈希桶 8，找到的第一个元素是 78。 返回元素 78 查询仅耗费了 2 次运算（1次计算哈希值，另一次在哈希桶中查找元素）。 现在，比方说你要找元素 59： 哈希表计算 59 的哈希码，等于9。 查找哈希桶 9，第一个找到的元素是 99。因为 99 不等于 59， 那么 99 不是正确的元素。 用同样的逻辑，查找第二个元素(9)，第三个(79)，……，最后一个(29)。 元素不存在。 搜索耗费了 7 次运算其实由上可知，只要你的哈希函数与哈希桶定义的越好，查找的效率也就相应的越高。 B-Tree以上的关于查找的数据结构都不能满足现在日新月异的数据库了，在二叉树搜索树的基础上，又演变出一种新的数据结构B-Tree B树（英语：B-tree）是一种自平衡的树，能够保持数据有序。这种资料结构能够让查找数据，顺序访问，插入数据及删除的动作，都在对数时间内完成—-来自维基百科 一颗m阶的B-Tree规则如下： 树中每个结点至多有m个孩子； 除根结点和叶子结点外，其它每个结点至少有m/2个孩子； 若根结点不是叶子结点，则至少有2个孩子； 所有叶子结点(失败节点)都出现在同一层，叶子结点不包含任何关键字信息； 所有非终端结点中包含下列信息数据 ( n, A0 , K1 , A1 , K2 , A2 , … , Kn , An )，其中： Ki (i=1,…,n)为关键字，且Ki &lt; Ki+1 , Ai (i=0,…,n)为指向子树根结点的指针, n为关键字的个数 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 相对于二叉搜索树而言，B-Tree在每个节点中最少都得有两个孩子，优化了二叉搜索树过于依赖层数，使其更加灵活，然而相应的维护成本大大的增高。 如上图所示，比方说你要查找节点21,从根节点开始遍历： 在根节点中，由于节点21满足20&lt;21&lt;30,所以指针指向了P2 在P2中，节点21满足21&lt;22,但是指针没有指向任何地址，所以返回NULL 又比方说要查找节点88，从根节点开始遍历 在根节点中，由于节点88满足30&lt;80,所以指针指向P3 在P3中，节点88满足88&gt;62,所以指针指向P7 在P7中，节点88满足88==88，所以返回P7中的88节点 由于B-Tree的索引结构文件和表数据存储文件不是连在一起的，访问数据也有额外消耗了 由上你可以发现这种结构还是不能高效解决范围查询的场景，当出现范围查询（where 1&lt;p&lt;3）,B-Tree还是得一遍一遍的从根节点开始遍历，再一次一次进行磁盘IO（因为索引文件存储在磁盘上，而磁盘操作是物理操作，非常耗时的，所以磁盘IO是数据库查询的一个瓶颈，后面的B+Tree正好优化了这一点）。 B+Tree B+ 树是一种树数据结构，通常用于数据库和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反——来自维基百科 在一个B+树里结构： 只有最底层的节点（叶子节点）才保存信息（相关表的行位置） 其它节点只是在搜索中用来指引到正确节点的 所有的叶子节点都带有关键字直至底层节点 B+树是B树的进化体,他从磁盘IO上对原有的结构进行了优化,以至于减少对磁盘的IO（上面也提到，磁盘IO是物理操作，这对磁盘来说是很耗时间的），大大的增加了搜索的效率。 上面也提到，B树对于范围查询来讲是比较吃力的，不能高效的满足它的需求，因为范围查询（where 1&lt;p&lt;3）正常情况下在B树上要遍历两或者三遍（每次从根节点遍历），意味着要至少进行两三次的磁盘IO，这对于大数据量查询来讲是很吃力的。 B+树是怎么样进行减少磁盘IO的优化呢？我们先来看看一个范围查询在索引是怎么遍历的。 我们假设一个范围查询：where 10&lt;p&lt;50 在根节点中，满足5&lt;10&lt;58,所以指针指向P1节点 在P1节点中，满足5&lt;10&lt;30,所以指针指向P2节点 在P2底层节点中，每个节点都带有关键字，且每个节点之间相互链接，可以从一个节点遍历到另一个节点，且都是顺序的，所以，在大于或等于10的节点开始遍历，一直遍历到小于等于50为止 由上可知，在底层节点都是互相连接的，遍历中间的值就是查询的结果，而且B+树的表数据和索引文件是存储在一起的，所以遍历的就是表的行数据，这样只要一次IO就完成了。 参考http://coding-geek.com/how-databases-work/http://blog.csdn.net/v_july_v/article/details/6530142]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo搭建github博客]]></title>
      <url>%2F2016%2F05%2F11%2Fset_up_github_blog_with_hexo%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 安装环境 由于hexo是基于node.js的一个博客框架，所以在安装hexo之前，先安装node.js，点击node.js进入官网进行安装即可 当然还要安装基于github的deploy工具git，点击git，进入官网进行安装即可 以上安装完成时，在你的博客磁盘区域新建一个hexo文件夹，进入hexo文件夹，右键点击Git Bash Here，就会进入git的交互环境，安装hexo环境只需三个指令 123$ npm install hexo-cli -g$ hexo init$ hexo g 依次完成以上的指令，就完成了hexo的安装，现在我们启动服务，输入1$ hexo s 即可以启动hexo服务，根据提示在浏览器输入 http://localhost:4000/ 就可以查看你博客了 当然这里有一些常用命令做参考： hexo new “postName” # 新建文章 hexo new page “pageName” # 新建页面 hexo generate # 生成public目录 hexo server # 启动服务 hexo deploy # 部署到github hexo help # 查看帮助 hexo version # 查看Hexo的版本 选择主题在 http://localhost:4000/ 看到的是hexo默认的博客主题，如果你想要别的主题，点击 https://hexo.io/themes/ 就可以查看了hexo的主题大全。我使用的Random主题，他符合以下人群： 喜欢用大图做背景 不喜欢文章摘要 不喜欢在文章列表中翻页 如果你也喜欢Random主题，接下来简单的介绍它的安装，安装Random只需两个指令就可以完成，还是在/hexo目录下运行下面的指令1$ git clone https://github.com/stiekel/hexo-theme-random.git themes/random 这样主题就下载好了,现在打开 hexo/_config.yml (_config.yml文件有两个，一个在hexo的根目录下，一个在你的主题文件夹的根目录下)，找到theme属性，将主题设为random1theme: random 这里要注意一点，yaml配置文件的属性冒号之后要有一个空格，然后是值，否则将读取不到你的值然后再重启服务12$ hexo clean$ hexo s 这样就可以查看Random主题的效果了，当然了还有其他配置，比如配置他的tags，categories，about，还有你的社交网站的链接的配置，你可以访问的他的中文文档 http://hexo-theme-random.herokuapp.com/2016/05/23/Hexo-theme-Random-Chinese-User-Guide/ 这里面可以很全面的去配置random主题的博客。 github部署如果你想把你的本地的静态博客部署到线上，github是一个很好的选择，它是一个代码托管工具，由于还支持markdown这样的文本编辑格式，所以也可以算是博客的托管工具，我们可以把我们的博客托管到github上，就可以通过浏览器的url访问了。 如果你没有github的账号，你可以点击 https://github.com/ ，根据它的提示注册账号和配置shh，也可以网上搜索github如何使用，如果你有github账号,接下来就是创建博客的仓库。 创建仓库首先你先在github的repositores页面点击右上角的new按钮，来新建一个仓库，然后在Repository name一栏，写上yourname.github.io (yourname指你的用户名)，然后点击create repository按钮进行创建。 配置_config.yml在hexo根目录下的_config.yml找到 deploy: 处，设置你自己的发布信息1234567deploy: #类型为git type: git #填写你仓库的地址 repository: https://github.com/yourname/yourname.github.io.git #根据你自己的分支情况，如果没有其他分支，一般为主分支 branch: master 注意：在前面也提到，每个属性后面的值前面一定要有个空格，比如 type:(空格)git 发布现在就是将你本地的静态博客发布到github上12$ hexo clean$ hexo d -g 注意，如果你的hexo是5.0以上或者出现 error deployer not found 错误 ，那就必须先安装 hexo-deployer-git 1npm install hexo-deployer-git --save 命令 git d -g相当于git g再git d，命令完成之后只需输入你的用户名和密码完成验证即可，发布完成，打开浏览器，输入 http://yourname.github.io 就可以查看你的博客了。 域名管理当然如果你不喜欢github的子域名来访问你的博客，这个时候，你就得自己创建域名了 域名的供应商很多，不过国内外最有名的就是 godaddy 了，狗爹是目前号称最大的域名注册商，当然各种服务也是挺好的，当然还有中国的 万维网 ，不过还是推荐狗爹，这里域名注册我就不介绍了，你只需按照网站步骤就可以了 不过得注意狗爹上很多域名产品是有优惠的，你只需google或者百度godaddy优惠码就会有很多的，可以一一去试，还是能够省一点的，对于国内来讲，优惠码一定要看准是否支持支付宝支付，因为有些优惠码不支持支付宝，当然如果你有国外的信用卡或者银联就另当别论了。 CNAME想要你的域名访问你的github的仓库，就必须要创建CNAME文件,CNAME文件创建有两种方法： 第一种直接在你的仓库的根目录下直接创建CNAME文件，内容为你域名的名称，比如 1pettyandydog.com 第二种在 /hexo/source/ 目录下创建CNAME文件( 推荐 )，内容相同，然后再重新发布 DNS配置如果你已经注册号域名了，接下来就是dns配置了，dns配置有两种 第一种用是godaddy自己的dns解释器，打开godaddy的账户/产品，点击当前域名下的DNS管理按钮，配置如下 第二种使用DNSpod域名DNS代理,注册DNSpod，进入DNSpod管理，添加你自己的域名，一样按上图添加记录，然后将godaddy的nameservers界面增加两条记录 这样就大功告成，输入你的网站 ( 比如：http://pettyandydog.com ) 就可以访问你的博客了,有时候可能短时间访问不了，只需等上一段时间就可以了。]]></content>
    </entry>

    
  
  
</search>
