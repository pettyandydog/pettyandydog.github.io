<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[深入并发包-AQS]]></title>
      <url>%2F2017%2F06%2F27%2FAQS%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言在java.util.concurrent并发包中，很多类的并发同步控制都是基于AbstractQueuedSynchronizer（简称AQS）这个同步器抽象类来实现的，比如ReentrantLock，Semaphore，CountDownLatch，ReentrantReadWriteLock，SynchronizerQueue和FutureTask，它通过依赖状态来实现获取锁或者一种许可的机制，下面通过源码来分析AQS以及ReentrantLock可重入锁中AQS的运用 AQS获取锁先看下他的继承体系：123public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; AQS继承于AbstractOwnableSynchronizer，顾名思义：线程独有的同步器，这为创建需要所有权的锁和相关的同步器提供了基础，在AbstractOwnableSynchronizer中只提供了一个线程属性的setter和getter方法12345678private transient Thread exclusiveOwnerThread;protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread;&#125;protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread;&#125; AQS继承了exclusiveOwnerThread属性，表示当前拥有独占锁的的线程，这也引入了锁的另一个特性：重入性，当前线程直接通过if (currentThread == getExclusiveOwnerThread()){state++}判断是否已经拥有了锁 现在我们再回到AQS，查看AQS的属性结构1234567// 头结点，你直接把它当做 当前持有锁的线程 可能是最好理解的private transient volatile Node head;// 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个隐视的链表private transient volatile Node tail;// 这个是最重要的，不过也是最简单的，代表当前锁的状态，0代表没有被占用，大于0代表有线程持有当前锁// 之所以说大于0，而不是等于1，是因为锁可以重入嘛，每次重入都加上1private volatile int state; 如上所示就是AQS定义的三个属性，其实线程在AQS会被抽象成一个Node的执行单元，我们再来看一看Node的结构：123456789101112131415161718192021222324252627282930313233343536static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ // 标识节点当前在共享模式下 static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 代表此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 表示线程处于等待的条件下的值，与下面的waitStatus对应，这在Lock中的condition中会使用 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; // ===================================================== // 取值为上面的1、-1、-2、-3，或者0(以后会讲到) // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // 也许就是说半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程本尊 volatile Thread thread;&#125; 这就是AQS的数据结构了，其实就是一个FIFO的队列，队列中的每一个节点Node就是代表一个具有状态的线程，如下图所示 我们新进的线程会插入队列的尾端tail，而队列的执行序列从head开始，AQS的工作就是维护这个队列以及node中线程的各种状态，下面以ReentrantLock的公平锁来分析AQS在其中发挥的作用 我们以下面ReentrantLock的使用方法来进入AQS1234567891011public class LockTest&#123; private ReentrantLock reentrantLock = new ReentrantLock(true); //构建ReentrantLock public void lockService() &#123; try &#123; reentrantLock.lock(); //获得锁 // do业务代码 &#125; finally &#123; reentrantLock.unlock();// 释放锁 &#125; &#125;&#125; ReentrantLock的构造方法如下 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 当fair参数为true时，将会创建内部类FairSync类，这是一个公平锁的实现，源码继承结构如下123static final class FairSync extends Sync &#123; ......&#125; FairSync继承与Sync，这是AQS的实现类，我们再来看一下Sync的源码继承结构123abstract static class Sync extends AbstractQueuedSynchronizer &#123; ......&#125; ReentrantLock只支持以独占锁的方式来获取锁，所以会实现AQS中的tryAcquire和tryRelease和isHeldExclusively这三个核心的方法，内部会用名叫Sync的内部抽象类来管理线程锁，当线程调用lock方法获取锁时，我们来看看FairSync的lock方法 123final void lock() &#123; acquire(1); &#125; 他会调用继承于AQS的acquire的方法，如下所示 123456789101112// 我们看到，这个方法，如果tryAcquire(arg) 返回true, 也就结束了。// 否则，acquireQueued方法会将线程压到队列中public final void acquire(int arg) &#123; // 此时 arg == 1 // 首先调用tryAcquire(1)一下，名字上就知道，这个只是试一试 // 因为有可能直接就成功了呢，也就不需要进队列排队了， // 对于公平锁的语义就是：本来就没人持有锁，根本没必要进队列等待(又是挂起，又是等待被唤醒的) if (!tryAcquire(arg) &amp;&amp; // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; selfInterrupt(); &#125;&#125; 当前线程会尝试去获取锁，调用FairSync实现的tryAcquire(1)方法,如下所示 1234567891011121314151617181920212223242526272829303132333435// 尝试直接获取锁，返回值是boolean，代表是否获取到锁// 返回true：1.没有线程在等待锁；2.重入锁，线程本来就持有锁，也就可以理所当然可以直接获取protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 如果state == 0 表示此时此刻没有线程持有锁 if (c == 0) &#123; // 虽然此时此刻锁是可以用的，但是这是公平锁，既然是公平，就得讲究先来后到， // 看看有没有别人在队列中等了半天了 if (!hasQueuedPredecessors() &amp;&amp; // 如果没有线程在等待，那就用CAS尝试一下，成功了就获取到锁了， // 不成功的话，只能说明一个问题，就在刚刚几乎同一时刻有个线程抢先了 =_= // 因为刚刚还没人的，我判断过了😂😂😂 compareAndSetState(0, acquires)) &#123; // 到这里就是获取到锁了，标记一下，告诉大家，现在是我占用了锁 setExclusiveOwnerThread(current); return true; &#125; &#125; // 判断是否是重入的线程，需要操作：state=state+1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; // 如果到这里，说明前面的if和else if都没有返回true，说明没有获取到锁 // 回到上面一个外层调用方法继续看: // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); return false;&#125; 如果返回false的话，会把当前线程加入阻塞队列中，现在我们继续来进入AQS中的addWaiter方法12345678910111213141516171819202122232425262728293031323334/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ // 此方法的作用是把线程包装成node，同时进入到队列中 // 参数mode此时是Node.EXCLUSIVE，代表独占模式 private Node addWaiter(Node mode) &#123; //mode值下一个等待的线程节点，默认为null Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后 Node pred = tail; // tail!=null =&gt; 队列不为空(tail==head的时候，其实队列是空的，不过不管这个吧) if (pred != null) &#123; // 设置自己的前驱 为当前的队尾节点 node.prev = pred; // 用CAS把自己设置为队尾, 如果成功后，tail == node了 if (compareAndSetTail(pred, node)) &#123; // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连， // 上面已经有 node.prev = pred // 加上下面这句，也就实现了和之前的尾节点双向连接了 pred.next = node; // 线程入队了，可以返回了 return node; &#125; &#125; // 仔细看看上面的代码，如果会到这里， // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队) enq(node); return node; &#125; 如果队列是空的，或者有竞争，就调用enq方法采用自旋的方式来加入阻塞队列，如下所示 123456789101112131415161718192021222324252627282930313233343536373839/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */ // 采用自旋的方式入队 // 之前说过，到这个方法只有两种可能：等待队列为空，或者有线程竞争入队， // 自旋在这边的语义是：CAS设置tail过程中，竞争一次竞争不到，我就多次竞争，总会排到的 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 之前说过，队列为空也会进来这里 if (t == null) &#123; // Must initialize // 初始化head节点 // 细心的读者会知道原来head和tail初始化的时候都是null，反正我不细心 // 还是一步CAS，你懂的，现在可能是很多线程同时进来呢 if (compareAndSetHead(new Node())) // 给后面用：这个时候head节点的waitStatus==0, 看new Node()构造方法就知道了 // 这个时候有了head，但是tail还是null，设置一下， // 把tail指向head，放心，马上就有线程要来了，到时候tail就要被抢了 // 注意：这里只是设置了tail=head，这里可没return哦，没有return，没有return // 所以，设置完了以后，继续for循环，下次就到下面的else分支了 tail = head; &#125; else &#123; // 下面几行，和上一个方法 addWaiter 是一样的， // 只是这个套在无限循环里，反正就是将当前线程排到队尾，有线程竞争的话排不上重复排 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; // 然后再次回到这段代码了 // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); 我们再来看一看acquireQueued方法，在进入阻塞队列中，他会再次尝试获取锁，如下所示1234567891011121314151617181920212223242526272829303132333435// 下面这个方法，参数node，经过addWaiter(Node.EXCLUSIVE)，此时已经进入阻塞队列// 注意一下：如果acquireQueued(addWaiter(Node.EXCLUSIVE), arg))返回true的话，// 意味着上面这段代码将进入selfInterrupt()，所以正常情况下，下面应该返回false// 这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//获取当前node的前一个node // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列 // 所以当前节点可以去试抢一下锁 // 这里我们说一下，为什么可以去试试： // 首先，它是队头，这个是第一个条件，其次，当前的head有可能是刚刚初始化的node， // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程 // 也就是说，当前的head不属于任何一个线程，所以作为队头，可以去试一试， // tryAcquire已经分析过了, 忘记了请往前看一下，就是简单用CAS试操作一下state if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 到这里，说明上面的if分支没有成功，要么当前node本来就不是队头， // 要么就是tryAcquire(arg)没有抢赢别人，继续往下看 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 当前线程获取锁失败会调用shouldParkAfterFailedAcquire方法，如下所示12345678910111213141516171819202122232425262728293031323334353637383940414243444546 // 刚刚说过，会到这里就是没有抢到锁呗，这个方法说的是："当前线程没有抢到锁，是否需要挂起当前线程？" // 第一个参数是前驱节点，第二个参数才是代表当前线程的节点 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; //下面的三个判断符合下列三种规则 // 规则1：如果前继的节点状态为SIGNAL，表明当前节点需要unpark(唤醒)，则返回成功，此时 acquireQueued方法的第12行（parkAndCheckInterrupt）将导致线程阻塞 // 规则2：如果前继节点状态为CANCELLED(ws&gt;0)，说明前置节点已经被放弃，则回溯到一个非取消的前继节点，返回false，acquireQueued方法的无限循环将递归调用该方法，直至规则1返回true，导致线程阻塞 // 规则3：如果前继节点状态为非SIGNAL、非CANCELLED，则设置前继的状态为SIGNAL，返回false后进入acquireQueued的无限循环，与规则2同 // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点 waitStatus大于0 ，之前说过，大于0 说明前驱节点取消了排队。这里需要知道这点： // 进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。 // 所以下面这块代码说的是将当前节点的prev指向waitStatus&lt;=0的节点， if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 仔细想想，如果进入到这个分支意味着什么 // 前驱节点的waitStatus不等于-1和1，那也就是只可能是0，-2，-3 // 在我们前面的源码中，都没有看到有设置waitStatus的，所以每个新的node入队时，waitStatu都是0 // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;// 回到下面的代码// if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;// parkAndCheckInterrupt()) 如果此线程取消了竞争（也就是waitStatus&gt;0），就会进入阻塞中断，这个时候需要一个契机将他唤醒，所有要不断循环前一个节点作为需要作为唤醒的契机（这在后面的释放锁操作会有说明），返回false，如果返回true的话，接下来会调用parkAndCheckInterrupt方法来检查中断操作，如下所示 123456// 这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的// 这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒=======private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放锁看完了获取锁，现在来看看释放锁的实现，在前面reentrantLock的使用用例中，当线程执行完会在finally块中执行reentrantLock.unlock()来释放锁，如下所示123public void unlock() &#123; sync.release(1);&#125; 他会调用release(1)方法,如下所示 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 上述会尝试执行释放锁的操作，调用FairSync实现的tryRelease方法，和获取锁的路子类似 1234567891011121314protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 是否完全释放锁 boolean free = false; // 其实就是重入的问题，如果c==0，也就是说没有嵌套锁了，可以释放了，否则还不能释放掉 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 如果释放锁成功，且head不为空就会调用unparkSuccessor方法来唤醒后继的线程，如下所示：1234567891011121314151617181920212223242526272829303132// 唤醒后继节点// 从上面调用处知道，参数node是head头结点private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 如果head节点当前waitStatus&lt;0, 将其修改为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 下面的代码就是唤醒后继节点，但是有可能后继节点取消了等待（waitStatus==1） // 从队尾往前找，找到waitStatus&lt;=0的所有节点中排在最前面的 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后往前找，仔细看代码，不必担心中间有节点取消(waitStatus==1)的情况 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 唤醒线程 LockSupport.unpark(s.thread);&#125; 唤醒的线程会在如下代码继续进行1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 刚刚线程被挂起在这里了 return Thread.interrupted();&#125; 注意：LockSupport是并发包中针对线程阻塞操作的工具类 执行完，这时会返回到acquireQueued(final Node node, int arg)方法，而方法中的无限循环for(;;)就是为了唤醒的线程重新去获取锁，直到异常退出或者执行完 总结AQS是由CLH锁实现的,是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋，在整个并发包中，很多地方你都会看见AQS的身影，他在并发控制的作用无法替代 参考https://hongjiev.github.io/2017/06/16/AbstractQueuedSynchronizer/http://blog.csdn.net/chen77716/article/details/6641477]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发包-线程池]]></title>
      <url>%2F2017%2F06%2F13%2Fthreadpool%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言线程是应用程序执行任务的最小单元，在jvm中允许应用程序在多个线程同时执行，竟可能利用服务器的性能来最大化提高应用程序的吞吐量和响应性，但是往往在生产环境中，如果我们为每一个任务分配一个线程，当创建足够多的时候，就会存在一些明显的缺陷： 线程生命周期开销高：线程的创建和销毁是需要一定的时间，并且需要JVM和操作系统相互辅助操作，在应用程序创建足够多的线程时，这个消耗也是很可观的 资源消耗：活跃的线程会消耗大量的内存，如果你的处理器数量少于你的处理线程的数量，这将会产生大量的闲置线程，这会占用大量的内存，以及在共享资源的竞争上会产生其他的性能开销，同时也给GC带来压力 稳定性：每个平台对于线程都会有一定的限制，对于JVM来讲，在JVM的启动参数或者Thread构造函数请求栈的大小这都对线程的数量造成一定的限制，如果超过了这些限制，很有可能会造成难以恢复的OutOfMemoryError的异常，还有操作系统本身对线程的一些限制，都会造成应用程序的不稳定基于以上的一些缺陷，所以需要有一种机制来管理线程，这就出现了Executor框架 Executor框架Executor框架是JDK1.5提出的，由JAVA大神Doug Lea编写，他很详细的描述了线程的生命周期，现在我们来看一看Executor框架的结构图 ExecutorExecutor是Executor框架最顶层的接口，也是最核心的功能，我们进入Executor接口的源码（JDK1.8）看一看12345678910111213public interface Executor &#123; /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &#123;@code Executor&#125; implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);&#125; 由上可知，Executor接口只有一个execute方法，他的功能从注释中可知：就是提交一个任务命令，然后在将来的某个时间段执行该（一组或者一个）任务命令，显而易见，这是个执行线程的方法，他将线程的提交过程和线程的执行过程解耦出来，这就相当于生产者-消费者模式，提交过程相当于生产者，执行过程相当于消费者，然后以一个异步的执行策略来执行任务（当然这并不是严格要求的），这提交和执行过程中要符合内存一致性效果，就是线程中将Runnable对象提交到Executor执行之前要遵循happen-before原则 ExecutorService在上述的Executor中，只是对于线程的提交，执行的描述，并没有考虑到任务线程的关闭，在线程的整个生命周期中，关闭线程也是非常重要的一部分，如果不能正常的关闭，会导致应用程序一些意想不到的异常，所以ExecutorService的作用是扩展了Executor，完善了任务线程的生命周期的管理，以及跟踪一个或多个异步的任务线程执行状况而生成Future，主要的方法如下： isShutdown() ：判断当前应用程序是否关闭，如果已关闭返回true shutdown()：启动顺序关闭机制，执行此前提交的任务，不再接受新的任务 shutdownNow() ：试图立刻执行关闭所有正在执行的任务，并且返回等待执行的任务列表 submit(Runnable task):submit是对 Executor接口中的execute方法的一个扩展，使用Future对异步任务线程的执行控制 isTerminated() ：判断所有的任务是否都已经完成，完成就返回true invokeAny(Collection&lt;? extends Callable&gt; tasks):执行给定的任务，如果某个任务完成则返回该结果 invokeAll(Collection&lt;? extends Callable&gt; tasks):执行给定的任务，当所有的任务完成之后，返回保持任务状态和结果的Futrue列表 AbstractExecutorServiceAbstractExecutorService是ExecutorService的默认实现，主要是使用RunnableFuture（它是一个Runnable的Futrue，指可以执行Runnable并可以访问其结果）实现submit，invokeAny和invokeAll等方法，而生成RunnableFuture的核心方法就是newTaskFor，他的含义给执行的任务线程生成一个RunnableFuture ScheduledExecutorService和ScheduledThreadPoolExecutorScheduledExecutorService是一种延迟执行的ExecutorService，ScheduledThreadPoolExecutor是其实现类，指安排指定的延迟时间来执行任务，主要方法schedule是指创建并执行在给定延迟时间启用的ScheduledFuture（它是一个scheduled的Future,指一种延迟并可结果化的操作） ForkJoinPoolForkJoinPool是对AbstractExecutorService的扩展，是基于分而治之的思想，将复杂的任务异步的分解成多个小任务去执行，该类也是ForkJoin框架核心的类，这里就不在赘述了 ThreadPoolExecutor任务的状态ThreadPoolExecutor顾名思义线程池，是Executor框架的主要实现方法，他实现了主要的任务线程执行和关闭过程，下面通过源码来分析一下（基于JDK1.8） ThreadPoolExecutor定义了五种任务线程的状态，它记录了线程池中的线程的声明周期： RUNNING：可以接受新的任务，也可以处理阻塞队列里的任务 SHUTDOWN：不接受新的任务，但是可以处理阻塞队列里的任务 STOP：不接受新的任务，不处理阻塞队列里的任务，中断正在处理的任务 TIDYING：过渡状态，也就是说所有的任务都执行完了，当前线程池已经没有有效的线程，这个时候线程池的状态将会TIDYING，并且将要调用terminated方法 TERMINATED：终止状态。terminated方法调用完成以后的状态 状态之间可以进行转换： RUNNING -&gt; SHUTDOWN：手动调用shutdown方法，或者ThreadPoolExecutor要被GC回收的时候调用finalize方法，finalize方法内部也会调用shutdown方法 (RUNNING or SHUTDOWN) -&gt; STOP：调用shutdownNow方法 SHUTDOWN -&gt; TIDYING：当队列和线程池都为空的时候 STOP -&gt; TIDYING：当线程池为空的时候 TIDYING -&gt; TERMINATED：terminated方法调用完成之后 源码定义如下：123456789private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; ThreadPoolExecutor处理某个状态拥有的活跃线程数量是用一个整形常量来表示，用前三位来表示状态，后29位来表示数量，我们先来看COUNT_BITS常量,通过计算可知它的值为29，在java中一个整形占用四个字节，一个字节是八位，所以一个整形占用32位，而COUNT_BITS表示的就是整形中的后29位，它的含义是来存储有效线程的线程数，那状态又怎么表示了，我们来看RUNNING状态：-1&lt;&lt;COUNT_BITS这个左移位运算（丢弃COUNT_BITS数量的最高位，0补最低位），通过-1&lt;&lt;29得到11100000000000000000000000000000，前3位为111，就是表示RUNNING的状态标志，其它四种状态也跟此表示方法一样来标志上述代码中，常量ctl表示的是初始线程池的状态和数量，默认是RUNNING状态和0个活跃任务线程数量，而CAPACITY表示的是线程池的容量，通过（1&lt;&lt;29）-1运算获得，清楚了任务线程的状态和数量的含义，我们来看一下三个重要的对任务线程的状态和数量操作的内部静态方法 123456// 得到状态，CAPACITY的非操作得到的二进制位11100000000000000000000000000000，然后做在一个与操作，相当于直接取前3位的的值private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 得到线程数，也就是后29位的数字。 直接跟CAPACITY做一个与操作即可，CAPACITY就是的值就 1 &lt;&lt; 29 - 1 = 00011111111111111111111111111111。 与操作的话前面3位肯定为0，相当于直接取后29位的值private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 或操作。相当于更新数量和状态两个操作private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 任务的初始化ThreadPoolExecutor提供了初始化的构造方法，如下所示：123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; corePoolSize：线程池中的线程数，如果执行的线程数大于该数量，就进入阻塞队列进行等待 maximumPoolSize：线程池允许最大的线程数 keepAliveTime：执行的线程数大于该线程池中的线程数，多余的空闲线程在回收前等待新任务的时间 unit：时间单位 workQueue：保存执行任务的阻塞队列 threadFactory：创建线程的线程工厂 handler：执行被阻止时使用的处理程序，因为线程已达到线程限制和队列容量 但是JDK并不推荐直接用构造函数来进行线程池的初始化，直接初始化的灵活性和管理上并不好，于是提供了executors线程池工厂类，它应用与各种不同场景下对线程池的初始化需求，主要有如下方法： newFixedThreadPool：创建一个固定数量级的线程池，如果活跃线程数超过线程池数量，它们将在等待队列中知道线程池中的线程可用 newSingleThreadExecutor：创建单个线程的线程池，如果该单线程由于故障等原因停止，想要执行后续的任务，则会创建新的线程去执行 newCachedThreadPool：创建一个可缓存的线程池，根据需要，如果有新的任务进来，线程池没有多余的线程可用，则在线程池中创建新的线程执行，有就复用已创建的线程，如果线程有60秒未被使用则会从缓存中回收 newSingleThreadScheduledExecutor：创建单个线程的线程池，以延迟或定时的方式来执行任务，如果该单线程由于故障等原因停止，想要执行后续的任务，则会创建新的线程去执行 newScheduledThreadPool：创建一个固定的线程池，以延迟或者定时的方式来执行任务 任务的执行ThreadPoolExecutor实现了execute方法，具体代码如下12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 执行execute方法总共有三个步骤，也就是上述代码的三个判断 if (workerCountOf(c) &lt; corePoolSize) ：如果当前的工作线程数量少于线程池的基本数量，则直接创建新的工作线程执行，调用addWorker方法 if (isRunning(c) &amp;&amp; workQueue.offer(command))：如果当前的工作线程数量大于等于线程池的基本数量，且是RUNNING的状态，就加入等待阻塞队列，如果成功的话，再进行第二次验证，如果在阻塞队列中由于另一个线程关闭线程池或者线程出现死亡了，这个时候线程并不在RUNNING状态，就把刚加入的线程remove掉，成功的话就调用reject方法，否则判断工程线程是否为0，是就调用addWorker()加入一个新线程 如果放进阻塞等待队列失败的话，那我们尝试添加一个新的线程执行，如果失败的话，则应该是线程池饱和或者关闭了，调用reject方法 注意：在addWorker方法中，第二boolean参数的true代表以corePoolSize为标准，false以maximumPoolSize为基准 execute方法的核心就是在线程池中如何启动一个线程，也就是addWorker方法，在深入addWorker方法之前先要了解线程在线程池的表现的基本单元载体类Worker，Worker是一个内部类，我们来看看他的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; // 使用ThreadFactory构造Thread，这个构造的Thread内部的Runnable就是本身，也就是Worker。所以得到Worker的thread并start的时候，会执行Worker的run方法，也就是执行ThreadPoolExecutor的runWorker方法 //把状态位设置成-1，这样任何线程都不能得到Worker的锁，除非调用了unlock方法。这个unlock方法会在runWorker方法中一开始就调用，这是为了确保Worker构造出来之后，没有任何线程能够得到它的锁，除非调用了runWorker之后，其他线程才能获得Worker的锁 setState(-1); this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; worker是线程池的执行单元，实现了AQS同步锁和runnable接口，接下来看一下addWorker源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 两个参数，firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用线程池的基本大小，为false使用线程池最大大小// 返回值是boolean类型，true表示新任务被接收了，并且执行了。否则是falseprivate boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 线程池当前状态 // 这个判断转换成 rs &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty)。 // 概括为3个条件： // 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态 // 2. 线程池不在RUNNING状态，线程池接受了新的任务 // 3. 线程池不在RUNNING状态，阻塞队列为空。 满足这3个条件中的任意一个的话，拒绝执行任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 线程池线程个数 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) // 如果线程池线程数量超过线程池最大容量或者线程数量超过了基本大小(core参数为true，core参数为false的话判断超过最大大小) return false; // 超过直接返回false if (compareAndIncrementWorkerCount(c)) // 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环 break retry; c = ctl.get(); // 重新检查状态 if (runStateOf(c) != rs) // 如果状态改变了，重新循环操作 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 走到这一步说明cas操作成功了，线程池线程数量+1 boolean workerStarted = false; // 任务是否成功启动标识 boolean workerAdded = false; // 任务是否添加成功标识 Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; // 得到线程池的可重入锁 w = new Worker(firstTask); // 基于任务firstTask构造worker final Thread t = w.thread; // 使用Worker的属性thread，这个thread是使用ThreadFactory构造出来的 if (t != null) &#123; // ThreadFactory构造出的Thread有可能是null，做个判断 mainLock.lock(); // 锁住，防止并发 try &#123; // 在锁住之后再重新检测一下状态 int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // 如果线程池在RUNNING状态或者线程池在SHUTDOWN状态并且任务是个null if (t.isAlive()) // 判断线程是否还活着，也就是说线程已经启动并且还没死掉 throw new IllegalThreadStateException(); // 如果存在已经启动并且还没死的线程，抛出异常 workers.add(w); // worker添加到线程池的workers属性中，是个HashSet int s = workers.size(); // 得到目前线程池中的线程个数 if (s &gt; largestPoolSize) // 如果线程池中的线程个数超过了线程池中的最大线程数时，更新一下这个最大线程数 largestPoolSize = s; workerAdded = true; // 标识一下任务已经添加成功 &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; if (workerAdded) &#123; // 如果任务添加成功，运行任务，改变一下任务成功启动标识 t.start(); // 启动线程，这里的t是Worker中的thread属性，所以相当于就是调用了Worker的run方法 workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) // 如果任务启动失败，调用addWorkerFailed方法 addWorkerFailed(w); &#125; return workerStarted;&#125; 在上述的代码中，如果任务添加成功，就会执行t.start()方法，也就是执行worker中的run方法，而worker中的run方法调用了runWorker(this)方法，接下来看一下runWorker方法： 1234567891011121314151617181920212223242526272829303132333435363738394041final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 得到当前线程 Runnable task = w.firstTask; // 得到Worker中的任务task，也就是用户传入的task w.firstTask = null; // 将Worker中的任务置空 w.unlock(); // allow interrupts。 boolean completedAbruptly = true; try &#123; // 如果worker中的任务不为空，继续知否，否则使用getTask获得任务。一直死循环，除非得到的任务为空才退出 while (task != null || (task = getTask()) != null) &#123; w.lock(); // 如果拿到了任务，给自己上锁，表示当前Worker已经要开始执行任务了，已经不是闲置Worker(闲置Worker的解释请看下面的线程池关闭) // 在执行任务之前先做一些处理。 1. 如果线程池已经处于STOP状态并且当前线程没有被中断，中断线程 2. 如果线程池还处于RUNNING或SHUTDOWN状态，并且当前线程已经被中断了，重新检查一下线程池状态，如果处于STOP状态并且没有被中断，那么中断线程 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); // 任务执行前需要做什么，ThreadPoolExecutor是个空实现 Throwable thrown = null; try &#123; task.run(); // 真正的开始执行任务，调用的是run方法，而不是start方法。这里run的时候可能会被中断，比如线程池调用了shutdownNow方法 &#125; catch (RuntimeException x) &#123; // 任务执行发生的异常全部抛出，不在runWorker中处理 thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); // 任务执行结束需要做什么，ThreadPoolExecutor是个空实现 &#125; &#125; finally &#123; task = null; w.completedTasks++; // 记录执行任务的个数 w.unlock(); // 执行完任务之后，解锁，Worker变成闲置Worker &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); // 回收Worker方法 &#125;&#125; 在runWorker方法中，如果任务为空，while表达式有个轮询的方式去获取任务，如果task为null的话，会去获取新的任务，接下来看一下获取任务的方法getTask() 123456789101112131415161718192021222324252627282930313233343536373839404142434445private Runnable getTask() &#123; boolean timedOut = false; // 如果使用超时时间并且也没有拿到任务的标识 retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 如果线程池是SHUTDOWN状态并且阻塞队列为空的话，worker数量减一，直接返回null(SHUTDOWN状态还会处理阻塞队列任务，但是阻塞队列为空的话就结束了)，如果线程池是STOP状态的话，worker数量建议，直接返回null(STOP状态不处理阻塞队列任务)[方法一开始注释的2，3两点，返回null，开始Worker回收] if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; boolean timed; // 标记从队列中取任务时是否设置超时时间，如果为true说明这个worker可能需要回收，为false的话这个worker会一直存在，并且阻塞当前线程等待阻塞队列中有数据 for (;;) &#123; int wc = workerCountOf(c); // 得到当前线程池Worker个数 // allowCoreThreadTimeOut属性默认为false，表示线程池中的核心线程在闲置状态下还保留在池中；如果是true表示核心线程使用keepAliveTime这个参数来作为超时时间 // 如果worker数量比基本大小要大的话，timed就为true，需要进行回收worker timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if (wc &lt;= maximumPoolSize &amp;&amp; ! (timedOut &amp;&amp; timed)) // 方法一开始注释的1，4两点，会进行下一步worker数量减一 break; if (compareAndDecrementWorkerCount(c)) // worker数量减一，返回null，之后会进行Worker回收工作 return null; c = ctl.get(); // 重新检查线程池状态 if (runStateOf(c) != rs) // 线程池状态改变的话重新开始外部循环，否则继续内部循环 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; try &#123; // 如果需要设置超时时间，使用poll方法，否则使用take方法一直阻塞等待阻塞队列新进数据 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; // 闲置Worker被中断 &#125; &#125;&#125; 任务线程会从阻塞队列中获取，如果发生如下情况，那么worker需要被回收： Worker个数比线程池最大大小要大 线程池处于STOP状态 线程池处于SHUTDOWN状态并且阻塞队列为空 使用超时时间从阻塞队列里拿数据，并且超时之后没有拿到数据(allowCoreThreadTimeOut || workerCount &gt; corePoolSize) 回收会在runWorker方法中发生如上事件抛出异常，在finally块中调用processWorkerExit方法进行回收 1234567891011121314151617181920212223242526272829303132private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // 如果Worker没有正常结束流程调用processWorkerExit方法，worker数量减一。如果是正常结束的话，在getTask方法里worker数量已经减一了 decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发问题 try &#123; completedTaskCount += w.completedTasks; // 记录总的完成任务数 workers.remove(w); // 线程池的worker集合删除掉需要回收的Worker &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池 int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; // 如果线程池还处于RUNNING或者SHUTDOWN状态 if (!completedAbruptly) &#123; // Worker是正常结束流程的话 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // 不需要新开一个Worker &#125; // 新开一个Worker代替原先的Worker // 新开一个Worker需要满足以下3个条件中的任意一个： // 1. 用户执行的任务发生了异常 // 2. Worker数量比线程池基本大小要小 // 3. 阻塞队列不空但是没有任何Worker在工作 addWorker(null, false); &#125;&#125; 在回收Worker的时候线程池会尝试结束自己的运行，tryTerminate方法： 123456789101112131415161718192021222324252627282930313233343536final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 满足3个条件中的任意一个，不终止线程池 // 1. 线程池还在运行，不能终止 // 2. 线程池处于TIDYING或TERMINATED状态，说明已经在关闭了，不允许继续处理 // 3. 线程池处于SHUTDOWN状态并且阻塞队列不为空，这时候还需要处理阻塞队列的任务，不能终止线程池 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 走到这一步说明线程池已经不在运行，阻塞队列已经没有任务，但是还要回收正在工作的Worker if (workerCountOf(c) != 0) &#123; // 由于线程池不运行了，调用了线程池的关闭方法，在解释线程池的关闭原理的时候会说道这个方法 interruptIdleWorkers(ONLY_ONE); // 中断闲置Worker，直到回收全部的Worker。这里没有那么暴力，只中断一个，中断之后退出方法，中断了Worker之后，Worker会回收，然后还是会调用tryTerminate方法，如果还有闲置线程，那么继续中断 return; &#125; // 走到这里说明worker已经全部回收了，并且线程池已经不在运行，阻塞队列已经没有任务。可以准备结束线程池了 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发 try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; // cas操作，将线程池状态改成TIDYING try &#123; terminated(); // 调用terminated方法 &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); // terminated方法调用完毕之后，状态变为TERMINATED termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; // else retry on failed CAS &#125;&#125; ThreadPoolExecutor的关闭线程池的关闭有两个重要的方法：shutdown和shutdownNow，下面看一下shutdown方法的源码：12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 关闭的时候需要加锁，防止并发 try &#123; checkShutdownAccess(); // 检查关闭线程池的权限 advanceRunState(SHUTDOWN); // 把线程池状态更新到SHUTDOWN interruptIdleWorkers(); // 中断闲置的Worker onShutdown(); // 钩子方法，默认不处理。ScheduledThreadPoolExecutor会做一些处理 &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池，上面已经分析过了&#125; 再看看中断线程的interruptIdleWorkers方法方法： 1234567891011121314151617181920212223242526// 调用他的一个重载方法，传入了参数false，表示要中断所有的正在运行的闲置Worker，如果为true表示只打断一个闲置Workerprivate void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 中断闲置Worker需要加锁，防止并发 try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 拿到worker中的线程 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; // Worker中的线程没有被打断并且Worker可以获取锁，这里Worker能获取锁说明Worker是个闲置Worker，在阻塞队列里拿数据一直被阻塞，没有数据进来。如果没有获取到Worker锁，说明Worker还在执行任务，不进行中断(shutdown方法不会中断正在执行的任务) try &#123; t.interrupt(); // 中断Worker线程 &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); // 释放Worker锁 &#125; &#125; if (onlyOne) // 如果只打断1个Worker的话，直接break退出，否则，遍历所有的Worker break; &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125;&#125; 轮询所有的worker,判断是不是中断的线程且可以拿到锁（判断闲置的worker）,就中断该线程,现在来看一看另一个关闭的shutdownNow方法12345678910111213141516// shutdownNow方法会有返回值的，返回的是一个任务列表，而shutdown方法没有返回值public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // shutdownNow操作也需要加锁，防止并发 try &#123; checkShutdownAccess(); // 检查关闭线程池的权限 advanceRunState(STOP); // 把线程池状态更新到STOP interruptWorkers(); // 中断Worker的运行 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池，上面已经分析过了 return tasks;&#125; shutdownNow方法的语义是立刻关闭所有的worker,而不是shutdown方法关闭闲置的方法,而且shutdownNow直接将状态改为STOP，这样的话，不会执行新的任务，同时回收所有的worker，而shutdown只是将状态变为SHUTDOWN,接下来看一看shutdownNow的中断worker方法interruptWorkers():12345678910private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 中断Worker需要加锁，防止并发 try &#123; for (Worker w : workers) w.interruptIfStarted(); // 中断Worker的执行 &#125; finally &#123; mainLock.unlock(); // 解锁 &#125;&#125; Worker的interruptIfStarted方法中断Worker的执行： 12345678910void interruptIfStarted() &#123; Thread t; // Worker无论是否被持有锁，只要还没被中断，那就中断Worker if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); // 强行中断Worker的执行 &#125; catch (SecurityException ignore) &#123; &#125; &#125;&#125; 总结在不同的应用场景下，线程池的生态也越来越大，它的意义是让用户更加高效的应用线程去执行不同的任务，为线程提供完整的生命周期，虽然线程池提供了很好的线程复用机制，但是并不是就可以滥用线程池来创建去执行任务，在操作系统或者JVM平台下都有对于线程一定的限制，合理的使用才能更加的高效！！！ 参考http://www.jianshu.com/p/758a99c83ef1http://fangjian0423.github.io/2016/03/22/java-threadpool-analysis/《java并发编程实战》第六章]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发关键字-synchronized]]></title>
      <url>%2F2017%2F05%2F24%2Fsynchronized%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言synchronized（同步）是java中在多处理器中实现线程安全最基本的手段，在java语言规范（第三版）中提到锁的同步机制，指在java中，线程之间通信的机制最基本的就是同步化，此方法是使用监视器（monitor，后面会讲到）实现的，每个对象与一个监视器关联，一个线程可以加锁和解锁此监视器，而且同一时间段只有一个线程持有监视器上的锁，其他线程就会被阻塞，直到他们可以在该监视器上获取锁 其实一个对象都可以看做一个锁，在java中，有三种对于synchronized的用法 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 当一个线程访问synchronized修饰的代码块时，他必须要获取一个锁，根据不同的修饰方式来获取所对应的对象的锁，退出或者是发生异常时释放锁，下面将一步一步深入锁的实现 锁的实现原理我们先将通过一个简单的同步代码开始12345678public class SynchronizedTest &#123; public static Object object = new Object(); public static void main(String[] args)&#123; synchronized(object) &#123; // synchronized test &#125; &#125;&#125; 上述代码main函数中获取了object的锁，我们用javap命令工具反编译该生成的class文件，信息如下1234567891011121314151617181920212223242526272829303132333435363738394041Compiled from &quot;SynchronizedTest.java&quot;public class SynchronizedTest &#123; public static java.lang.Object object; public SynchronizedTest(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return public static void main(java.lang.String[]); Code: 0: getstatic #3 // Field object:Ljava/lang/Object; 3: dup 4: astore_1 5: monitorenter 6: aload_1 7: monitorexit 8: goto 16 11: astore_2 12: aload_1 13: monitorexit 14: aload_2 15: athrow 16: return Exception table: from to target type 6 8 11 any 11 14 11 any static &#123;&#125;; Code: 0: new #4 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: putstatic #3 // Field object:Ljava/lang/Object; 10: return&#125; 由上述反编译class文件的执行代码可知，在main函数中执行synchronized代码块使用了monitorenter和monitorexit两个字节码指令，JVM通过monitorenter字节码指令来获取对象的锁，通过monitorexit字节码指令来释放该对象的锁，当执行monitorenter字节码指令时，首先会尝试获取对象的锁，如果该对象没有没有被锁定或者当前线程已经拥有了该锁，则锁的计数器加1，相应的执行monitorexit字节码指令释放锁的时候会减1，当计数器为0表示对象没有锁定，如果一个线程获取锁失败时，那当前线程就必须被阻塞等待，直到对象锁被另一对象释放，下面我们通过介绍对象头和monitor以及JVM对锁的优化措施进一步了解如何获取对象的锁和释放对象的锁。 对象头在HotSpot虚拟机中，对象的内存布局分为三部分：对象头，实例数据和对齐填充，其中对象头是对象的内存布局中很重要的部分，他分为两个部分的信息，第一个部分存储的是对象本身运行时的数据，比如哈希码，GC分代年龄等，空间大小根据32位和64位的虚拟机分别为32bit和64bit，这还有另一个官方称号叫做“Mark Word“，他是实现轻量级锁和偏向锁的关键，这个后面会讲到，另一个部分用于存储指向方法区对象类型数据的指针，如果存储的是对象数组的话，还有一部分空间存储该数组的长度，默认的存储结构如下所示（32位虚拟机为例）： 考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构，以便在极小的空间内存储更多的信息，他会根据不同的状态复用自己的存储空间，如下所示 注意：其中偏向锁和轻量级锁这两个锁状态是JDK1.6之后引入的对锁的优化，之后会介绍 monitormonitor是线程私有的数据结构，每一个线程都有一个可用的monitor record列表，同时还有一个全局的可用列表，每一个锁住的对象都会和一个monitor关联，下面是monitor的结构组成： Owner：初始时为NULL表示当前没有任何线程拥有该monitor，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL； EntryQ：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor失败的线程。 RcThis：表示blocked或waiting在该monitor上的所有线程的个数。 Nest：用来实现重入锁的计数。 HashCode：保存从对象头拷贝过来的HashCode值（可能还包含GC age）。 Candidate：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值：0表示没有需要唤醒的线程，1表示要唤醒一个继任线程来竞争锁。 当一个线程进入同步代码块时，该代码块的同步对象通过Mark Work中的LockWord指向monitor的起始地址来关联monitor，由monitor来获取锁和释放锁 由于在java中，synchronized是一个重量级的锁，在多处理器并发中，效率总是不尽人意，JVM团队认为还有很大的改进空间，所以进行了锁的一系列的优化，下面将介绍锁的优化措施 偏向锁偏向锁是JDK1.6引入的一项锁优化，他的目的是消除在无竞争的情况下的同步原语，进一步提高程序的运行性能，说白了就是将同步的操作都消除掉，下面介绍如何获取锁和释放锁 获取锁当一个线程访问同步代码块时，会执行monitorenter字节码指令，对象会在Mark Word利用CAS操作记录关联的线程ID标识，操作成功就将标志位置为“01”，即偏向锁状态，再标记是否是偏向锁置为“1”,这样以后该线程,再次进入或者退出同步块时不需要其他的同步操作 释放锁如果有另一个线程尝试获取这个锁，偏向锁就会失效，这时会等待全局安全点（在这个时间点上没有字节码正在执行）撤销偏向锁状态到无锁状态（标志位“01”）或者膨胀到轻量级锁状态（标志位“00”），把是否是偏向锁置为0，它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 轻量级锁轻量级锁也是JDK1.6之中加入的新型锁机制，他的作用是在没有多线程的竞争下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗 获取锁当线程进入代码块时，该同步块的对象没有被锁定，当前线程会在自己的栈内创建一片空间来存储锁记录，然后再将Mark Word复制到锁记录中（官方在复制时会加一个Displaced前缀，就是Displaced Mark Word），然后尝试用CAS操作将Mark Word指向该线程的栈帧中的锁记录地址，如果成功了就会拥有该对象的锁，锁的标志位就变成了“00”，此时属于轻量级锁的状态，如果更新失败的话，说明当前对象存在竞争，那轻量级锁就会失效，膨胀成重量级锁，锁的标志位就变成了“10”，Mark Word指向的就是重量级锁的指针，后面的线程就会进程阻塞 释放锁轻量级锁释放锁是通过CAS操作将当前的Mark Word和当前线程的栈帧中的锁记录替换回去，如果成功的话，表示访问完整个同步块了，如果失败的话，表示有竞争出现，那就要马上放弃该锁，唤醒被挂起的线程在多核处理器的并发情况下，锁的状态会因为竞争的关系而变化，然而对于锁的状态会随着膨胀升级，从最开始的无锁，到偏向锁，再到轻量级锁，最后是重量级锁，锁只能是升级，不能降级，下面是三种锁状态的优缺点比较 JVM的团队在锁的优化下了很大的功夫，其实还有包括自旋锁和自适应自旋锁：以消耗CPU的代价换取加锁解锁的消耗，锁消除：最小的粒度消除加锁解锁的消耗，锁粗化：用一次加锁解锁的消耗来替代多次的加锁解锁的消耗，Synchronized的性能也越来越好，在合理的情况下使用不会比concurrent包下的lock机制性能差。 参考http://ifeve.com/java-synchronized/ 周志明《深入理解java虚拟机》第十三章 http://developer.51cto.com/art/201702/532564.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入并发关键字-volatile]]></title>
      <url>%2F2017%2F05%2F22%2Fvolatile%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 前言关键字volatile可以说是JVM提供的最轻量的同步机制了，也被称为轻量级的 synchronized，他在多处理器并发编程中提供了两个重要的特性： 保证共享变量的可见性，指一个线程修改了一个共享变量的值，其他线程能够读取到最新的修改值 禁止重排序，指禁止代码在执行过程中为优化性能而编译的执行顺序 如果在合适的情况下使用volatile关键字，程序会更加的高效，因为他对于synchronized来讲不会使线程上下文的调度和切换 volatile的实现原理volatile是如果实现可见性和禁止指令重排序的？先通过一段双重检查单例模式（double checked singleton）代码开始1234567891011121314public class DoubleCheckedSingleton &#123; private volatile static DoubleCheckedSingleton instance; private DoubleCheckedSingleton ()&#123;&#125; public static DoubleCheckedSingleton getInstance() &#123; if (instance == null) &#123;//single checked synchronized (DoubleCheckedSingleton.class) &#123; if (instance == null) &#123;//double checked instance = new DoubleCheckedSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 在上述代码中，由volatile修饰的赋值代码片段instance = new DoubleCheckedSingleton()；在x86处理器下通过工具获取JIT编译器生成的汇编代码指令如下所示：120x01a3de1d: movb $0x0,0x1104800(%esi);0x01a3de24: lock addl $0x0,(%esp); 相对于普通变量的赋值操作来讲，volatile修饰的共享变量的在赋值后多执行了lock addl $0x0,(%esp)指令操作，其中lock指令前缀在多核处理器中会做两件事： 将当前CPU缓存行的数据写回到主内存； 这个写回内存的操作会导致在其它CPU里缓存了该内存地址的数据无效。 处理器为了更加高效的运行，他不会直接与主内存进行通信，而是在先读取到其处理器内部缓存进行一系列的操作，但是不是立刻会回写到主内存中，对于volatile修饰的共享变量进行写操作，JVM会向该处理器发送一条Lock前缀的指令，锁住该缓存（早期的处理器是通过锁住整个总线，效率较低），并使用缓存一致性来确保修改的原子性，该操作称为“缓存锁定”，然后引起该处理器将内部缓存回写到主内存中，在确保缓存一致性的情况下，处理器通过嗅探技术访问主内存和内部缓存，确保处理器内部缓存和主内存上的状态保持一致，如果一个处理器在内部缓存对一个共享地址进行写操作时，该处理器会无效其对应的缓存，再下次访问该内存地址时，进行读取主内存到该处理器内部缓存。 lock前缀指令也相当于一个内存屏障（Memory Barrier），如上所述，由于缓存锁定操作，这样让该指令执行完，下一个指令才能执行，这个就实现了禁止了指令重排序，回写主内存同时使其他cpu该内存地址无效化，这样也就实现了可见性。 volatile关键字的使用如何使用volatile关键字，这里要了解确保并发安全的三个要素：原子性，可见性，顺序性，其中原子性指该操作不可分割，不受其他线程干扰，顺序性就是禁止指令重排序，对于关键字volatile来讲，volatile关键字保证了可见性和顺序性，同时它也是一个轻量级的synchronized,它在多处理器上的安全性体现在更加细微的操作，上述也提到，由于缓存一致性会保证单个读写操作的原子性，这样就符合并发安全的三要素了，然而在大多数程序中，大多数都是对一些共享变量的复合操作，比如i++操作，这就涉及到从主内存读取i到缓存中，在缓存中进行i+1的操作和将i写入主内存三个操作，这个就无法保证i++操作的原子性了，对于类似的复合操作来讲，如果共享变量具有原子性或者在一些原子操作的场合下，比如共享变量被concurrent包下的一些原子类修饰或者做一些CAS的一些操作，使用volatile是一个好的选择。 参考http://ifeve.com/volatile/ 周志明《深入理解java虚拟机》第十二章]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[NIO学习笔记]]></title>
      <url>%2F2017%2F03%2F17%2Fnio_note%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Channel和Buffer概述与实现所有的IO在NIO中都是从channel开始，channel像是流，buffer像是缓冲区，流可以读到缓冲区中，缓冲区可以写到流中，如下图所示 channel主要实现：FileChannel（文件流），DatagramChannel（数据报流-UDP），SocketChannel（socket流-TCP），ServerSocketChannel（服务端socket流-TCP） Buffer主要实现（主要是七个IO的基本类型）：ByteBuffer，CharBuffer，DoubleBuffer，FloatBuffer，IntBuffer，LongBuffer，ShortBuffer 简单的FileChannel读取数据到bufferbuffer内存模型的三个标记位：1.capacity(容量):buffer初始化时分配的容量2.position(位置):buffer内读取或写入的位置(读取或写入时position从0开始，如果在get(position)方法中有赋值，则从该位置开始)3.limit(最大容量):读取或写入的最大位置(读取时，置为position的位置，写入时，置为catacity的位置) 总结：不管是读取还是写入，都是从position标志的位置开始，到limit的位置结束 将channel读入buffer的示例如下：12345678910111213141516171819202122232425262728293031public void simpleChannelToBuffer(String fromPath)&#123; ByteBuffer buffer=null; RandomAccessFile file=null; FileChannel fileChannel=null; try &#123; file = new RandomAccessFile(fromPath,"rw"); fileChannel = file.getChannel();//建立到目的文件的通道 buffer = ByteBuffer.allocate(48);//分配48bytes的缓存区 int bytesRead =0 ; while((bytesRead=fileChannel.read(buffer))!=-1)&#123;//将通道内的文件数据读取到缓存区中 System.out.print(bytesRead); buffer.flip();//切换读模式，position置为0，limit置为写入时的position的位置 while(buffer.hasRemaining())&#123;//缓存区中是否有数据 System.out.print((char)buffer.get()); &#125; buffer.clear();//清空所有的数据，切换成写模式 //buffer.compact();//清空已经读取的数据，切换成写模式 &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; fileChannel.close(); file.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Scatter（分散）与Gather（聚集）Scatter（分散）：从channel读取数据写入多个buffer中 代码如下：1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray); //依次写入到buffer中 Gather（聚集）：将多个buffer的数据写入同一个channel中 代码如下1234ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.write(bufferArray); //依次写入到channel中 通道之间的数据传输12345678RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0; //读取的位置long count = fromChannel.size(); //读取的大小toChannel.transferFrom(position, count, fromChannel); //数据从fromChannel到toChannel//另一种写法：fromChannel.transferTo(position, count, toChannel); 注意：在SocketChannel中，传输的只会是准备好的数据，可能不足count大小，但是一有数据就会传输，只到buffer被填满 Selector如果你想单线程异步处理多个流，或者是你的应用打开了多个链接（通道），但是每个链接的的流量又很低，这就是Selector的工作 Selector首先要注册Channel，调用select()方法，一直阻塞到有某个注册的通道（Channel）有事件（数据或者新接连）就绪，等到这个方法返回，线程就开始处理这个通道中的事件 注意：与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以 selector可以监听channel以下四种不同类型的事件： OP_CONNECT(连接就绪) ：比如：socketChannel OP_ACCEPT(接收就绪)：比如：ServerSocketChannel OP_READ(读就绪) OP_WRITE(写就绪) 代码如下：123456789101112131415161718192021222324Selector selector = Selector.open();//创建一个selectorchannel.configureBlocking(false);//设置非阻塞模式//selector注册channel，事件可以多选，比如SelectionKey.OP_READ | SelectionKey.OP_WRITESelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); //返回读就绪的channel if(readyChannels == 0) continue; //如果还没有就继续监听 Set selectedKeys = selector.selectedKeys();//获取已就绪的channel的集合 Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next();//如下是判断哪种事件的channel的处理 if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();//该事件处理完就移除 &#125;&#125; pipeJava NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取 首先创建Pipe：Pipe pipe = Pipe.open();ThreadA向管道写数据，访问sink通道，代码如下：123456789Pipe.SinkChannel sinkChannel = pipe.sink();String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125; ThreadB向管道读取数据，访问source通道，代码如下：123Pipe.SourceChannel sourceChannel = pipe.source();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf); NIO和IONIO与IO的差异如下: IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 面向流和面向缓冲IO是面向流的，是一个不可控制处理方式，必须从头到尾直到读取所有的字节，没有缓冲的余地，而NIO是面向缓冲区的，它先将流中的数据读取到缓冲区中，然后再对数据进行处理，这样增加了数据处理的灵活性 阻塞和非阻塞IO是阻塞IO，当一个线程在读取数据的时候是阻塞的，再次期间不能做其他的任何事情，直到读写数据结束NIO是非阻塞IO，当一个线程在读取数据时，在该数据变成可读性之前，也就是空闲时间，可以做其他事情 选择器Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道 参考http://ifeve.com/java-nio-all/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM加载机制]]></title>
      <url>%2F2017%2F03%2F06%2Fjvm_classLoad%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 类加载过程类加载是指类通过JVM加载到内存开始到从内存中卸载出去的过程，其生命周期包括七个阶段：加载（Loading），验证（Verification），准备（Preparation），解析（Resolution），初始化（Initialization），使用（Using），卸载（Unloading），其中验证，准备和解析统称为链接过程，如下图所示： 类加载器类加载器作用于类的加载过程，每一个加载器都拥有独立的类名称空间，而JVM中，有两种类型的类加载器，一种是由C++语言实现的启动类加载器（Bootstrap ClassLoader），另一种是由java语言实现的，独立于虚拟机外部，并且全部继承抽象类java.lang.ClassLoader的类加载器 双亲委派模型在大部分开发程序中，一般都会使用三种系统提供的类加载器 启动类加载器（Bootstrap ClassLoader）：由C++语言编写，负责加载核心java库（存储在/jre/lib） 扩展类加载器（Extension ClassLoader）:由sun.misc.Launcher$ExtClassLoader实现，负责加载java扩展库（存储在） 应用程序类加载器（Application ClassLoader）：由sun.misc.Launcher$AppClassLoader实现，负责加载应用程序的java库（存储在java.class.path或CLASSPATH下的类库） 除了以上三个由系统实现的类加载器，还可以自己实现自定义的类加载器，而这些类的关系如下图所示： 如上类加载器的层次关系图，展示类加载器与类加载器之间的层次关系，这被称为双亲委派模型，每一层上面相当于是自己的父类加载器，以组合的模式来复用父类加载器的功能双亲委派模型的工作过程是：当一个加载器收到加载请求时，他首先会该请求委派给父类加载器去完成，最终传递到顶层的启动类加载器加载，只有当父类加载器加载不了，才会让子加载器自己去尝试加载，这样的话，可以防止代码的重复，比如A类的加载器要加载System，B类加载器也要加载System，双亲委派机制可能在系统实现的三个类加载器就可以加载了。 参考https://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM垃圾收集]]></title>
      <url>%2F2017%2F02%2F14%2Fjvm_gc%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 JVM垃圾收集技术需要关注三个步骤：1.哪些对象需要被回收，2.什么时候进行回收，3.如何进行回收 哪些对象需要被回收引用计数算法引用技术算法大致的过程是给对象分配一个引用计数器，当该对象被引用时，引用计数器就加一，该引用失效时，计数器就减一，当计数器为零时，说明该对象没有任何引用，就判定该对象可以被回收，虽然它的实现简单即高效，不过现代主流的JVM收集器都没有使用该算法，它有一个致命的缺陷是无法解决对象之间相互循环引用的问题 可达性分析算法可达性分析算法大致的过程是通过一系列的成为GC Roots的对象作为起点，他会向下进行搜索，所走过的路径成为引用链，如果一个对象到GC Roots没有任何的引用链（指该对象在程序中没有任何关系了），则说明该对象是可以被回收的在java语言中，可以作为GC Roots的对象包括如下： 虚拟机栈中的栈帧内的本地变量表中引用的对象 方法区中类静态属性引用和常量引用的对象 本地方法栈中引用的对象 什么时候进行回收在现代的内存分配中，堆被分为年轻代（8：1比例分配的1个Eden区和2个Survivor（FromSurvivor 和 ToSurvivor））和老年代，那什么时候会对年轻代和老年代的对象进行回收呢？ 首先，创建一个对象，JVM会给该对象分配一个对象年龄计数器，该对象大部分情况下会被优先分配到年轻代中的Eden区中（对于大对象，直接分配到老年代中），当Eden区中没有被分配的空间时，这时候JVM会触发一次Minor GC（年轻代GC），该对象的年龄置为1，存活下来的对象会往ToSurvivor区中移动，FromSurvivor区中存活的对象也复制到ToSurvivor区中，这时，ToSurvivor区和FromSurvivor区身份调换，当该对象的年龄增加到一定程度（默认是15）时，该对象会被晋升到老年代中，当然如果FromSurvivor中的相同年龄段的对象超过了一般，则大于该年龄段的对象直接晋升到老年代，在老年代中如果最大可用的连续空间小于晋升到老年代的对象大小，会进行一次Full GC 如何进行回收垃圾收集算法标记-清除算法（Mark-Sweep）标记-清除算法的回收过程分为两个阶段：标记和清除，标记就是标记哪些对象可以被回收（上面已经介绍过了），清除就是回收哪些被标记的可回收对象，这两个阶段的效率都不是很高，而且会产生大量的空间碎片，过程如下图 复制算法（Copying）复制算法的回收过程是将内存分成两块等量大小的内存块，一块是存储对象数据，另一块是保留区域（不存储任何数据），当存储对象数据的内存块用完了，就将还存活的对象复制到保留区域，然后将已使用过的内存块清理掉，原来存储对象数据的内存块变成了保留区，原来的保留区变成了存储对象数据的内存块，复制过程只需要移动堆顶的指针可以，简单高效，而且没有内存碎片化的存在，但是却将原有的内存缩小了一般，这也适合现代新生代的回收机制，因为新生代大部分都是朝生夕死，当然他们的内存划分比例不需要到达1：1，典型的就是8：1的eden区和survivor区，具体过程如下图： 标记-整理算法标记-整理算法的回收过程分为标记和整理两个阶段，它是标记-清除算法的改进版本，标记和标记-清除算法一致，不同的是，他不是直接对可回收的对象进行清除，而是将存活下来的对象往一端移动，再清理掉存活边界外的内存，它解决了标记-清除算法的内存碎片化问题，但是效率不是很高，具体过程如下图： 分代收集算法分代收集算法是指按照对象的存活周期，在堆中分为新生代和老年代，根据不同年代的特点使用不同收集算法的组合，比如新生代的特点是朝生夕死，对象存活周期短，使用复制算法，只需要少量的存活对象的复制成本即可，而老年代存活周期长，使用标记-清除或者标记-整理算法，因为它们的内存不大，没有额外的空间进行担保，这样就会形成一个组合来进行垃圾收集 垃圾收集器JVM的发展中，发布了很多的收集器，从最开始的单线程版的收集器serial(针对新生代)/serial old（针对老年代）收集器（JDK1.3以前）到多线程的并行收集器parallel scavenge（针对新生代）/parallel old(针对老年代)收集器，一直到现在针对多核，多CPU的环境下，充分的利用其硬件资源和重视快速响应的CMS收集器（JDK1.5以后）和G1收集器（JDK1.7以后） CMS收集器cms（Concurrent Mark Sweep）收集器是一款针对于最短回收时间停顿的老年代收集器，从名称上就可以知道该收集是基于标记-清除算法，它是把最耗时间的标记（GC Root Tracing）和清除过程使用了并发机制，和用户线程共同运行，大大的减少了停顿时间，具体过程如下：该收集器可以分为五个步骤： 初始标记：标记GC Roots所能关联的对象 并发标记：根据第一步的对象并发的遍历其他的对象（GC Roots Tracing） 重新标记：由于第二步的运行时间较长，对象可能会产生变化，开启多个线程重新标记已标记的对象 并发清理：并发的从需要被收集的对象集合中清除这些对象 并发重置：重置CMS收集器的数据，为下一次收集做准备 上述的五大步骤就是CMS收集的过程，整的来说已经实现了并发收集，低停顿，响应快等优点，但是还有三个明显的缺点： 由于CMS收集器是并发收集，它会占用其他线程的CPU资源，导致吞吐量低，部分线程变慢 CMS收集器无法处理在重新标记这个时间段里的垃圾，因为在重新标记期间，程序会产生新的对象或者变动，这是CMS收集器会预先预留一部分内存来处理，所以在一定的比例下（默认老年代空间使用率到达68%），就会触发CMS收集 CMS收集器采用的是标记-清除算法，所以会产生大量的内存碎片 G1收集器G1收集器（Garbage-First）是一款服务器型的垃圾收集器，它是由一个个大小相等的Regoin（内存区域）组成，通过一系列的标记阶段之后，之后优先收集那些垃圾最多的区域，它也保存了以往的分代收集的概念，但是新生代和老年代不需要设定固定的大小来控制，这样在内存的使用上提供了很大的灵活性，传统的堆分区如下：上述的是传统的把堆分成年轻代（1个eden区和2个survivor区），老年代，和永久代，在G1收集器中也保持了分代的理念，如下图: 如上图所述，他是用一个个内存区域的概念来存储分代对象，和CMS收集器不同的是它是用标记-整体算法来进行收集过程，整体的解决了内存碎片的问题 参考http://zhaoyanblog.com/archives/397.htmlhttps://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM运行时数据区域]]></title>
      <url>%2F2017%2F02%2F10%2Fjvm_list_range%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Java虚拟机（英语：Java Virtual Machine，缩写为JVM），一种能够运行Java bytecode的虚拟机，以堆栈结构机器来进行实做。最早由太阳微系统所研发并实现第一个实现版本，是Java平台的一部分，能够运行以Java语言写作的软件程序(来自wiki) 运行时数据区域JVM运行时数据区域由java栈，PC寄存器，本地方法栈，堆和方法区等五大数据区域组成，其结构图如下： 线程私有java栈java栈是线程私有的，它的生命周期会随着线程的创建而开始，摧毁而结束，它描述着java执行方法的内存模型：每个线程在执行方法时，会创建一个栈帧，该栈帧存储着方法的所有信息（局部变量表，操作数栈，栈数据区和方法出口等信息），一个方法的调用就好像是JVM对栈帧进行进栈到出栈的过程，由于其生命周期和线程一样，所以不需要GC PC寄存器PC寄存器也是线程私有的，是一块很小的内存，它是存储JVM当前方法执行的指令地址，就像是执行字节码的指示器，控制着当前程序的执行方向，JVM执行方法时就需要获取该计数器的指令来进行下一步的操作 本地方法栈本地方法栈与java栈类似，不同的是java栈执行的是java方法服务（字节码），而本地方法栈执行的JVM自己定义的本地方法服务，也就native修饰的方法 线程共享堆堆是线程共享的，所以它的声明周期由虚拟机创建时开始，主要存放的是对象的实例和数组，是JVM内存分配最大的，由于其生命周期较长，所以被垃圾回收收集器管理，由于现代的垃圾收集器都采用分代收集算法，所以还能以8比1的比例细分成一个Eden区和两个Survivor区（FromSurvivor和ToSurvivor） 方法区方法区也是线程共享的，它用于存储类的信息，常量，静态变量等信息（类的元数据在JAVA1.8已经移动到一块本地内存空间，也就是元空间），还有运行时常量池是方法区很重要的部分，存放编译器编译期间各种class中的常量值和类的描述信息。 对象在内存区域是如何运行对象在内存中是如果创建我们在代码中直接用new来表示创建一个对象，而在虚拟机中，会碰到一个new指令，首先会检查指令的参数在常量池中是否有这个类的符号引用，再检查此类是否已经被加载，解析和初始化过了，如果没有就会执行相应的加载过程，然后就会在堆中为对象分配内存，分配内存有两种方式： 指针碰撞：如果GC使用的是复制算法，把堆内存一分为二，一边是已分配内存，一边是空闲内存，没有内存碎片，那么只需从中间开始，指针往空闲内存空间移动相应大小的距离即可 空闲列表：如果GC是没有使用标记-整体的算法，存在内存碎片，这时候会维护一种记录可用内存的表，再从表中寻找一块足够大小的内存空间分配给对象实例。 由于堆是线程共享的，在分配内存时存在着线程安全，比如T1线程准备在表中选取A内存分配，还没有开始分配，这时T2线程也准备在表中选取A内存分配，这就会造成冲突，解决线程安全问题有下面两个方案： CAS同步，在分配操作上使用CAS操作保证分配内存的原子性 每个线程在堆上预先分配自己的一小块内存（本地线程分配缓冲 TLAB），只需要在该内存用完了，再同步分配新的TLAB 对象在内存中的结构组成对象存储在内存中分为三个部分：对象头，实例数据，对齐填充 对象头对象头包括两个部分，第一部分是存储对象自身的运行时数据（哈希码，GC分代年龄，锁标志等），也叫Mark Word，第二部分是类型指针，也叫元数据指针，来确定该对象是哪个类的实例 实例数据实例数据存储的是该对象内部所定义的类型的字段信息，包括从父类继承下来的，还是在子类定义的 对齐填充这是一个占位符，JVM规定对象的大小为8字节的整数倍，如果不是就用对齐填充来补全 对象在内存中如何被访问在内存中访问对象有两种方式：句柄池和直接引用 句柄池句柄池访问是指在栈中的reference引用指向的是句柄池上的地址，再由句柄池指向相应的对象信息，句柄池的内容包括对象实例数据的指针和对象类型数据的指针，在java堆划分一小块内存来存储它，具体访问过程如下图： 直接引用直接引用访问是指栈中的reference引用直接指向堆中对象实例的地址，访问过程如下图：以上两种访问方式各有优劣，句柄池在对象实例频繁的更替时，不需要改动reference中的指针，只需改变句柄池的指针即可，但是直接引用的访问速度比句柄池更快，省去了句柄池的指针指向对象实例的消耗，总结出来就是，对象更替频繁的使用句柄池，对象访问频繁的使用直接引用 参考https://book.douban.com/subject/24722612/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis持久化策略]]></title>
      <url>%2F2017%2F01%2F17%2Fredis_data_persistence%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Redis提供了两种不同级别的持久化策略，RDB（redis database）持久化和AOF(append only file)持久化，它们应用在不同的场景中，各有千秋，以下是两种策略的实现方案 RDB（redis database）持久化RDB（redis database）持久化是将内存中的数据生成一个特定格式的二进制的rdb文件，保存在磁盘中，在redis服务进程开启时通过读取磁盘中的rdb文件，数据又会还原到内存中。rdb文件结构如下： 写入指令写入（1）SAVE：SAVE命令是在当前服务进程进行持久化操作，会阻塞其他的操作命令，直到RDB文件创建完毕（2）BGSAVE：BGSAVE命令是创建一个子服务进程来专门处理持久化操作，其它操作命令在父服务进程继续执行 间隔性写入在配置文件中设置写入触发条件,比如:SAVE 900 1,代表在900秒内对数据库进行一次修改，就触发写入程序。 载入在服务器启动时，会对当前的持久化策略进行一个判断，如果当前已经开启了AOF持久化功能，那就会优先载入AOF还原程序，否则才载入RDB文件，整个载入过程都是阻塞的，保持数据的一致性。 AOF(append only file)持久化AOF(append only file)持久化是基于redis服务器对键值对的操作命令生成的aof文件，保存在磁盘中,AOF文件的结构就是一串操作命令的文本文件 写入AOF持久化通过以下步骤来进行持久化操作： 1. 命令追加（append）在redis服务器中提供了一个sds（简单动态字符串）类型的缓冲区aof_buff,它用于记录redis的操作命令，也就是利用命令追加（append）模式将redis的操作命令一条一条的追加到该缓冲区的末尾 2. 写入AOF文件将存储到缓冲区aof_buff中的指令通过调用flushAppendOnlyFile函数写入AOF文件中，写入AOF文件有三个策略： ● always：每一次数据操作，就将aof_buff缓冲区中的所有数据同步写入到AOF文件中 ● everysec：启动一个线程，定时（每隔一秒）将aof_buff缓冲区中的所有数据同步写入AOF文件中 ● no：不要求同步的情况下（aof_buff存储满溢），将aof_buff缓冲区中的数据写入AOF文件中三个策略的安全性：always&gt;everysec&gt;no , 效率：no&gt;everysec&gt;always 载入AOF持久化的载入方式是创建一个伪客户端去读取AOF文件，再在伪客户端中执行读取AOF文件中的一条条指令，直到完毕，数据库就恢复了之前的状态 重写AOF文件就像是数据库操作的日志文件，记录了数据库各种操作的指令，但是会出现冗余的指令记录，长时间下去，会导致文件体积变得太大，比如，执行如下操作1234RPUSH msg &apos;a&apos;RPUSH msg &apos;b&apos;RPUSH msg &apos;c&apos;RPUSH msg &apos;d&apos; 如上所示，最后msg的结果是’a’,’b’,’c’,’d’，AOF文件就会有四条指令的记录，其实只要一条指令记录就可以了，这时，AOF持久化提供了一种重写的机制，它会创建一个子进程来处理，在子进程中创建一个新的AOF文件，针对上面情况，对一个对象的多次操作，它会用一条指令来表示，这样新的AOF文件就大大减少了存储体积，由于在子进程进行重写的时候，父进程还会处理操作指令，在重写期间执行的操作指令会被写到一个aof重写缓冲区中，所以不仅仅是aof缓冲区写入新的AOF文件中，aof重写缓冲区也会写进新的AOF文件中，这样和旧的AOF文件保存的数据库状态是一致的，最后替换旧的AOF文件 思考优劣比较RDB持久化的优点在于：（1）RDB文件是一个非常紧凑的二进制文件，所以在远程传输上有很大的优势，可用于灾备中心的存储文件（2）在载入数据库上，大数据量的情况下，RDB比AOF更加快速（3）在持久化上，RDB持久化方式会fork一个子进程来执行，这样会保证Redis最大的性能缺点如下：（1）Redis的数据存储是基于内存的，如果碰上意外（宕机或者电源中断），如果你是每个五分钟甚至更长进行一次持久化，那么将会损失这几分钟的数据（2）RDB是fork子进程来进行持久化的，所以当大数据集的时候，这会加大cpu的响应时间，影响Redis的处理速度AOF持久化的优点在于：（1）AOF使用的是fsync策略进行持久化，所以即使碰上意外，也只是损失1秒的数据（2）AOF文件是一个日志文件，由指令集组成，通俗易懂，使使用者更加的好维护缺点如下：（1）相对于RDB文件来说，AOF文件相对过大了 如何选择使用哪种持久化方式一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快， 除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug 参考http://www.redis.cn/topics/persistence.htmlhttps://read.douban.com/ebook/7519526/（数据库的设计与实现）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis基本数据类型及其实现]]></title>
      <url>%2F2016%2F12%2F28%2Fredis_datatype%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库(来自wiki)，它提供丰富的数据结构类型：字符串（Strings），列表（Lists），哈希（Hashed），集合（Sets），有序集合（Sorted sets）来满足数据存储的需求，下面分别对这五大数据类型及其实现进行详述 字符串（String）实现的数据结构1. REDIS_ENCODING_INT（long类型整数）场景：SET的value为整数指令：SET msg 123 2. REDIS_ENCODING_RAW（大于32字节的字符串）场景：SET的value为大于32字节的字符串指令：SET msg LongString...... 注意：SDS是redis内部构建基于字符串的数据结构（不是直接使用C字符串），它由free（未分配空间），len（字符串长度或已使用长度），buf（存储字符数组）三部分组成，降低操作字符串的复杂度，len属性解决了不需要遍历整个字符串才能获取，free属性降低了内存重新分配的次数 3. REDIS_ENCODING_EMBSTR（小于32字节的字符串）场景：SET的value为小于32字节的字符串指令：SET msg hello 注意：对于字符串存储，对于raw编码模式，需要调用两次连续分配内存函数构建RedisObject和SDS这两块内存，而embstr的编码只需要一次性的内存分配一块连续的内存空间即可， 列表（Lists）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩列表）场景：（1）列表保存的元素都少于64个字节 （2）列表保存的元素数量少于512个指令：RPUSH msg &#39;a&#39; &#39;b&#39; &#39;c&#39;注意：ZipList是redis基于小数值和短字符串而构建的数据结构，由zlbytes（压缩列表占用的字节数），zltail（压缩列表尾节点到起始地址的偏移量），zllen（节点数），entryx（压缩列表的各个节点），zlend（压缩列表的尾端标记值） 2. REDIS_ENCODING_LINKEDLIST（链表）场景：（1）列表保存的元素都大于64个字节 （2）列表保存的元素数量大于512个指令：RPUSH msg &#39;a&#39; &#39;b&#39; &#39;c&#39; ......注意：LinkedList是类似于java中的LinkedList，由一个双向链表构成，自带长度计数器和表头表尾指针，在对于增加删除时能高效的进行调整（前后指针重新指定） 哈希（Hashes）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩列表）场景：（1）哈希对象中的键值对的长度都小于64字节 （2）哈希对象中的键值对的数量小于512个指令：HSET msg name &quot;andy&quot;注意：利用压缩列表实现键值对，实现方法是：key在前，value在后，形成一个链 2. REDIS_ENCODING_HASHTABLE（哈希表）场景：（1）哈希对象中的键值对的长度都大于64字节 （2）哈希对象中的键值对的数量大于512个指令：HSET msg name &quot;andy&quot; age &quot;24&quot; ......注意：HashTable也叫字典表，是整个redis的核心，类似于java中的HashTable，但是在其特殊的应用场景下，做出了一些改进，比如渐进式的rehash等等 集合（Sets）实现的数据结构1. REDIS_ENCODING_INTSET（整数集合）场景：（1）集合中的元素为整数 （2）集合中的元素个数小于512个指令：SADD msg 1 2 3注意：IntSet是redis存储整数集合的数据结构，有encoding（编码，保存的位数类型），length（长度）和contents（整数数组）构成，可以灵活的根据整数的存储位数来选择相应的存储方式来节省内存 2. REDIS_ENCODING_HASHTABLE（哈希表）场景：（1）集合中的元素不为整数 （2）集合中的元素个数大于512个指令：SADD msg &quot;a&quot; &quot;b&quot; &quot;c&quot; 有序集合（Sorted Sets）实现的数据结构1. REDIS_ENCODING_ZIPLIST（压缩表）场景：（1）有序集合中的元素小于128个 （2）有序集合中所有元素的集合都少于64个字节指令：ZADD a 8 b 5 2. REDIS_ENCODING_SKIPLIST（跳跃表）场景：（1）有序集合中的元素大于128个 （2）有序集合中所有元素的集合有多于64个字节指令：ZADD a 8 b 5 ......注意：跳跃表是一种有序的数据结构，它通过每个节点指向其它多个节点的指针，来到达最快的访问节点速度，由header（表头节点），tail（表尾节点），level（节点最大层数），length（节点数），简单的实现就是通过一个有序的链表，表示为第一层，再取其中头结点和尾节点，中间随机多个不重复节点组成新的链表，即为第二层，如下重复下去，直到到达随机（1-32层）的阈值，这样到达中间的节点的复杂度将会大大的降低。上图中是还使用了哈希来获取元素的分数值来进行排序。 参考http://www.redis.cn/topics/data-types.htmlhttps://read.douban.com/ebook/7519526/（数据库的设计与实现）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[源码解析String，StringBuffer，StringBuilder的区别]]></title>
      <url>%2F2016%2F11%2F18%2FString%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 String，StringBuffer，StringBuilder三者是处理字符串的常用类，String是在JDK1.0时就存在的字符串处理类，也是使用最广泛的，StringBuffer也是JDK1.0开始发布的线程安全的字符串处理类，他改变了原有String不可改变的字符串，增加了一个缓冲的概念，StringBuilder是JDK1.5提出的字符串处理类，他取消了StringBuffer原有的线程安全的特性，增加了字符串处理的效率。 其实要说哪种处理字符串是性能最好的，我觉得是哪种场景上的字符串处理性能是最好的，因为他们是各有千秋，下面是基于JDK1.8的源码解析这三种字符串处理方式的区别 String123public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char value[]; 由上可知，String实现了序列化和字符序列两个接口，这会带来两个特性，一个是可传输的特性，一个是字符处理的特性，再看String的核心属性value，value是存储字符串的载体，由于被final修饰了，所有该字符串载体一旦初始化了就是不可变的，正是String不可变这一特性，所以它在处理字符串的方式只能通过构造初始化的方式来实现 1.初始化一个空串123public String() &#123; this.value = "".value;&#125; 2.初始化一个字符串对象1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125; 3.初始化一个字符串123public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length);&#125; 4.初始化字节类型的字符串123public String(byte ascii[], int hibyte) &#123; this(ascii, hibyte, 0, ascii.length);&#125; 当然还可以初始化StringBuffer，StringBuilder来构建，String的构造方法很丰富，提供了很多类型且多样的数据源来支持，如果你想要构建一个不变的或者变化不多的字符串，String很适合你 StringBuffer123public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123; 在StringBuffer继承体系来看，StringBuffer拥有String应有的特性，而且还继承了AbstractStringBuilder这个抽象类，这个类定义了StringBuffer的存储载体(也是StringBuilder的存储载体)，现在通过一个append方法来看看StringBuffer处理字符串的方式 12345public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this;&#125; 由上可知，这是一个StringBuffer拼接字符串的方法，由synchronized来修饰，所以StringBuffer是线程安全的（其实StringBuffer几乎所有的方法都是由synchronized修饰），这里它是调用的父类的append方法 123456789public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;&#125; 这是父类AbstractStringBuilder的append方法，在方法内有是两个很重要方法，也就是缓冲区的实现 扩容方法：ensureCapacityInternal(int minimumCapacity) 赋值方法：str.getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) 我们先看看扩容方法1234private void ensureCapacityInternal(int minimumCapacity) &#123; if (minimumCapacity - value.length &gt; 0) expandCapacity(minimumCapacity);&#125; 这里会对所拼接的字符串做一个判断，也就是所拼接的字符串不能为空1234567891011void expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity);&#125; 以上代码可知，他会先对原有的字符数组的容量扩大两倍再加二，在和最小的容量(原有的容量+拼接字符串的容量)比较，没有最小容量大就取最小容量，这里也有一个以防内存溢出导致容量为负数的一个处理，最后核心的就是 Arrays.copyOf(value, newCapacity)，Arrays这是一个数组的工具类，copyOf方法是针对数组在原有的基础上改变其容量，这就是等于对原有的字符串数组进行了扩容，在回来看看将拼接的字符数组重新添加到新的字符数组的方法 123456789101112public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) &#123; if (srcBegin &lt; 0) &#123; throw new StringIndexOutOfBoundsException(srcBegin); &#125; if (srcEnd &gt; value.length) &#123; throw new StringIndexOutOfBoundsException(srcEnd); &#125; if (srcBegin &gt; srcEnd) &#123; throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); &#125; System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin);&#125; 该方法开始会对不符合条件进行异常处理，最后的调用System.arraycopy方法将拼接字符数组添加到新的字符数组，这就完成了一个字符串拼接的过程，也就是缓冲池的实现，在多线程的情况下保证安全的前提字符串大量的变动，使用StringBuffer是最好的 StringBuilder123public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence 其实从父类体系来看，StringBuilder和StringBuffer是一样的，那StringBuilder与StringBuffer有什么区别呢？让我们看看它的append的方法 1234public StringBuilder append(String str) &#123; super.append(str); return this;&#125; 这里你就会方法它也是调用父类的append方法，而他们的父类又是同一个，这里不同的就是StringBuilder的append方法没有用synchronized修饰，所以它是不安全的，当然也就意味着在单线程的情况下比StringBuffer的性能是要好的，其实对于StringBuffer和StringBuilder来讲，它们都是对于AbstractStringBuilder类的实现，或许会有其他细节处理的不同，大致来讲，他们的区别就是一个是线程安全的实现，一个是线程不安全的实现，只是要你自己去权衡线程安全与性能之间的抉择 总结StringBuilder或者StringBuffer并不一定比String的效率高，在各个场景中有不同的用法而已，对于StringBuilder和StringBuffer来讲，也不是施了什么魔法，只是实现了CopyOnWrite的思想，对字符串的操作的性能更高了，应对不同情况的选择而已]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解刨单例模式]]></title>
      <url>%2F2016%2F11%2F01%2Fsingleton%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 单例模式，也叫单子模式，是一种常用的软件设计模式。在应用这个模式时，单例对象的类必须保证只有一个实例存在。许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。这种方式简化了在复杂环境下的配置管理。——来自wikipedia 单例模式大致上分为两种模式，饿汉模式和懒汉模式，在开发环境中有很多的应用，比如Spring的bean工厂就应用了单例模式来对bean进行初始化，他对类的实例进行了统一的管理，每次返回该类的唯一实例，也优化了实例化类的资源利用。 饿汉模式123456789public class HungrySingleton &#123; private final static HungrySingleton INSTANCE = new HungrySingleton(); private HungrySingleton() &#123;&#125; public static HungrySingleton getInstance() &#123; return INSTANCE; &#125;&#125; 饿汉模式指在类的实例在全局定义，利用static和final修饰，保持类的唯一性，在类装载的时候就初始化了， 因为创建实例本身是线程安全的，所以饿汉模式也是线程安全的。 但是饿汉模式的应用场景是明确类本身实例的信息，因为这是在类装载前就实例化了，无法改变，但是如果想根据上下文或者所依赖参数的变化来动态的实例化类，饿汉模式就不匹配了，于是另一种懒汉模式就登场了。 懒汉模式懒汉模式指全局的实例在第一次调用的时候才加载 简单模式123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;// 线程1 instance = new LazySingleton();// 线程2 &#125; return instance; &#125;&#125; 这是一个很简单的懒汉模式，在单线程的环境下，通过第一次检查instance是否为空来获取唯一的实例，但是在多线程的环境下，由于instance = new LazySingleton()不是一个原子性的操作，会受到其他线程的干扰，如上所示： 如果线程1在if (instance == null) {挂起，线程2在instance = new Singleton()开始执行，instance指向了一个内存空间，但是还没有开始初始化对象( 指令重排序，下面会讲到 )，线程2挂起，线程1这个时候继续，这个时候判断instance不为null，返回的只是一个空内存块(没有实例化对象)，很容易造成NullPointException， 如果线程2在instance = new Singleton()挂起，线程1在if (instance == null) {开始执行，这个时候instance还没有指向内存，instance为null，也进来进行了创建实例的步骤，线程1和线程2创建了两个实例，违背了单例的思想 所以以上两种情况表明这种简单模式是线程不安全的 单重检验锁模式（single checked locking pattern）123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static synchronized LazySingleton getInstance() &#123; if (instance == null) &#123;// single check instance = new LazySingleton(); &#125; return instance; &#125;&#125; 以上的模式是在获取实例的方法getInstance()加上同步锁synchronized来修饰，以保证线程的安全性，但是虽然保证了线程安全，但是这种暴力的同步严重影响了程序执行的性能，在执行getInstance()方法时，频繁的线程的更换调度，对于性能是一个很大的开销。 如果instance已经实例化了，对于上述模式来讲，他还是要等待前面的线程获取完实例才能获取实例，这样实现很低效，其实同步只是针对实例化对象的过程，对于已经实例化对象的instance来说，只需要返回就可以了，不需要同步。 双重检验锁模式（double checked locking pattern）1234567891011121314151617public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;//single check 线程1 synchronized (LazySingleton.class) &#123; if (instance == null) &#123;//double check instance = new LazySingleton(); //线程2 &#125; &#125; &#125; return instance; &#125;&#125; 双重检验锁模式又对单重检验锁模式进行了优化，他用两次检查来判断instance是否被实例化，同步锁只是针对instance的实例化，对于instance已经实例化的情况下，直接返回instance，不进入同步锁的代码块，大大的提高了性能 但是，又重现了简单模式的第一种情况，如上代码所示，假设线程2在实例化对象只是在instance指向了内存空间，但是还没有实例化对象(指令重排序)，这个时候线程1的instance！=null，直接返回instance，造成NullPointException，现在问题来了，什么是指令重排序？ 一般的情况下，程序运行代码是顺序运行的，但是会存在一些指令的重排序问题，比如123int a=1；int b=1；int c=a+b; 以上代码使用指令来执行，分为以下5个步骤： 对a赋值1 对b赋值1 获取a的值 获取b的值 运算a+b的值存在c的内存中 上述的五个步骤有时并不是按照顺序进行的，有时你执行步骤1对a赋值1时，就会执行步骤3获取a的值，因为他们存在数据依赖，这就是发生了指令重排(具体了解，访问 http://tech.meituan.com/java-memory-reordering.html )，对于实例化对象来讲，具体的步骤如下： 分配内存 实例化对象 引用指向内存对象 正常的情况下只有实例化了对象才会引用指向内存对象，但是如果这时发生了指令重排序，执行顺序变成了1,3,2，在执行步骤3还没有执行步骤2就执行线程1了，这个时候就会造成异常错误，这个时候就会使用volatile关键字来避免指令重排序。 volatile式模式（double checked locking pattern with ）volatile的定义是：java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 正如上所说，java线程内存模型确保所有线程看到这个变量的值是一致的就是volatile的可见性，正是因为他的可见性，要求所有线程看见该变量要一致，所以代表着volatile的另一个特性:禁止指令重排序，其实，在JDK1.5之前volatile是不能保证能够禁止指令重排序的，在JDK1.5之后才能应用于双重检查模式。 1234567891011121314151617public class LazySingleton &#123; private volatile static LazySingleton instance; private LazySingleton ()&#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123;//single check synchronized(LazySingleton.class)&#123; if (instance == null) &#123;//double check instance = new LazySingleton(); &#125; &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类模式(static nested class pattern)静态内部类模式也是一种懒汉模式，他利用内部类的特性(调用时才加载）来创建实例 123456789public class LazySingleton &#123; private static class SingletonClass &#123; private static final LazySingleton INSTANCE = new LazySingleton(); &#125; private LazySingleton ()&#123;&#125; public static final LazySingleton getInstance() &#123; return SingletonClass.INSTANCE; &#125; &#125; 这种模式也能保证线程的安全性，JVM在保持类的信息的一致性，加载类的时候是线程安全的，而且不需要同步来执行getInstance()方法。 参考https://zh.wikipedia.org/wiki/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8Fhttp://tech.meituan.com/java-memory-reordering.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[动态代理]]></title>
      <url>%2F2016%2F10%2F05%2Fproxy%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 代理模式 在代理模式中,角色分配如下： Subject(1-k) : 委托对象所实现的所有接口(i&gt;=1) RealSubject : 委托对象，也就是被代理的对象 ProxySubject : 代理对象 在JDK实现的代理模式是面向接口的，不管是委托类还是代理类都应该实现相同的接口，这样才会保持行为的一致性，因为对于Client来说，它只要输出它所想要的结果，不会管你是谁实现的，所以为了减轻委托对象的压力，就必须要克隆出其他跟自己一样的帮手来帮助自己，就好像火车票代售点一样，代理对象就由此而生了。 静态代理静态代理是指在JVM执行前就把你的代理类给定义好了，例子如下： Subject 123public interface Subject &#123; public void doSomething();&#125; RealSubject 1234567public class RealSubject implements Subject&#123; @Override public void doSomething() &#123; // TODO Auto-generated method stub System.out.println("i am just do something!!!!!"); &#125;&#125; ProxySubject 12345678910public class ProxySubject implements Subject&#123; Subject realSubject = null ; @Override public void doSomething() &#123; //类似于Spring的@Before do something realSubject = new RealSubject(); realSubject.doSomething(); //类似于Spring的@After do something &#125;&#125; 由上可知，其实调用代理类(ProxySubject)和调用委托类(RealSubject)是一样的效果，等于是代理类对委托类又重新封装了一层，但是为什么要这样做呢？ 如果每次Client调用委托类来完成业务操作，那么每次委托类就得创建对象来完成业务，如果是大业务场景，消耗的内存是巨大的，这个时候，如果是代理类来实现，可以在代理类内对委托类实现缓存操作，这样就会减少很大的内存消耗。 如果你想对原生的委托类进行扩展(比如Spring中的@After和@Before的思想），你可以对委托类进行修改，但是这会影响原有已经实现的程序逻辑，如果使用代理类，在不影响原生的委托类情况下再进行逻辑的扩展，使程序变得更加健壮。 由上可知，代理类的作用使原生的委托类更加的灵活被运用，能够应付不同的不同应用场景，但是，如果委托类的一些应用方法的删减，实现接口的减少，对于代理类来说也要进行很大的修改，这样的改动有时使代理模式变得更加的复杂，变得不是那么的灵活，如果有一种代理类能够需要调用的时候才加载，不管接口的变动，代理类都会自动的更新，无需改变，那么这就是动态代理。 动态代理动态代理是在静态代理的基础上对代理类进行了优化，利用java反射的原理来创建代理类，使代理类在JVM运行时创建。 如上图所示，这个代理类会根据现有的接口数或者实现的方法动态的去创建对象，对于业务频繁更替的场景下，不需要对代理类进行频繁的更改，更加的灵活，而在java中，对于动态代理的实现，有两种方法，一种是JDK形式的实现，一种是第三方包cglib的实现形式。 JDK动态代理在JDK实现中，主要是一个类，一个接口：动态代理类Proxy和调用处理器InvocationHandler 1.Proxy Proxy是动态创建代理类的类，它主要是利用接口的信息在类加载器中动态的生成代理类，而其中主要的生成代理类的方法就是newProxyInstance方法，实现如下： 123456789101112131415161718192021222324252627public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; // 检查调用处理器是否为空，为空抛异常 if (h == null) &#123; throw new NullPointerException(); &#125; // 获得与制定类装载器和一组接口相关的代理类类型对象 Class cl = getProxyClass(loader, interfaces); // 通过反射获取构造函数对象并生成代理类实例 try &#123; Constructor cons = cl.getConstructor(constructorParams); return (Object) cons.newInstance(new Object[] &#123; h &#125;); &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString()); &#125; catch (IllegalAccessException e) &#123; throw new InternalError(e.toString()); &#125; catch (InstantiationException e) &#123; throw new InternalError(e.toString()); &#125; catch (InvocationTargetException e) &#123; throw new InternalError(e.toString()); &#125; &#125; 由上就很容易发现，这是个简单的java反射创建对象，获取Class对象，再获取构造器，最后反射成对象，这是个静态方法，所以直接类本身就可以调用了。 Proxy还有很多的实现，比如利用一个HashMap来实现对代理类的缓存，key就是接口列表，value就是代理类的对象，还有关联调用处理器的方法等等。 2.InvocationHandler InvocationHandler是调用处理器，是负责方法调用时，利用java反射机制在JVM运行时调用该方法，其中主要的方法就是invoke方法，有三个参数proxy,method,args，这是需要自己去实现的，以下是invoke方法的实现 12345public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //方法反射 Object obj = method.invoke(proxyObj, args); return obj; &#125; 3.代码实现 MyInvocationHandler 1234567891011public class MyInvocationHandler implements InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; ////类似于Spring的@Before do something //方法反射 Object obj = method.invoke(proxyObj, args); //类似于Spring的@After do something return obj; &#125;&#125; JdkProxyFactory 1234567891011public class JdkProxyFactory &#123; private Object proxyObj = null;//代理类 // 创建代理 public Object createProxy(Object targetObject,InvocationHandler myInvocationHandler) &#123; if (null != targetObject) &#123; this.proxyObj = targetObject; &#125; return Proxy.newProxyInstance(this.proxyObj.getClass().getClassLoader(), this.proxyObj.getClass().getInterfaces(), myInvocationHandler); &#125;&#125; 以上就是一个简单的JDK实现的代理类，直接用以下的代码调用就可以了 123Subject proxySubject = (Subject)new JdkProxyFactory().createProxy(new RealSubject(),new MyInvocationHandler());proxySubject.doSomething(); 当我们调用doSomething方法时，你以为是调用RealSubject对象的doSomething方法，其实是调用代理类$ProxyN(生成代理类的名称，N从1开始)的doSomething方法，他会触发该方法的调用处理器invoke方法来调用doSomething方法。 cglib动态代理CGLib是面向类的，而cglib动态代理的实现也是一个类和一个接口：Enhancer和MethodInterceptor，和JDK的Proxy和InvocationHandler职能是一样的，一个是负责创建类，一个是负责调用方法的处理 1.Enhancer Enhancer可以说是CGLib的一个字节码增强器，它的作用通过委托类的子类来实现代理类的创建，创建过程如下： 通过委托类创建它的子类，在子类中的每个方法设置回调方法，然后获取它的Class对象 利用Class对象根据GeneratorStrategy.generate方法生成代理类的字节码 通过反编译生成代理类的Class对象 再通过反射机制创建代理类的对象 2.MethodInterceptor MethodInterceptor是一个方法拦截器，它的作用就是在代理类每执行一个方法时执行拦截方法并返回，其中最主要的方法intercept实现如下 123456public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //相当于调用了代理类本身的方法 Object result = proxy.invokeSuper(obj, args); return result; &#125; CGLib实现了Fastclass机制，对代理类的方法建立了索引，把方法存储在索引中，通过方法名和它的信息就可以获取该方法，不需要进行反射来进行方法的调用。 3.代码实现 MyMethodInterceptor 1234567891011public class MyMethodInterceptor implements MethodInterceptor &#123; public Object intercept(Object obj, Method method, Object[] arg, MethodProxy proxy) throws Throwable &#123; ////类似于Spring的@Before do something //方法反射 Object object = proxy.invokeSuper(obj, arg); //类似于Spring的@After do something return object; &#125;&#125; CglibProxyFactory 12345678910111213public class CglibProxyFactory &#123; private Object proxyObj = null;//代理类 // 创建代理 public Object createProxy(Object targetObject,MethodInterceptor MyMethodInterceptor) &#123; if (null != targetObject) &#123; this.proxyObj = targetObject; &#125; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.proxyObj.class); enhancer.setCallback(MyMethodInterceptor); return enhancer.create(); &#125;&#125; 这是一段Cglib代理类的实现，调用代码如下： 12Subject proxySubject = (Subject)new CglibProxyFactory().createProxy(new RealSubject(),new MethodInterceptor());proxySubject.doSomething(); 相比于JDK代理实现，Cglib的实现更快，它的不同之处在于 Cglib代理摒除了JDK代理利用反射来调用方法(反射的效率是很低的），利用索引来实现。 Cglib代理是面向extends的，意味着一些不能继承的类无法用Cglib来实现，而JDK代理是面向implements,这方面更规范。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neo4j的导入方案]]></title>
      <url>%2F2016%2F09%2F27%2Fneo4j-import%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 概述Neo4j是一种强大的，可扩展的和高性能的图形数据库，由边，属性和节点组成，是用来描述节点与节点之间的关系，由位于美国旧金山的Neo技术公司进行开发和维护，它属于NoSql的范围内，在一些社交的项目中处理人与人或物之间的关系挥发这巨大的作用，以下列举它的一些特点 支持ACID事务 高可用性 可扩展到数十亿的节点和关系 高效且快速的遍历查询(图的遍历) 强大的结构化查询语言Cypher 导入方案如果你想选择Neo4j作为你的处理关系的数据库，首先处理的问题就是导入外部数据，将MySQL，Oracle或者PostgreSQL的关于用户的关系数据导入Neo4j中，这里有两种导入数据的方式： 1. LOAD CSVLOAD CSV是Cypher语言的指令，是将csv文件中的属性插入Neo4j中，首先先将原数据库的数据导出成csv文件，以电影信息为例，导出CSV文件如下： movies.csv：1234id,title,country,year1,Wall Street,USA,19872,The American President,USA,19953,The Shawshank Redemption,USA,1994 Neo4j提供了一个WEB端的客户端系统，利用可视化的方式展示节点与节点的关系，在上面可以利用Cypher语言对数据进行操作，代码如下：1234LOAD CSV WITH HEADERS FROM &quot;CSV地址&quot; AS csvLineMERGE (country:Country &#123; name: csvLine.country &#125;)CREATE (movie:Movie &#123; id: toInt(csvLine.id), title: csvLine.title, year:toInt(csvLine.year)&#125;)CREATE (movie)-[:MADE_IN]-&gt;(country) 上面的意思是创建country和movie节点，然后将country和movie建立MADE_IN的关系，这样就将csv的数据导入了Neo4j中了，LOAD CSV指令导入的形式只是相当于多个CRATE指令，通过繁杂的JAVA程序向硬盘写数据，所以只是适于小数据量的导入 注意：csv中属性的数据都是String类型的，Neo4j是由JAVA写的，每个属性是有类型的，所以内置了toInt这样的类型转换方法 2. neo4j-importneo4j内置了一个批量导入的脚本，存储在/BIN目录下的neo4j-import.bat,它直接在数据库存储文件目录中生成你所需创建节点和关系文件，所以它的限制也很多，第一点是导入前，还没有创建数据库，讲白了只能是第一次导入才有效，第二点是节点和关系要分开导入就是要额外进行导出存储关系的csv，第三点是如果不进行强制指定类型，每个节点(包括不同类型的节点)的id不能相同， movie.csv：1234id,title,year1,Wall Street,19872,The American President,19953,The Shawshank Redemption,1994 country.csv：1234id,name4,USA5,CHINA6,UK MADE_IN.csv：1234:START_ID,:END_ID1,42,53,6 （1）由于配置文件的默认读取的位置在import中，所以导出的csv格式的文件要存储在neo4j存储目录下的import目录（2）使用neo4j-import工具,在neo4j的bin目录下执行以下的指令1neo4j-import --into ../data/databases/graph.db --id-type string --nodes:movie ../import/movie.csv --nodes:country ../import/country.csv --relationships:MADE_IN ../import/MADE_IN.csv --multiline-fields=true --skip-bad-relationships=true --bad-tolerance=2000 这样就完成了neo4j的批量导入了，大约1000万的数据量，十几分钟就完成了 注意：在导入过程中有可能遇到如下错误（1）./data/databases/graph.db already contains a database错误，表示graph.db已经包含了一个数据库，需要将其删除才能导入（2）Duplicate input ids that would otherwise clash can be put into separate id space，表示有ID重复，按提示查询（3）panic called，so exiting表示出现特殊符号，可检查列中可含有特殊符号 –multiline-fields=true :多行导入–skip-bad-relationships=true：过滤错误的关系不导入，可以在log中查看–bad-tolerance=2000：错误的最大限制在2000个]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LRU(Least recently used-最久未使用算法)]]></title>
      <url>%2F2016%2F09%2F22%2FLeast_recently_used%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 现在的数据越来越多的被存储，对于数据库来讲，访问大数据量会变得越来越慢，于是为了提高访问的速度，将小范围区域的数据存储在一个高速缓冲存储器，以至于不会每次去读取磁盘，而是在内存中直接访问数据。内存存储的代价远远的大于磁盘存储的价值，所以缓存很小，并不能存储你所有的数据，所以你不得不保存你所认为重要的数据(使用次数较多的数据)，那就要淘汰最少使用的数据，如何从缓存中淘汰最少使用的数据，一个简单而且有效的算法，最近最少使用算法LRU. LRU原理最久未使用算法（LRU）：最久没有访问的内容作为替换对象 —– 来自wiki LRU翻译过来就是最久未使用，当缓存到达一定的阀值时，剔除掉最久未使用的数据，通俗来讲，比如一个缓存只能缓存10000条数据，10000条就是这个缓存的阀值，小于10000条时可以随意添加，一旦数据量到达了10000条时，这个时候就要删除最久未使用的数据了，以保持最大程度的使用缓存。 LRU实现LRU的实现最简单的就是单链表的实现，这里引用的就是JDK中的LinkedHashMap,它有两种形式，一个是最晚读的数据放在前面，最早读的数据放在后面，另一个就是FIFO，也就是先进先出。 晚读放前，早读放后 每次新的数据从头部开始插入，当链表缓存空间满了的时候，就从尾部对数据进行删除，如果有数据命中的话，就将该数据移动到头部。 而基于LinkedHashMap的实现有两种方法，一种就是继承LinkedHashMap的方式，叫做inheritance，一种直接使用LinkedHashMap,叫做delegation，这两种都可以实现LRU算法，而大部分功能LinkedHashMap已经实现了,但是淘汰的删除方法就需要重写了。12345678public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 这是LinkedHashMap的构造方法和删除元素的方法，默认情况下，LinkedHashMap是根据元素的添加顺序进行存储的,如果构造参数accessOrder为true的话，就会按照访问数据，最晚访问的放在最前，最早访问的放在最后。 inheritance12345678910111213public class LruInheritance&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int MAX_SIZE=100; public LruInheritance(int cacheSize) &#123; super((int) Math.ceil(cacheSize / 0.75)+1, 0.75f, true); MAX_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_SIZE; &#125;&#125; 在构造方法中，由于将负载因子设置为0.75，所以在原有容量要除以该负载因子，因为Map中的阀值是原有容量*负载因子，以此来判断是否超标。而原本LinkedHashMap删除的机制返回的都是false，所以要重写removeEldestEntry方法,如果超过当前容量就返回true，就会删除当前元素了。 delegation12345678910111213141516public class LruDelegation&lt;K, V&gt; &#123; private final int MAX_SIZE; LinkedHashMap&lt;K, V&gt; map; public LruDelegation(int cacheSize) &#123; MAX_CACHE_SIZE = cacheSize; int capacity = (int) Math.ceil(MAX_SIZE / 0.75) + 1; map = new LinkedHashMap(capacity, 0.75f, true) &#123; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_SIZE; &#125; &#125;; &#125;&#125; 在这个构造方法中，它内部就是用已经重写removeEldestEntry方法的LinkedHashMap实现的，他与inheritance不同的是，对LinkedHashMap不同使用，一个当爹使，一个当朋友使。 FIFO(先进先出)其实与第一种方式相比，对于LinkedHashMap来讲，就是accessOrder参数的变化，上面也提到，LinkedHashMap默认的是FIFO的，构造参数accessOrder默认是false的，所以与第一种相比，只要将accessOrder置为false，或者使用一个无参构造，就可以实现了。1234567final int MAX_SIZE= 100;LinkedHashMap&lt;Integer, String&gt; lru = new LinkedHashMap&lt;Integer, String&gt;() &#123; @Override protected boolean removeEldestEntry(Map.Entry&lt;Integer, String&gt; eldest) &#123; return size() &gt; MAX_SIZE; &#125;&#125;; 这种是基于单链表实现LRU缺点是：由于LinkedHashMap本身特性，所以是线程不安全的，而且命中率不高。优点是：实现起来简单，很多东西LinkedHashMap已经帮你实现了 其实多链表或者多队列的组合使用，效率和命中很更高，一个链表或队列专门用来维护命中概率（作为访问历史数据存储），另一个作为多次访问数据存储 ### 新的数据都会从历史数据的队列的头部插入,如果当前队列容量满了之后，就会从尾部淘汰，如果当前历史数据被访问多次，就会移动到正式的LRU数据队列中，然后按时间排序，当该队列满了之后，就会从尾部淘汰。多个链表或队列组合的LRU能够应该复杂的场景,能够应对不同情况，不同的淘汰机制,提高数据的命中率，同时响应的维护成本也响应的提高了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初识HTTP-1]]></title>
      <url>%2F2016%2F09%2F06%2Fmeet-http-1%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 定义HTTP译为超文本传输协议,是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）,也是基于超文本为载体在客户端和服务器端进行传输的协议。 超文本是基于超文本构建语言构建的文档，比如HTML(HyperText Markup Language 超文本标记语言)就是标准的构成超文本的语言,而传输（转移）是基于超文本的内容在客户端和服务器端进行通信。 如上图所示，这是一个简单的超文本传输的过程，]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java反射笔记(java reflection)]]></title>
      <url>%2F2016%2F09%2F04%2Fjava_reflection%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 java是一门静态语言，一般来讲，类的定义需要在JVM运行前完成，要通过JVM编译环节，才能运行在JVM上，而java反射机制使java的类定义能够在JVM运行时动态的加载，让在某些功能上更加灵活多用，根据不同的上下文来决定类的功能 Class在每一个类都有Class对象，在JVM编译的环节中，他会检查类的信息，这个时候就会获取该类的Class对象，它包含了该类的所有信息,获取Class对象有很多种方法。 获取Class对象1.利用类本身的情况下 1Class myClass = className.class; 2.利用类名的情况下 1Class myClass = Class.forName("className"); 注意：在使用类名获取Class对象时，参数名称必须是类的全称，包括包的名称，这样才能找得到 3.利用类对象的情况下 1Class myClass = new Object().getClass(); 当然，你拥有Class对象，等于你就知道该类的所有信息，包括变量，方法，修饰符，注解，甚至它的父类，实现的接口，所在包的信息，具体的方法可以参考相应的文档：http://docs.oracle.com/javase/6/docs/api/java/lang/Class.html Constructor在java中，创建实例对象是根据构造器来实现的，JVM编译环节通过Constructor来检查类中构造方法的信息，Constructor拥有构造方法所有的信息，如果我们获取了Constructor对象，也就可以反射出拥有该构造器的对象。 获取Constructor对象1.获取所有的Constructor对象 1Constructor[] constructors = myClass.getConstructors(); 2.获取指定的构造器 1Constructor constructor = myClass.getConstructor(String.class); getConstructor方法的参数是构造方法的参数的Class对象 实例化对象12Object obj = constructor.newInstance("参数值"); 相当于SimpleReflection simpleReflection = new SimpleReflection(“参数值”)，newInstance方法的参数是构造方法的参数的实例 Field在java的JVM编译环节中，通过Field来检查类变量的信息,它拥有类变量所有的信息。 获取Field对象公有(public)变量1.获取所有Field 1Field[] fields = myClass.getFields(); 2.获取指定的Field 1Field field = myClass.getField(); 私有(private)变量1.获取所有Field 1Field[] privateFields = myClass.getDeclaredFields(); 2.获取指定的Field 1Field privateField = myClass.getDeclaredField(); 获取变量属性1.获取变量名称 1String fieldName = field.getName(); 2.获取变量类型 1Class fieldType = field.getType(); set&amp;get变量公有(public)变量12Object value = field.get(new Object());field.set(new Object(), value); 私有(private)变量通常情况下，外部类是不能访问内部的私有变量的，因为在访问对象变量时，JVM会有一个反射访问检查(reflection access check),私有变量没有访问权限是不能访问的，在Field对象有一个setAccessible方法，true表示在外部对象的作用域里可以访问私有变量。 123privateField.setAccessible(true);Object value = privateField.get(new Object());privateField.set(new Object(), value); 非静态变量的Field.get()和Field.set()方法需要指定该变量所属的对象，因为每个对象里有很多相同变量，它们独自享有一块内存，如果不指定对象，就会有歧义，而对于静态变量，可以将参数设置为NULL，因为在类加载时，是先加载静态变量，后加载构造方法，所以静态变量和对象没有必要的关系。 Method在java的JVM编译环节中，通过Method来检查方法的信息,它拥有方法所有的信息。 获取Method对象公有(public)方法1.获取所有的方法1Method[] methods = myClass.getMethods(); 2.获取指定的方法1Method method = myClass.getMethod("methodName", new Class[]&#123; String.class&#125;); 私有(private)方法1.获取所有的方法1Method[] privateMethods = myClass.getDeclaredMethods(); 2.获取指定的方法1Method privateMethod = myClass.getDeclaredMethod("methodName", new Class[]&#123; String.class&#125;); 获取Method信息1.获取方法名1String methodName = method.getName(); 2.获取返回类型1Class methodType = method.getReturnType(); 3.获取参数类型1Class[] types = method.getExceptionTypes(); Method访问方法公有(public)方法1Object returnValue = method.invoke(new Object(), "方法参数列表"); 私有(private)方法原理和Field一样，在JVM反射访问检查时，通过setAccessible方法来设置私有方法的访问权限。12privateMethod.setAccessible(true);Object returnValue = privateMethod.invoke(new Object(), "方法参数列表"); 方法也有静态的，所以在invoke方法中如果是静态方法可以设置成NULL. Annotation注解在java 5才出现，它扩展了类，属性，方法，参数等，在JVM编译时，通过Annotation来检查注解的信息 类注解1.获取所有的注解1Annotation[] annotations = myClass.getAnnotations(); 2.获取指定的注解1Annotation annotation = myClass.getAnnotation(MyAnnotation.class); 方法注解1.获取所有的注解1Annotation[] annotations = method.getAnnotations(); 2.获取指定的注解1Annotation annotation = method.getAnnotation(MyAnnotation.class); 参数注解12345Annotation[][] parameterAnnotations = method.getParameterAnnotations();for(Annotation[] annotations : parameterAnnotations)&#123; for(Annotation annotation : annotations)&#123; &#125;&#125; 变量注解1.获取所有的注解1Annotation[] annotations = field.getAnnotations(); 2.获取指定的注解1Annotation annotation = field.getAnnotation(MyAnnotation.class); 访问注解信息1234if(annotation instanceof MyAnnotation)&#123; MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println("name: " + myAnnotation.name());//假设注解中有name属性，就可以这样访问了&#125; Array在java中，数组是一个很特殊的对象，它不继承于Object，它们没有Object的所有属性和方法，所以它不是有某个类实例化出来的，它是由JVM动态创建的，JVM有一个Array通过反射机制来处理数组 创建数组1String[] arrays = (int[]) Array.newInstance(String.class, 3); 相当于String[] arrays = new String(3),newInstance方法中的参数为数组的类型和大小 访问数组set(对数组赋值)12Array.set(arrays, 0, 'hello');Array.set(arrays, 1, 'world'); set方法参数为别为目标数组，数组下标，值。 get(获取数组值)1Array.get(arrays,0); get方法参数分别是目标数组，数组下标。 获取Class对象通过class属性1Class class = String[].class; 通过forName方法1Class intArray = Class.forName("[I"); “[“代表的是数组，”I”代表的是int类型(针对于基本类型)，这个是原生的数组创建，因为在JVM创建数组，类名就是”[I”。 而对于普通类型来讲，创建数组就需要明确类型：1Class intArray = Class.forName("[Ljava.lang.String;"); “[L”声明普通类型数组，”java.lang.String”表示类型(类型全称)，”;”表示结束 通过getClass方法1Class class = arrays.getClass(); 获取数组属性获取数组类型1Class type = class.getComponentType(); 参考http://ifeve.com/java-reflection/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap的死循环(HashMap infinite loop)]]></title>
      <url>%2F2016%2F08%2F28%2FHashMap_infinite_loop%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 HashMap是一个线程不安全的key-value的存储集合，也意味着它在多线程的环境中也存在很大的风险。 HashMap的存储结构： 通常来讲，HashMap是由一个数组和一个链表组成，在初始化的时候，HashMap会初始化一个数组table[],在不指定容量的情况下默认为16，负载系数为0.75，HashMap在put的时候会通过key的hash值来计算这个数组的下标，然后就把这个存储集合存储在该下标的数组中，在查找时的复杂度为O(1),然而在Hash算法中，很有可能存在不同的key算出相同的值，HashMap就会把相同的值用链表来表示，这个时候就要遍历链表了，查找复杂度为O(n) 正是由于链表的存在，在多线程的环境下，共享链表，这就会变得不安全了 什么时候链表会变得不安全呢？HashMap的容量是动态的，随着容量的增加而增量，在每次put的时候都会检查当前的容量是否满足，假设上述图片的容量为4，如果当前的容量大于4乘以0.75(负载因子)，就会创建一个4乘以2的容量的新数组，将老的数组Copy到新的数组，然后所有的值就会重新hash，也就是rehash 现在我们模拟两个线程下的rehash情况，我们有两个线程：Thread1，Thread2，我们先看看HashMap中的rehash方法transfer(). 123456789101112131415// tranfer()片段// 这是在resize()中调用的方法,resize()就是HashMap扩容的方法 for (int j = 0; j &lt; src.length; j++) &#123; Entry e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry next = e.next; //假设线程1停留在这里就挂起了,线程2登场 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125;&#125; 此时运行完Thread1： 此时Entry e是e1，Entry next = e.next中的next是next1,红色是还没有完成，指针指向步骤还没有开始。现在Thread2登场了，Thread2运行完结构如下： 发现与Thread1的情况刚好反过来了，此时Entry e是e2，Entry next = e.next中的next是next2，是的，Thread2已经完成了指针指向操作了 12345Entry next = e.next; int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next;//假设Thread2已经走了这里 这个时候Thread1要登场了，从Entry next = e.next;开始继续运行下去,此时在Thread2的影响下Thread1运行的结构已经变了 此时由于Thread2的影响，(key:2 ,value:b)已经指向了(key:1,value:a),而红线是Thread1接下来的操作,完成指针指向操作，当Thread1完成时结构如下 这个时候你就会发现圆圈内形成了一个闭环，infinite loop就形成了！！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[exports和module.exports的区别]]></title>
      <url>%2F2016%2F08%2F22%2Fexports_module.exports%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 首先得明确两个的含义 exports:首先对于本身来讲是一个变量（对象），它不是module的引用，它是{}的引用，它指向module.exports的{}模块 module.exports:首先，module是一个变量，指向一块内存，exports是module中的一个属性，存储在内存中，然后exports属性指向{}模块 内存示意图如下： 现在来看看它们在运用中的异同：12exports.bar=function()&#123;&#125;;module.exports.bar=function()&#123;&#125; 上面的两行代码，分别来暴露相同的模块，两个方式是等价的，因为他们改变的内存是暴露模块的{}，使暴露模块变成了 exports和module.exports的等价是由于他们在操作同一块内存，所以意义是一样的12exports=function()&#123;&#125;;module.exports=function()&#123;&#125; 现在我们把bar属性给去掉，这时候效果就完全不一样了 这时候exports和module.exports操作的就不是同一块内存了,exports指向了新的内存,实际上module.exports也指向了新的内存，但是nodejs中寻找的是module变量下的exports属性所指向的内存块,如果exports和module.exports操作的不是同一个内存块的话，exports就不起作用了，所以不管怎么样，使用module.exports是万无一失的。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker学习笔记]]></title>
      <url>%2F2016%2F07%2F07%2Fdocker%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 什么是dockerdocker是基于linux内核（涉及cgroup，namespace，以及 AUFS 类的 Union FS 等技术），由go语言开发的，实际上是linux的一个独立和被隔离的进程，也可以称之为容器，其中含义如上鲸鱼船的图标（docker的图标）一样形象，鲸鱼船就像是linux一样，船本身相当于内核，船上可以载重的空间相当于文件存储系统，而在船上的箱子就是docker，他只是运行在linux内核上，箱子内部的空间相当于小型的文件存储系统，自成一体，不会受到外部空间（宿主）的影响，可以随时搬到另一艘船(内核)进行运输 docker和传统虚拟机的区别docker属于一种轻量级的虚拟机，那它比传统的虚拟机相比有什么区别 由上图可知，传统的虚拟机运行了一个完整的Guest OS(操作系统)，通过虚拟技术运行在宿主上，而docker上没有运行一个完整的操作系统，它只是一个容器，由docker引擎运行在宿主上，本质上来讲传统的虚拟机是在宿主之上虚拟出一套硬件，独立运行，而docker是直接运行在宿主的内核上，共享硬件资源，所以它的优势很明显 资源利用上更高效(接近宿主) 运行速度高(不需要另外一个完整的操作系统) 可移植性高(共享内核，可以在其他的宿主上运行) 安装docker支持很多主流平台的安装，包括windows，mac，linux各大发行版，在官网上写的很详细，这里说安装的一些注意点 docker对于安装环境有两个很重要的要求 宿主是linux的64位系统 宿主的内核版本不能低于3.10 如果不是linux64位的系统，那只有更换成64位的，内核版本可以通过uname -rshell命令查看你系统的内核版本，如果内核版本过低，通过sudo apt-get install -y --install-recommends linux-generic-lts-xenialshell命令去升级内核，这样就可以开始docker的安装了 如果在使用脚本安装的时候出错，可能是由于国内的防火墙的原因，可以使用国内云服务提供的修改版本 阿里云版本：1curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - DaoCloud版本：1curl -sSL https://get.daocloud.io/docker | sh 如果你的系统内核缺少AUFS内核驱动（这是docker最佳实践的内核）的话，可执行以下指令安装1sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual 如果官网的GPG密钥地址无法识别，可以执行如下指定进行安装 12sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 如果你已经安装好了docker引擎，进行docker服务的启动，linux旧版本(CentOS 7之前，Ubuntu 12.04/14.04,Debian 7 Wheezy)的启动方式： 1sudo service docker start 如果是高版本(CentOS 7之后，Ubuntu 16.04,Debian 8 Jessie/Stretch)的启动方式：12sudo systemctl enable dockersudo systemctl start docker docker核心：镜像，容器，仓库开始docker的第一个例子hello world 1docker run hello-world 以上指令是运行一个名为‘hello-world’的镜像，分解成下面的操作 运行完成会生成一个容器，利用docker ps 指令就可以查询你所生成的容器 由上可知，运行hello-world镜像可以分解成两步： 从本地镜像库查找，如果匹配则运行 如果本地镜像库没有找到，则会从官方维护的镜像库开始查找进行，如果匹配则运行，不匹配则报错 上面无论是本地镜像库，还是官方镜像库都是存储镜像的仓库，其实对于镜像，容器和仓库这三者，如果基于JAVA这种面向对象的语言来理解，镜像相当于一个声明类，而容器相当于一个实例对象，仓库就是JDK,而docker引擎就是等于JVM，当然这不是很严谨，但是很形象 镜像镜像是docker一个很重要的组件，通过docker images指令来查看所有的镜像，如下图所示 由上可知，镜像由五个属性组成： REPOSITORY：镜像实体，一般来讲名为‘hello-world’此类镜像是有官方维护的，‘andy/hello-world’此类镜像是由用户维护的，andy是用户名 TAG：标签，对于软件而言，理解也可以成版本，laster表示是该镜像的最终版本 IMAGE ID：镜像的唯一标识 CREATED：指镜像的创建时间 VIRTUAL SIZE：虚拟大小，并不是实际的大小，跟docker的分层存储有关 利用docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt;命令来加载镜像，如果没有Docker Registry地址，则默认会加载官方的镜像，标签如果没有指定，则默认下载laster版本 也可以利用docker rmi &lt;IMAGE ID&gt;指令去删除指定的镜像，也可以使用docker rmi $(docker iamges -q)去删除所有的镜像 容器简单的说，容器是一组独立运行的应用，由docker引擎提供它的上下文，镜像提供内容，利用docker run 指令可以新建和运行容器，如下图所示 利用docker ps -a指令来查看你所有的容器，如下图所示 由上可知，容器由七项属性组成 CONTAINER ID：容器唯一标识 IMAGE：所依赖的镜像 COMMAND：运行容器的命令 CREATE：容器的创建时间 STATUS：容器的状态 PORTS：所暴露的端口 NAMES：容器名 利用docker stop &lt;container id&gt; 指令停止指定容器运行，也可以使用docker stop $(docker ps -a)停止所有的容器如果你想启动它，可以利用docker start &lt;container id&gt;命令，如果你还想重新启动，可以利用docker restart &lt;container id&gt;,如果你想删除一个容器,可以使用docker rm &lt;container id&gt;，这跟删除镜像有点相似，rm指令是删除容器的，rmi指令是删除镜像的 仓库仓库是存放镜像的地方，官方维护了一个类似于github的dockerhub公共仓库来存放镜像，它的设计思想跟github很像，在这里你可以托管你的镜像，你可以点击dockerhub注册一个dockerhub的账户，然后在终端利用docker login命令输入你的用户名，密码和邮箱进行登录，在本地用户目录就会生成一个.dockercfg文件来保存用户信息，可以利用docker search &lt;image&gt;命令查询你所要镜像的信息，如下图所示 由上可知，你所查询的该镜像在公共仓库的信息，以下五项组成 NAME：相关镜像的名称 DESCRIPTION：相关镜像的描述 STARS：喜欢程度，表示该镜像的受欢迎程度 OFFICIAL：是否是官方的镜像 AUTOMATED：是否是自动创建的镜像 然后使用docker pull &lt;image&gt;命令加载公共仓库的镜像到本地，当然如果想要将自己的镜像推送到公共仓库上只需要两步 将你自己的镜像打上标签：docker tag &lt;IMAGE ID&gt; &lt;USERNAME&gt;/&lt;IAMGE NAME&gt;:&lt;TAG&gt;. 推送到公共仓库：docker push &lt;USERNAME&gt;/&lt;REPOSITORY&gt;. 自定义镜像：dockerfile现实中，官方的镜像是根本不能满足我们的需求的，所以我们需要自己去自定义镜像，首先我们需要创建dockerfile文件 123mkdir myimagecd myimagetouch Dockerfile 现在可以开始来构建一条鲸鱼的镜像，首先用文本编辑器打开Dockerfile，编辑以下内容123FROM docker/whalesay:latestRUN apt-get -y update &amp;&amp; apt-get install -y fortunesCMD /usr/games/fortune -a | cowsay Dockerfile内容一条指令会加载一层镜像，以下会分成三步执行 加载鲸鱼的镜像 更新软件源，并下载安装fortunes应用 运行这个应用 现在在该目录下利用docker build -t docker-whale .指令就完成了自己的镜像构建了，这里要注意一点，在构建的时候，镜像名后会跟随一个.，这个往往会被忽略掉，这表示运行该镜像的上下文，不是Dockerfile文件的位置，Dockerfile里所运行的上下文都是基于这个定义的，你自己也可以定义你想要的上下文，比如使用/usr/local替换.最后使用docker run docker-whale指令运行该镜像，如下图所示： 这就是一个基于官网的例子的自定义镜像，自定义镜像让docker更加灵活，更加强大，让就像编程一样，拥有无限魔力 这里列举自定义镜像最佳实践和建议 Dockerfile的定义尽量是简短的，合理而又简短的配置，一站化停止和销毁 每个Dockerfile目录尽量只有Dockerfile文件，如果有其他文件，在构建的时候，可以新建一个.dockerignore的文件到该目录进行排除其他不必要的文件 尽量避免安装不必要的包，即使他是很有用的 多数情况下，一个容器只是运行一个进程，这样能够更容易扩展和重复使用(使用容器连接) 减少构建层数来减少构建的复杂度，使用‘\’和连接符‘&amp;&amp;’来进行一次性构建 这里再列举一些常用的Dockerfile指令 LABEL记录你的Dockerfile的信息 比如：LABEL version=”0.0.1-beta” RUN运行你的应用程序或者是指令 比如：RUN apt-get update &amp;&amp; apt-get install -y curl注意：如果以上命令分成两层写，会导致获取缓存内以前的版本，导致安装无效 CMD运行该镜像包含的软件 比如：CMD [“sh”,”-s”“server tomcat start”] ENTRYPOINT运行你的应用程序和指令，或者是脚本 ENTRYPOINT [“server”]注意：如果指定了ENTRYPOINT，那么后面的CMD都变成了它的参数 EXPOSE指定该容器所监听连接的默认端口，如果docker run -p指定端口，则会覆盖该端口，比如EXPOSE 8080 ENV更新或添加你当前容器的环境变量 比如：ENV PATH /user/local/nginx/bin:$PATH ARG构建临时的环境变量，在容器运行时不会存储这些环境变量 比如：ARG NAME [=jack] COPY本地文件复制到容器 比如：COPY usr/local/ /usr/local/ ADD也有复制的功能，但在其上多了远程url下载，和自动解压包的功能 比如：ADD http://source.com/a.tar /usr/local (先下载url的资源，再解压到目标目录中)注意：推荐使用COPY，因为他的目标更明确，ADD相当于使用了多层的RUN，还不如使用RUN加连接符 VOLUME指定数据存储区，使容器和宿主进行映射存储 比如：VOLUME /data 然后使用docker run -dv mydata:/data 命令指定宿主的mydata作为容器中data目录的存储区 WORKDIR指定当前目录(目录必须存在，应使用绝对路径)，比如： WORKDIR /usr/local/ USER指定当前用户 比如：USER docker ONBUILD指定当前的镜像后面的指令不会马上构建，只有在别的镜像引用时才构建加载，适合一些基础的组件构建 总结：这是一篇docker的学习笔记，docker很强大，特别在云服务平台发挥很大的重要，现在在很多集群管理也使用docker来构建，学习docker也会有很大的提升。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[原子操作-CAS]]></title>
      <url>%2F2016%2F06%2F06%2Fcas%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 概念CAS(compare and swap)，比较和交换，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值—来自wikipedia 现代的大多数CPU都实现了CAS,它是一种无锁(lock-free),且非阻塞的一种算法，保持数据的一致性，原理并不难理解，下面是一段CAS的简单实现： 1234567891011121314public boolean cas(int old_v)&#123; for(;;)&#123; int new_v = old_v+1; int except_v = getMemoryValue(); if(expect_v == old_v)&#123; setMemoryValue(new_v); break; &#125;else&#123; old_v = except_v; &#125; &#125; return true;&#125; 其中getMemoryValue()方法指在内存中取出最新的值，setMemoryValue(new_v)方法指在讲新的值放入内存中，整个if-else就是CAS的操作（expect_v==old_v是compare，而setMemoryValue(new_v)是swap），假设有两个线程访问以上代码，用分段图表示如下： 以上图就是CAS的操作表现，由此可知，在CAS中，有三个核心的属性：old_i(旧值)，new_i(新值)，expect_i(期望值)，它每次通过旧值通过计算得到新值，然后利用旧值与期望值(从内存读取的最新的值)相比较，如果相同，就将新值写入内存中替换期望值，如果不相同，则表示操作失败，重新执行。 ABA问题CAS并不是一个完美的无锁算法，在以上的CAS操作中，getMemoryValue()方法只是在内存中取出最新的值，它不会在乎它的变化，如下图所示 如上图所示，如果线程2期间发生了两次变化，线程1是察觉不到的，经典的例子就是堆的pop和push，线程1入栈时，top的值是A，然后线程2进行了两次入堆，第二次入栈的值也是A，线程1对top进行compare，发现和旧值是一样的，就执行入堆操作，其实这时堆已经发生了改变当然如果想要解决这个问题，只有加上一个标志或者版本号来监视它的变化，这样由两个值来最为compare的根据，如还是堆的pop和push问题，只要加上一个操作标志，当每次对进行pop或者push就加1，那compare的时候再加上对原来的改变次数和现在的改变次数进行比较，这样就可以避免ABA问题了 应用乐观锁乐观锁是在最理想的情况下去执行，只有在发生冲突的时候再进行处理，其实这跟CAS的理念是很符合的，也可以这么讲，CAS也是一种乐观锁技术 JAVAjava中实现了大量的CAS操作，在JDK1.5发布的java.util.concurrent包就是建立在CAS之上的，相对比与synchronized这种锁机制且阻塞的算法，无锁且非阻塞的CAS无疑在性能上有质的提升，来看看java对CAS的实现，以AtomicInteger的增量方法为例(基于JDK1.8)123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 这里会调用sun.misc包下的Unsafe类，这是一个调用底层指令集的final类，下面看一下getAndAddInt方法12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 在这里你会看见compareAndSwapInt方法，这是一个native的方法，用来调用CPU的CAS指令实现无锁且非阻塞的增量操作，这在concurrent包下有很多这样的操作，JDK1.8的concurrentHashMap放弃了分段锁的概念，采用了CAS操作，这大大的增加了多线程下的性能 总结很多时候在线程安全和性能方面很难得到权衡，线程安全的三大特性：可见性，原子性和顺序性，原子性往往就要加上锁去实现，现在用CAS去替代原子性，volatile保证可见性和顺序性，大大增加了多线程在操作上的性能 参考https://zh.wikipedia.org/wiki/%E6%AF%94%E8%BE%83%E5%B9%B6%E4%BA%A4%E6%8D%A2http://zl198751.iteye.com/blog/1848575]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库索引]]></title>
      <url>%2F2016%2F05%2F12%2Fdatabase_index%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 索引概述 索引（英语：Index）：又稱引得，通檢，備檢，是一本书籍的重要组成部分，它把书中的重要名词列罗列出来，并给出它们相应的页码，方便读者快速查找该名 词的定义和含义—-来自维基百科。 数据库索引：是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据——来自维基百科。 索引很普遍，也很方便，他能使人能更好更快的找到自己想要的东西，在生活中也都能有很好的应用，比如一些书籍目录，指示牌，门牌号，而下面讲到的是在数据库中的应用。 数据库索引二叉树查找树要知道数据库索引之前，必须知道一种数据结构二叉查找树 二叉查找树是一种特殊的二叉树，必须要符合一定的结构规则： 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 如上图所示可知，我们这颗二叉查找树一共有7个节点，比如我们现在要搜索122这个节点，从根节点100开始遍历： 由于100&lt;122，所以我们需要查找根节点的右节点150 由于122&lt;150，所以我们现在需要查找它的左节点122 由于122==122，返回当前的节点(如果122节点绑定了当前数据库的信息，我们就可以通过索引来查找数据了) 二叉查找树是根据查找的层数来决定你的查找效率，当然最坏的查找效率也就O(n),但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(log n),如SBT,AVL树，红黑树等。 其实在这里你就能够想象到在数据库中使用索引的查找时的整个结构过程，以上我们会发现，二叉搜索树太依赖搜索的层数，数据太多也意味着层数也会增加，查询的效率也会相应的下降，面对百万级，甚至亿级的查询时，分分钟崩溃，而且你也会发现二叉搜索树应对的是单值查询（where p=2），在范围查询（where 1&lt;p&lt;3）中就捉襟见肘了（要遍历很多次），其实在单值查询中还有一种索引结构叫做哈希表 哈希表哈希表（Hash table，也叫散列表），是根据键（Key）而直接访问在内存存储位置的数据结构。 也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。 这个映射函数称做散列函数，存放记录的数组称做散列表。—-来自维基百科 其实在数据库中一些简单常见的连接操作叫做hash连接，这个数据结构也被数据库用来保存一些内部的东西（比如锁表或者缓冲池） 哈希表的定义： 关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。 关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。 由图可知，这个Hash table中有0-9十个哈希桶，我们想象成是一个数组（以0-9下标组成）,比如你所要查找的关键字通过哈希函数对10去模，保留整数有效位最后一位，用它利用比较函数（比如equals）来定位哈希桶的位置： 如果元素最后一位是 0，则进入哈希桶0， 如果元素最后一位是 1，则进入哈希桶1， 如果元素最后一位是 2，则进入哈希桶2 。依次类推 比方说你要找元素 78： 哈希表计算 78 的哈希码，等于 8。 查找哈希桶 8，找到的第一个元素是 78。 返回元素 78 查询仅耗费了 2 次运算（1次计算哈希值，另一次在哈希桶中查找元素）。 现在，比方说你要找元素 59： 哈希表计算 59 的哈希码，等于9。 查找哈希桶 9，第一个找到的元素是 99。因为 99 不等于 59， 那么 99 不是正确的元素。 用同样的逻辑，查找第二个元素(9)，第三个(79)，……，最后一个(29)。 元素不存在。 搜索耗费了 7 次运算其实由上可知，只要你的哈希函数与哈希桶定义的越好，查找的效率也就相应的越高。 B-Tree以上的关于查找的数据结构都不能满足现在日新月异的数据库了，在二叉树搜索树的基础上，又演变出一种新的数据结构B-Tree B树（英语：B-tree）是一种自平衡的树，能够保持数据有序。这种资料结构能够让查找数据，顺序访问，插入数据及删除的动作，都在对数时间内完成—-来自维基百科 一颗m阶的B-Tree规则如下： 树中每个结点至多有m个孩子； 除根结点和叶子结点外，其它每个结点至少有m/2个孩子； 若根结点不是叶子结点，则至少有2个孩子； 所有叶子结点(失败节点)都出现在同一层，叶子结点不包含任何关键字信息； 所有非终端结点中包含下列信息数据 ( n, A0 , K1 , A1 , K2 , A2 , … , Kn , An )，其中： Ki (i=1,…,n)为关键字，且Ki &lt; Ki+1 , Ai (i=0,…,n)为指向子树根结点的指针, n为关键字的个数 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 相对于二叉搜索树而言，B-Tree在每个节点中最少都得有两个孩子，优化了二叉搜索树过于依赖层数，使其更加灵活，然而相应的维护成本大大的增高。 如上图所示，比方说你要查找节点21,从根节点开始遍历： 在根节点中，由于节点21满足20&lt;21&lt;30,所以指针指向了P2 在P2中，节点21满足21&lt;22,但是指针没有指向任何地址，所以返回NULL 又比方说要查找节点88，从根节点开始遍历 在根节点中，由于节点88满足30&lt;80,所以指针指向P3 在P3中，节点88满足88&gt;62,所以指针指向P7 在P7中，节点88满足88==88，所以返回P7中的88节点 由于B-Tree的索引结构文件和表数据存储文件不是连在一起的，访问数据也有额外消耗了 由上你可以发现这种结构还是不能高效解决范围查询的场景，当出现范围查询（where 1&lt;p&lt;3）,B-Tree还是得一遍一遍的从根节点开始遍历，再一次一次进行磁盘IO（因为索引文件存储在磁盘上，而磁盘操作是物理操作，非常耗时的，所以磁盘IO是数据库查询的一个瓶颈，后面的B+Tree正好优化了这一点）。 B+Tree B+ 树是一种树数据结构，通常用于数据库和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反——来自维基百科 在一个B+树里结构： 只有最底层的节点（叶子节点）才保存信息（相关表的行位置） 其它节点只是在搜索中用来指引到正确节点的 所有的叶子节点都带有关键字直至底层节点 B+树是B树的进化体,他从磁盘IO上对原有的结构进行了优化,以至于减少对磁盘的IO（上面也提到，磁盘IO是物理操作，这对磁盘来说是很耗时间的），大大的增加了搜索的效率。 上面也提到，B树对于范围查询来讲是比较吃力的，不能高效的满足它的需求，因为范围查询（where 1&lt;p&lt;3）正常情况下在B树上要遍历两或者三遍（每次从根节点遍历），意味着要至少进行两三次的磁盘IO，这对于大数据量查询来讲是很吃力的。 B+树是怎么样进行减少磁盘IO的优化呢？我们先来看看一个范围查询在索引是怎么遍历的。 我们假设一个范围查询：where 10&lt;p&lt;50 在根节点中，满足5&lt;10&lt;58,所以指针指向P1节点 在P1节点中，满足5&lt;10&lt;30,所以指针指向P2节点 在P2底层节点中，每个节点都带有关键字，且每个节点之间相互链接，可以从一个节点遍历到另一个节点，且都是顺序的，所以，在大于或等于10的节点开始遍历，一直遍历到小于等于50为止 由上可知，在底层节点都是互相连接的，遍历中间的值就是查询的结果，而且B+树的表数据和索引文件是存储在一起的，所以遍历的就是表的行数据，这样只要一次IO就完成了。 参考http://coding-geek.com/how-databases-work/http://blog.csdn.net/v_july_v/article/details/6530142]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo搭建github博客]]></title>
      <url>%2F2016%2F05%2F11%2Fset_up_github_blog_with_hexo%2F</url>
      <content type="text"><![CDATA[仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢 安装环境 由于hexo是基于node.js的一个博客框架，所以在安装hexo之前，先安装node.js，点击node.js进入官网进行安装即可 当然还要安装基于github的deploy工具git，点击git，进入官网进行安装即可 以上安装完成时，在你的博客磁盘区域新建一个hexo文件夹，进入hexo文件夹，右键点击Git Bash Here，就会进入git的交互环境，安装hexo环境只需三个指令 123$ npm install hexo-cli -g$ hexo init$ hexo g 依次完成以上的指令，就完成了hexo的安装，现在我们启动服务，输入1$ hexo s 即可以启动hexo服务，根据提示在浏览器输入 http://localhost:4000/ 就可以查看你博客了 当然这里有一些常用命令做参考： hexo new “postName” # 新建文章 hexo new page “pageName” # 新建页面 hexo generate # 生成public目录 hexo server # 启动服务 hexo deploy # 部署到github hexo help # 查看帮助 hexo version # 查看Hexo的版本 选择主题在 http://localhost:4000/ 看到的是hexo默认的博客主题，如果你想要别的主题，点击 https://hexo.io/themes/ 就可以查看了hexo的主题大全。我使用的Random主题，他符合以下人群： 喜欢用大图做背景 不喜欢文章摘要 不喜欢在文章列表中翻页 如果你也喜欢Random主题，接下来简单的介绍它的安装，安装Random只需两个指令就可以完成，还是在/hexo目录下运行下面的指令1$ git clone https://github.com/stiekel/hexo-theme-random.git themes/random 这样主题就下载好了,现在打开 hexo/_config.yml (_config.yml文件有两个，一个在hexo的根目录下，一个在你的主题文件夹的根目录下)，找到theme属性，将主题设为random1theme: random 这里要注意一点，yaml配置文件的属性冒号之后要有一个空格，然后是值，否则将读取不到你的值然后再重启服务12$ hexo clean$ hexo s 这样就可以查看Random主题的效果了，当然了还有其他配置，比如配置他的tags，categories，about，还有你的社交网站的链接的配置，你可以访问的他的中文文档 http://hexo-theme-random.herokuapp.com/2016/05/23/Hexo-theme-Random-Chinese-User-Guide/ 这里面可以很全面的去配置random主题的博客。 github部署如果你想把你的本地的静态博客部署到线上，github是一个很好的选择，它是一个代码托管工具，由于还支持markdown这样的文本编辑格式，所以也可以算是博客的托管工具，我们可以把我们的博客托管到github上，就可以通过浏览器的url访问了。 如果你没有github的账号，你可以点击 https://github.com/ ，根据它的提示注册账号和配置shh，也可以网上搜索github如何使用，如果你有github账号,接下来就是创建博客的仓库。 创建仓库首先你先在github的repositores页面点击右上角的new按钮，来新建一个仓库，然后在Repository name一栏，写上yourname.github.io (yourname指你的用户名)，然后点击create repository按钮进行创建。 配置_config.yml在hexo根目录下的_config.yml找到 deploy: 处，设置你自己的发布信息1234567deploy: #类型为git type: git #填写你仓库的地址 repository: https://github.com/yourname/yourname.github.io.git #根据你自己的分支情况，如果没有其他分支，一般为主分支 branch: master 注意：在前面也提到，每个属性后面的值前面一定要有个空格，比如 type:(空格)git 发布现在就是将你本地的静态博客发布到github上12$ hexo clean$ hexo d -g 注意，如果你的hexo是5.0以上或者出现 error deployer not found 错误 ，那就必须先安装 hexo-deployer-git 1npm install hexo-deployer-git --save 命令 git d -g相当于git g再git d，命令完成之后只需输入你的用户名和密码完成验证即可，发布完成，打开浏览器，输入 http://yourname.github.io 就可以查看你的博客了。 域名管理当然如果你不喜欢github的子域名来访问你的博客，这个时候，你就得自己创建域名了 域名的供应商很多，不过国内外最有名的就是 godaddy 了，狗爹是目前号称最大的域名注册商，当然各种服务也是挺好的，当然还有中国的 万维网 ，不过还是推荐狗爹，这里域名注册我就不介绍了，你只需按照网站步骤就可以了 不过得注意狗爹上很多域名产品是有优惠的，你只需google或者百度godaddy优惠码就会有很多的，可以一一去试，还是能够省一点的，对于国内来讲，优惠码一定要看准是否支持支付宝支付，因为有些优惠码不支持支付宝，当然如果你有国外的信用卡或者银联就另当别论了。 CNAME想要你的域名访问你的github的仓库，就必须要创建CNAME文件,CNAME文件创建有两种方法： 第一种直接在你的仓库的根目录下直接创建CNAME文件，内容为你域名的名称，比如 1pettyandydog.com 第二种在 /hexo/source/ 目录下创建CNAME文件( 推荐 )，内容相同，然后再重新发布 DNS配置如果你已经注册号域名了，接下来就是dns配置了，dns配置有两种 第一种用是godaddy自己的dns解释器，打开godaddy的账户/产品，点击当前域名下的DNS管理按钮，配置如下 第二种使用DNSpod域名DNS代理,注册DNSpod，进入DNSpod管理，添加你自己的域名，一样按上图添加记录，然后将godaddy的nameservers界面增加两条记录 这样就大功告成，输入你的网站 ( 比如：http://pettyandydog.com ) 就可以访问你的博客了,有时候可能短时间访问不了，只需等上一段时间就可以了。]]></content>
    </entry>

    
  
  
</search>
